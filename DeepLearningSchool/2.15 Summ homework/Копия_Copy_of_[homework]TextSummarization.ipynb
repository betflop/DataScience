{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Копия Copy of [homework]TextSummarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2045e6589afb4c8fa90762454aea52db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3921e425560f4986a37b7378649e5c60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd7fba2cdfa24f278c585b8a94352c96",
              "IPY_MODEL_9b57ca855c1e484cb2c8ddab5f198b7f"
            ]
          }
        },
        "3921e425560f4986a37b7378649e5c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd7fba2cdfa24f278c585b8a94352c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c2a2084361f403bbdc1da09f0fb6a28",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ff8523787e84922a264427aff18d5c8"
          }
        },
        "9b57ca855c1e484cb2c8ddab5f198b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4689b9871d104dc2be7213077fc07d6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [02:26&lt;00:00,  6.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10fb66338fd14b238773cda4d7d4ab01"
          }
        },
        "7c2a2084361f403bbdc1da09f0fb6a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ff8523787e84922a264427aff18d5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4689b9871d104dc2be7213077fc07d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10fb66338fd14b238773cda4d7d4ab01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "955f186ebecf4fb69b51deeff5c3e363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9686022110a8415891a13e1e0fe38b0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31442dc4f42c48b79388953e4553db69",
              "IPY_MODEL_811f98ab01ec4e18a43be079d5e47642"
            ]
          }
        },
        "9686022110a8415891a13e1e0fe38b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31442dc4f42c48b79388953e4553db69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b73659f9732749ae8c33923089a5eeb2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f38433071924a8aa31c29569e2876ff"
          }
        },
        "811f98ab01ec4e18a43be079d5e47642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac408ec605d744ff8dea95635cf57fa1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30000/30000 [29:04&lt;00:00, 17.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a820546969fb46d4ae887b68330d83e4"
          }
        },
        "b73659f9732749ae8c33923089a5eeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f38433071924a8aa31c29569e2876ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac408ec605d744ff8dea95635cf57fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a820546969fb46d4ae887b68330d83e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e77aec435e384156b25f055c2f46bef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80d4d6b052854990b55ceacd552c3558",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bb456f3630e4e3ca44fb9ca4b4167ce",
              "IPY_MODEL_7ab88e8acb334208a65d4a9f5565d3d9"
            ]
          }
        },
        "80d4d6b052854990b55ceacd552c3558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bb456f3630e4e3ca44fb9ca4b4167ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3af62bffff6c48d0a9a63df37ced10d0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5265,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5265,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e41e563965e4de1b7f910bf85b3c5de"
          }
        },
        "7ab88e8acb334208a65d4a9f5565d3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3163dcca565b462bbb169ae04d1a2e14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5265/5265 [06:01&lt;00:00, 14.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_018faafbd7c349c9a2fcb8db3ddb1287"
          }
        },
        "3af62bffff6c48d0a9a63df37ced10d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e41e563965e4de1b7f910bf85b3c5de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3163dcca565b462bbb169ae04d1a2e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "018faafbd7c349c9a2fcb8db3ddb1287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df72cebf277145399d4f228ecd760845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4460f66ee1d94d1f9ca596ff0ba992e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64b18189c28047fe9bb389e78c63e0d2",
              "IPY_MODEL_01a3a80706374fa5b80a31e70837b04f"
            ]
          }
        },
        "4460f66ee1d94d1f9ca596ff0ba992e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64b18189c28047fe9bb389e78c63e0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39f352fa5f25436384b63331aabc6a35",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5770,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5770,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdf47fd4010f4f6aa6c370b8c5ac39f3"
          }
        },
        "01a3a80706374fa5b80a31e70837b04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b853402b7404163954bf0f84eaddf76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5770/5770 [11:20&lt;00:00,  8.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_732192e666ff4ce18e206666dd961427"
          }
        },
        "39f352fa5f25436384b63331aabc6a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdf47fd4010f4f6aa6c370b8c5ac39f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b853402b7404163954bf0f84eaddf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "732192e666ff4ce18e206666dd961427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c8fc1e452a843f397661a38215cea78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4171381ae7fc49398508458217823652",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e0bf13c03e9c440a82785e216611e5a7",
              "IPY_MODEL_ed3bf220a2174857abd9be199749ecab"
            ]
          }
        },
        "4171381ae7fc49398508458217823652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0bf13c03e9c440a82785e216611e5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12c83ab0c0e54f30b493ac24e18e6cab",
            "_dom_classes": [],
            "description": "Train Loss: 0.178, Valid Loss: 0.179:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 552,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3ab5d2e388248519bd9bcf0ba7cbb9c"
          }
        },
        "ed3bf220a2174857abd9be199749ecab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8497f3aed7f4d7eb3fa7f9356161edf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/552 [00:00&lt;05:04,  1.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d98081a1541f4cc285c6b5a05d0a1376"
          }
        },
        "12c83ab0c0e54f30b493ac24e18e6cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3ab5d2e388248519bd9bcf0ba7cbb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8497f3aed7f4d7eb3fa7f9356161edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d98081a1541f4cc285c6b5a05d0a1376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b692dd847a094df6a33fd2b14e9b43ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0be2609bd0724b059748cbfd4361f910",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e73f596d4994e759ee2bdbe691a3881",
              "IPY_MODEL_046ef077af114e289cad90860327c55b"
            ]
          }
        },
        "0be2609bd0724b059748cbfd4361f910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e73f596d4994e759ee2bdbe691a3881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_377c5d46faa94cd4a3b14a7beae47032",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b5138531402495c80267bf28c870a37"
          }
        },
        "046ef077af114e289cad90860327c55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18e737d2eb7f44398e4b94fd148c4e9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [36:18&lt;00:00, 435.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1ea69ffd83148b78f1a47297f8c5dff"
          }
        },
        "377c5d46faa94cd4a3b14a7beae47032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b5138531402495c80267bf28c870a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e737d2eb7f44398e4b94fd148c4e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1ea69ffd83148b78f1a47297f8c5dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmb8UhIzOnfK"
      },
      "source": [
        "# Text Summarization. Homework\n",
        "\n",
        "Всем привет! Это домашка по суммаризации текста.\n",
        "\n",
        "На семинаре мы рассмотрели базовые модели для суммаризации текста. Попробуйте теперь улучшить два метода: TextRank и Extractive RNN. Задание достаточно большое и требует хорошую фантазию, тут можно эксперементировать во всю.\n",
        "\n",
        "Для сдачи заданий надо получить определенное качество по test-у:\n",
        "\n",
        "- 1 задание: 0.35 BLEU\n",
        "- 2 задание: 0.35 BLEU\n",
        "\n",
        "Если ваш подход пробивает это качество – задание считается пройденным. Плюсом будет описание того, почему вы решили использовать то или иное решение. \n",
        "\n",
        "Датасет: gazeta.ru\n",
        "\n",
        "**P.S.** Возможно, в датасете находятся пустые данные. Проверьте эту гипотезу, и если надо, сделайте предобратоку датасета.\n",
        "\n",
        "\n",
        "`Ноутбук создан на основе семинара Гусева Ильи на кафедре компьютерной лингвистики МФТИ.`\n",
        "\n",
        "Загрузим датасет и необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkLTkFRfXvA"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXS1sdYZCluU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4aa0b1-7604-4985-e0ce-adf77af197ae"
      },
      "source": [
        "!pip install -Uq razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa\n",
        "!pip install -Uq transformers youtokentome"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 512kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 16.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 18.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 54.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5MB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 46.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 54.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 42.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 54.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.0MB 53.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: botocore 1.19.30 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7MB 25.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.1MB/s \n",
            "\u001b[31mERROR: allennlp 1.2.2 has requirement transformers<3.6,>=3.4, but you'll have transformers 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZ2UGS2DGjH"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(eval(line)) # Simple hack\n",
        "    records = pd.DataFrame(records)\n",
        "    if sort_by_date:\n",
        "        records = records.sort(\"date\")\n",
        "    if shuffle:\n",
        "        records = records.sample(frac=1)\n",
        "    return records"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDp-BunEA91"
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "It44Ii6Aeysg",
        "outputId": "ea8d4c12-14e3-4b7e-d7bc-9b32fb9af4b6"
      },
      "source": [
        "train_records.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23366</th>\n",
              "      <td>https://www.gazeta.ru/social/2017/10/11/109281...</td>\n",
              "      <td>О том, что чиновники Роскомнадзор а стали фигу...</td>\n",
              "      <td>Следователи пришли в Роскомнадзор</td>\n",
              "      <td>Чиновников Роскомнадзора обвинили в мошенничес...</td>\n",
              "      <td>2017-10-11 22:05:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14768</th>\n",
              "      <td>https://www.gazeta.ru/comments/2011/06/07_e_36...</td>\n",
              "      <td>Кремлевская администрация и правительство пыта...</td>\n",
              "      <td>Сумеречное решение</td>\n",
              "      <td>Возросшая фискальная нагрузка неподъемна для э...</td>\n",
              "      <td>2011-06-07 17:13:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39413</th>\n",
              "      <td>https://www.gazeta.ru/social/2019/02/23/122037...</td>\n",
              "      <td>После завершения «декоммунизации» Украинский и...</td>\n",
              "      <td>«Уничтожить легенды»: на Украине готовятся к «...</td>\n",
              "      <td>На Украине готовятся к началу «деколонизации»,...</td>\n",
              "      <td>2019-02-23 23:40:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9131</th>\n",
              "      <td>https://www.gazeta.ru/auto/2018/12/20_a_121011...</td>\n",
              "      <td>На автодорогах России в 2019 году появятся пил...</td>\n",
              "      <td>Водителей разбудят: на дорогах России появится...</td>\n",
              "      <td>Участки с шумовой разметкой появятся на россий...</td>\n",
              "      <td>2018-12-20 09:34:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>https://www.gazeta.ru/politics/2012/12/06_a_48...</td>\n",
              "      <td>Американский сенат в четверг одобрил скандальн...</td>\n",
              "      <td>Магнитский закрыл Америку</td>\n",
              "      <td>«Акт Магнитского» принят сенатом США. Теперь д...</td>\n",
              "      <td>2012-12-06 22:23:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     url  ...                 date\n",
              "23366  https://www.gazeta.ru/social/2017/10/11/109281...  ...  2017-10-11 22:05:46\n",
              "14768  https://www.gazeta.ru/comments/2011/06/07_e_36...  ...  2011-06-07 17:13:13\n",
              "39413  https://www.gazeta.ru/social/2019/02/23/122037...  ...  2019-02-23 23:40:24\n",
              "9131   https://www.gazeta.ru/auto/2018/12/20_a_121011...  ...  2018-12-20 09:34:31\n",
              "410    https://www.gazeta.ru/politics/2012/12/06_a_48...  ...  2012-12-06 22:23:09\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk-9qgHZe3LF",
        "outputId": "443c54d0-b86d-4bcf-bd17-90304153fcb5"
      },
      "source": [
        "train_records.shape, val_records.shape, test_records.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((52400, 5), (5265, 5), (5770, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAcVSli3r3S"
      },
      "source": [
        "## 1 задание: TextRank (порог: 0.35 BLEU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7jAQp-_Ds98"
      },
      "source": [
        "TextRank - unsupervised метод для составления кратких выжимок из текста. \n",
        "Описание метода:\n",
        "\n",
        "1. Сплитим текст по предложениям\n",
        "2. Считаем \"похожесть\" предложений между собой\n",
        "3. Строим граф предложений с взвешенными ребрами\n",
        "4. С помощью алгоритм PageRank получаем наиболее важные предложения, на основе которых делаем summary.\n",
        "\n",
        "Функция похожести можно сделать и из нейросетевых(или около) моделек: FastText, ELMO и BERT. Выберете один метод, загрузите предобученную модель и с ее помощью для каждого предложениия сделайте sentence embedding. С помощью косинусной меры определяйте похожесть предложений.\n",
        "\n",
        "Предобученные модели можно взять по [ссылке](http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvd2sOWYvunE"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2GNJcAMgqzn",
        "outputId": "5cc9b8e1-bcfb-40f9-e386-f33c5c3fef82"
      },
      "source": [
        "!pip install catalyst"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catalyst\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/45/24a485b76527a2601f11f12c16b5b11f853b42a3ba029d21d5c80c6c30d1/catalyst-20.11-py2.py3-none-any.whl (489kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 10.2MB/s \n",
            "\u001b[?25hCollecting GitPython>=3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.3.0)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.1.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Collecting deprecation\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.5)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.7.0+cu101)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (50.3.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.35.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.6.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.8)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2020.11.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Installing collected packages: smmap, gitdb, GitPython, deprecation, catalyst\n",
            "Successfully installed GitPython-3.1.11 catalyst-20.11 deprecation-2.1.0 gitdb-4.0.5 smmap-3.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8dEynkLff0i"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from catalyst.utils import set_global_seed\n",
        "\n",
        "seed = 42\n",
        "set_global_seed(seed)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo4pWZV9flNE",
        "outputId": "73f9fffe-90db-45bc-b3f2-9b68e6108619"
      },
      "source": [
        "cosine_similarity([[1,2,3,4,5]], [[2,3,4,5,6]]), cosine_similarity([[1,2,3,4,5]], [[5,4,3,2,1]]), cosine_similarity([[1,1]], [[-1,-1]])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.99493668]]), array([[0.63636364]]), array([[-1.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EpVP2xILm_k"
      },
      "source": [
        "# загрузим предварительно обученные модели лля токенизации и получения эмбеддингов\n",
        "\n",
        "# pretrained_model_name = \"DeepPavlov/rubert-base-cased-sentence\"\n",
        "# tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_model_name)\n",
        "# model = transformers.AutoModelWithLMHead.from_pretrained(pretrained_model_name)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzV34vhMghJu",
        "outputId": "85168316-5a82-4b84-9176-448672c522e4"
      },
      "source": [
        "# !wget http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 17:08:46--  http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 661614603 (631M) [application/octet-stream]\n",
            "Saving to: ‘sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz’\n",
            "\n",
            "sentence_ru_cased_L 100%[===================>] 630.96M  3.02MB/s    in 3m 11s  \n",
            "\n",
            "2020-12-06 17:11:59 (3.31 MB/s) - ‘sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz’ saved [661614603/661614603]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ulmJ154hTvz",
        "outputId": "bfc90920-f958-4e52-ccb7-cd1b4b1db6ad"
      },
      "source": [
        "# !tar -xvzf sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_ru_cased_L-12_H-768_A-12_pt/\n",
            "sentence_ru_cased_L-12_H-768_A-12_pt/pytorch_model.bin\n",
            "sentence_ru_cased_L-12_H-768_A-12_pt/bert_config.json\n",
            "sentence_ru_cased_L-12_H-768_A-12_pt/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTn5gDsJJrdX",
        "outputId": "2a09cc9e-4094-4ba3-d0ef-e3434922ff10"
      },
      "source": [
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 17:44:28--  http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662398225 (632M) [application/octet-stream]\n",
            "Saving to: ‘sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz’\n",
            "\n",
            "sentence_multi_case 100%[===================>] 631.71M  5.53MB/s    in 3m 17s  \n",
            "\n",
            "2020-12-06 17:47:46 (3.21 MB/s) - ‘sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz’ saved [662398225/662398225]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiEdJqn5J7qE",
        "outputId": "ed0fe584-a4c8-4bcb-bcd3-188b8c890977"
      },
      "source": [
        "!tar -xvzf sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_multi_cased_L-12_H-768_A-12_pt/\n",
            "sentence_multi_cased_L-12_H-768_A-12_pt/pytorch_model.bin\n",
            "sentence_multi_cased_L-12_H-768_A-12_pt/bert_config.json\n",
            "sentence_multi_cased_L-12_H-768_A-12_pt/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWGg1KqJg2UK"
      },
      "source": [
        "import transformers\n",
        "import torch\n",
        "class Seq2Vec():\n",
        "  def __init__(self,vocabName=\"vocab.txt\",bertConfig = \"bert_config.json\",bertName=\"pytorch_model.bin\", tokenizer_name = \"bert-base-multilingual-cased\"):\n",
        "    #   https://huggingface.co/transformers/pretrained_models.html\n",
        "    self.tokenizer = transformers.BertTokenizer.from_pretrained(tokenizer_name)\n",
        "    self.simple_vocab = {}\n",
        "    with open(vocabName,\"r\") as vocab:\n",
        "      all_text = vocab.read().split('\\n')\n",
        "      for i in range(len(all_text)):\n",
        "        self.simple_vocab[all_text[i]] = i\n",
        "    self.model = transformers.BertModel.from_pretrained(bertName, config = bertConfig, output_hidden_states=True)\n",
        "    self.model.to(\"cuda\")\n",
        "    self.model.eval()\n",
        "    self.data = {}\n",
        "    self.PAD = self.simple_vocab['[PAD]']\n",
        "    self.SEP = self.simple_vocab['[SEP]']\n",
        "    self.CLS = self.simple_vocab['[CLS]']\n",
        "  def get_ids(self,tokens):\n",
        "    result = [self.CLS]\n",
        "    for k in tokens:\n",
        "      if (k in self.simple_vocab):\n",
        "         result.append(self.simple_vocab[k])\n",
        "      else: result.append(0)\n",
        "    result.append(self.SEP)\n",
        "    if (result == [self.CLS]): return [self.CLS,0,self.SEP]\n",
        "    return result\n",
        "  def get_vec(self,sequence):\n",
        "    with torch.no_grad():\n",
        "      if(\"|\".join(sequence) in self.data):\n",
        "        return self.data[\"|\".join(sequence)]\n",
        "      tokens = self.tokenizer.tokenize(\" \".join(sequence))\n",
        "      tokens = self.get_ids(tokens)\n",
        "\n",
        "      embeddings = self.model(torch.LongTensor([tokens]).to(\"cuda\")).last_hidden_state[:,0,:]\n",
        "      \n",
        "      res = embeddings.cpu().reshape(-1).detach().numpy()\n",
        "      self.data[\"|\".join(sequence)] = res\n",
        "      return res\n",
        "\n",
        "model = Seq2Vec()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fevnxRxfyQD"
      },
      "source": [
        "def embed_str(sentence):\n",
        "    '''\n",
        "    Функция для вывода массива эмбедингов предложения, полученных с пом. \n",
        "    модели BERT. Эти эмбединги - выход скрытого слоя модели.\n",
        "    '''\n",
        "    # print(sentence)\n",
        "    if len(sentence) > 1:\n",
        "        sentence = ' '.join(sentence)\n",
        "    # if sentence in embed_sentence:\n",
        "    #     return embed_sentence[sentence]\n",
        "    \n",
        "    input_ids = torch.tensor(tokenizer.encode(sentence)).unsqueeze(0)\n",
        "    outputs = model(input_ids)\n",
        "    last_hidden_states = [outputs[0].detach().numpy().squeeze()[-1, :]]\n",
        "    # embed_sentence[sentence] = last_hidden_states\n",
        "    return last_hidden_states"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GwyRrMPAzS"
      },
      "source": [
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pymorphy2\n",
        "import razdel\n",
        "\n",
        "i = 0\n",
        "\n",
        "def unique_words_similarity(words1, words2):\n",
        "    '''\n",
        "    Функция подсчёта близости предложений на основе пересечения слов\n",
        "    '''\n",
        "    global i\n",
        "    i += 1\n",
        "    words1 = set(words1)\n",
        "    words2 = set(words2)\n",
        "    if not len(words1) or not len(words2):\n",
        "        return 0.0\n",
        "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
        "\n",
        "\n",
        "def your_super_words_similarity(words1, words2):\n",
        "    global i\n",
        "    i += 1\n",
        "    # print(i)\n",
        "\n",
        "    # words1 = np.squeeze(words1)\n",
        "    # words2 = np.squeeze(words2)\n",
        "    # print('your_super_words_similarity')\n",
        "    words1, words2 = model.get_vec(words1), model.get_vec(words2)\n",
        "    # print(words1)\n",
        "    # print(words1.shape)\n",
        "    # print(words2)\n",
        "    # print(words2.shape)\n",
        "    dist = cosine_similarity([words1], [words2]) # [:, 0]\n",
        "    # print('dist', dist)\n",
        "    return dist[0] \n",
        "    # words1 = words1/np.linalg.norm(words1)\n",
        "    # words2 = words2/np.linalg.norm(words2)\n",
        "\n",
        "    # return words1.dot(words2)\n",
        "\n",
        "\n",
        "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
        "    '''\n",
        "    Составление summary с помощью TextRank\n",
        "    '''\n",
        "    # Разбиваем текст на предложения\n",
        "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    # Токенизируем предложения\n",
        "    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
        "\n",
        "    # При необходимости лемматизируем слова\n",
        "    if morph is not None:\n",
        "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
        "\n",
        "    # Для каждой пары предложений считаем близость\n",
        "    pairs = combinations(range(n_sentences), 2)\n",
        "    # print('len pairs ', len(pairs))\n",
        "    # if calc_similarity==unique_words_similarity: \n",
        "    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
        "    # else:\n",
        "    #     '''\n",
        "    #     скор для варианта с рассчетом косинусного расстояния м-ду эмбеддингами\n",
        "    #     переведём sentences_words в эмбединги\n",
        "    #     '''\n",
        "    #     scores = [(i, j, calc_similarity(embed_str(sentences_words[i]), embed_str(sentences_words[j]))) for i, j in pairs]\n",
        " \n",
        "    print('i = ', i)\n",
        "    # Строим граф с рёбрами, равными близости между предложениями\n",
        "    g = nx.Graph()\n",
        "    g.add_weighted_edges_from(scores)\n",
        "\n",
        "    # Считаем PageRank\n",
        "    pr = nx.pagerank(g)\n",
        "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
        "    result.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Выбираем топ предложений\n",
        "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
        "    result = result[:n_summary_sentences]\n",
        "\n",
        "    # Восстанавливаем оригинальный их порядок\n",
        "    result.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Восстанавливаем текст выжимки\n",
        "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
        "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
        "    return predicted_summary\n",
        "\n",
        "def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for text, summary in records[['text', 'summary']].values[:nrows]:\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
        "        text = text if not lower else text.lower()\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4bDN_2NhVXR"
      },
      "source": [
        "# test_records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Zu-WMfvunE"
      },
      "source": [
        "# calc_text_rank_score(test_records, calc_similarity=unique_words_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84iwLYimAqPl",
        "outputId": "dcff8293-a269-46fb-ea48-70663a6ed5d5"
      },
      "source": [
        "calc_text_rank_score(test_records, calc_similarity=your_super_words_similarity)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i =  741\n",
            "i =  1444\n",
            "i =  2347\n",
            "i =  2725\n",
            "i =  3253\n",
            "i =  7081\n",
            "i =  7822\n",
            "i =  9713\n",
            "i =  10533\n",
            "i =  11274\n",
            "i =  11739\n",
            "i =  12300\n",
            "i =  13161\n",
            "i =  14646\n",
            "i =  16357\n",
            "i =  16952\n",
            "i =  17183\n",
            "i =  17711\n",
            "i =  18306\n",
            "i =  18834\n",
            "i =  19362\n",
            "i =  19797\n",
            "i =  20500\n",
            "i =  20906\n",
            "i =  21536\n",
            "i =  21971\n",
            "i =  22601\n",
            "i =  23007\n",
            "i =  23535\n",
            "i =  23860\n",
            "i =  24601\n",
            "i =  25007\n",
            "i =  25535\n",
            "i =  26096\n",
            "i =  26447\n",
            "i =  26882\n",
            "i =  27443\n",
            "i =  28346\n",
            "i =  28941\n",
            "i =  29376\n",
            "i =  30117\n",
            "i =  32818\n",
            "i =  33283\n",
            "i =  34063\n",
            "i =  34528\n",
            "i =  35123\n",
            "i =  35864\n",
            "i =  38142\n",
            "i =  39088\n",
            "i =  40363\n",
            "i =  41309\n",
            "i =  42170\n",
            "i =  42765\n",
            "i =  43143\n",
            "i =  43704\n",
            "i =  44445\n",
            "i =  45306\n",
            "i =  46047\n",
            "i =  46453\n",
            "i =  47083\n",
            "i =  47863\n",
            "i =  48298\n",
            "i =  49039\n",
            "i =  50365\n",
            "i =  51446\n",
            "i =  52527\n",
            "i =  53157\n",
            "i =  53508\n",
            "i =  54411\n",
            "i =  54972\n",
            "i =  55500\n",
            "i =  55878\n",
            "i =  56406\n",
            "i =  56616\n",
            "i =  57211\n",
            "i =  57914\n",
            "i =  58509\n",
            "i =  59037\n",
            "i =  59778\n",
            "i =  62124\n",
            "i =  62559\n",
            "i =  63339\n",
            "i =  63867\n",
            "i =  64273\n",
            "i =  64868\n",
            "i =  66759\n",
            "i =  67194\n",
            "i =  67860\n",
            "i =  68238\n",
            "i =  68734\n",
            "i =  69554\n",
            "i =  70019\n",
            "i =  70454\n",
            "i =  71049\n",
            "i =  71679\n",
            "i =  72382\n",
            "i =  73085\n",
            "i =  73361\n",
            "i =  73889\n",
            "i =  75065\n",
            "i =  75561\n",
            "i =  76381\n",
            "i =  76787\n",
            "i =  77315\n",
            "i =  78095\n",
            "i =  78798\n",
            "i =  79539\n",
            "i =  80280\n",
            "i =  80556\n",
            "i =  81186\n",
            "i =  83266\n",
            "i =  83969\n",
            "i =  84434\n",
            "i =  85064\n",
            "i =  85844\n",
            "i =  86250\n",
            "i =  87628\n",
            "i =  88408\n",
            "i =  89149\n",
            "i =  89677\n",
            "i =  92162\n",
            "i =  92658\n",
            "i =  93478\n",
            "i =  94006\n",
            "i =  94441\n",
            "i =  95344\n",
            "i =  96290\n",
            "i =  96956\n",
            "i =  97859\n",
            "i =  98454\n",
            "i =  98805\n",
            "i =  99400\n",
            "i =  99751\n",
            "i =  100927\n",
            "i =  101227\n",
            "i =  101723\n",
            "i =  102584\n",
            "i =  102990\n",
            "i =  103810\n",
            "i =  104188\n",
            "i =  104684\n",
            "i =  105674\n",
            "i =  106269\n",
            "i =  106972\n",
            "i =  108148\n",
            "i =  109051\n",
            "i =  109547\n",
            "i =  110075\n",
            "i =  110778\n",
            "i =  112923\n",
            "i =  113703\n",
            "i =  115719\n",
            "i =  116215\n",
            "i =  116593\n",
            "i =  117154\n",
            "i =  117619\n",
            "i =  118795\n",
            "i =  119923\n",
            "i =  120419\n",
            "i =  120884\n",
            "i =  121412\n",
            "i =  122007\n",
            "i =  122472\n",
            "i =  123000\n",
            "i =  124596\n",
            "i =  125416\n",
            "i =  125977\n",
            "i =  126680\n",
            "i =  127383\n",
            "i =  127848\n",
            "i =  128199\n",
            "i =  129102\n",
            "i =  129537\n",
            "i =  130203\n",
            "i =  130983\n",
            "i =  131649\n",
            "i =  132639\n",
            "i =  133459\n",
            "i =  134162\n",
            "i =  134903\n",
            "i =  136856\n",
            "i =  137676\n",
            "i =  138417\n",
            "i =  138768\n",
            "i =  139398\n",
            "i =  139674\n",
            "i =  141385\n",
            "i =  141820\n",
            "i =  142285\n",
            "i =  142636\n",
            "i =  143539\n",
            "i =  144100\n",
            "i =  144695\n",
            "i =  145598\n",
            "i =  146544\n",
            "i =  148197\n",
            "i =  149575\n",
            "i =  150703\n",
            "i =  150934\n",
            "i =  151462\n",
            "i =  152057\n",
            "i =  152435\n",
            "i =  152666\n",
            "i =  153569\n",
            "i =  154164\n",
            "i =  155649\n",
            "i =  156145\n",
            "i =  156673\n",
            "i =  156926\n",
            "i =  157787\n",
            "i =  158018\n",
            "i =  158838\n",
            "i =  159244\n",
            "i =  159947\n",
            "i =  160688\n",
            "i =  161429\n",
            "i =  163985\n",
            "i =  164513\n",
            "i =  164948\n",
            "i =  165983\n",
            "i =  166308\n",
            "i =  167436\n",
            "i =  168297\n",
            "i =  169038\n",
            "i =  169858\n",
            "i =  170068\n",
            "i =  170698\n",
            "i =  171104\n",
            "i =  171600\n",
            "i =  172161\n",
            "i =  173022\n",
            "i =  174562\n",
            "i =  175303\n",
            "i =  176384\n",
            "i =  177164\n",
            "i =  177629\n",
            "i =  178409\n",
            "i =  178815\n",
            "i =  179311\n",
            "i =  179807\n",
            "i =  181032\n",
            "i =  181467\n",
            "i =  182247\n",
            "i =  182950\n",
            "i =  183545\n",
            "i =  183798\n",
            "i =  184464\n",
            "i =  185367\n",
            "i =  185802\n",
            "i =  186505\n",
            "i =  187066\n",
            "i =  187342\n",
            "i =  188377\n",
            "i =  188728\n",
            "i =  189289\n",
            "i =  189817\n",
            "i =  190142\n",
            "i =  190883\n",
            "i =  191586\n",
            "i =  191862\n",
            "i =  192943\n",
            "i =  193846\n",
            "i =  194707\n",
            "i =  196360\n",
            "i =  196711\n",
            "i =  197089\n",
            "i =  197992\n",
            "i =  198812\n",
            "i =  199218\n",
            "i =  199959\n",
            "i =  200662\n",
            "i =  201328\n",
            "i =  201793\n",
            "i =  202289\n",
            "i =  202992\n",
            "i =  203427\n",
            "i =  203955\n",
            "i =  205036\n",
            "i =  205501\n",
            "i =  206726\n",
            "i =  207546\n",
            "i =  209199\n",
            "i =  211152\n",
            "i =  211648\n",
            "i =  212113\n",
            "i =  212933\n",
            "i =  213528\n",
            "i =  214854\n",
            "i =  215520\n",
            "i =  216745\n",
            "i =  217606\n",
            "i =  217882\n",
            "i =  218135\n",
            "i =  218513\n",
            "i =  219143\n",
            "i =  219396\n",
            "i =  219991\n",
            "i =  220771\n",
            "i =  221996\n",
            "i =  222347\n",
            "i =  223013\n",
            "i =  223244\n",
            "i =  223910\n",
            "i =  224613\n",
            "i =  226629\n",
            "i =  228225\n",
            "i =  228753\n",
            "i =  229494\n",
            "i =  230160\n",
            "i =  230688\n",
            "i =  232704\n",
            "i =  233265\n",
            "i =  234045\n",
            "i =  234370\n",
            "i =  234623\n",
            "i =  237179\n",
            "i =  237845\n",
            "i =  238440\n",
            "i =  240585\n",
            "i =  241081\n",
            "i =  241271\n",
            "i =  242982\n",
            "i =  243612\n",
            "i =  246097\n",
            "i =  246958\n",
            "i =  247661\n",
            "i =  248067\n",
            "i =  249607\n",
            "i =  251752\n",
            "i =  252313\n",
            "i =  252874\n",
            "i =  253174\n",
            "i =  253670\n",
            "i =  254531\n",
            "i =  255234\n",
            "i =  255937\n",
            "i =  257018\n",
            "i =  258099\n",
            "i =  259002\n",
            "i =  259278\n",
            "i =  259656\n",
            "i =  260559\n",
            "i =  261262\n",
            "i =  262487\n",
            "i =  262952\n",
            "i =  263732\n",
            "i =  264260\n",
            "i =  264821\n",
            "i =  265199\n",
            "i =  265634\n",
            "i =  266012\n",
            "i =  267140\n",
            "i =  267701\n",
            "i =  268736\n",
            "i =  268967\n",
            "i =  269528\n",
            "i =  270269\n",
            "i =  270620\n",
            "i =  272273\n",
            "i =  273219\n",
            "i =  273684\n",
            "i =  274180\n",
            "i =  275170\n",
            "i =  275800\n",
            "i =  276206\n",
            "i =  276612\n",
            "i =  277077\n",
            "i =  277455\n",
            "i =  277686\n",
            "i =  278182\n",
            "i =  278678\n",
            "i =  279239\n",
            "i =  279539\n",
            "i =  280280\n",
            "i =  280776\n",
            "i =  281029\n",
            "i =  281525\n",
            "i =  282053\n",
            "i =  283134\n",
            "i =  283459\n",
            "i =  284239\n",
            "i =  284617\n",
            "i =  285358\n",
            "i =  286633\n",
            "i =  287194\n",
            "i =  287470\n",
            "i =  287905\n",
            "i =  288571\n",
            "i =  289699\n",
            "i =  290329\n",
            "i =  291109\n",
            "i =  293125\n",
            "i =  294028\n",
            "i =  294493\n",
            "i =  294818\n",
            "i =  295224\n",
            "i =  295752\n",
            "i =  296347\n",
            "i =  296725\n",
            "i =  297586\n",
            "i =  298216\n",
            "i =  298777\n",
            "i =  299597\n",
            "i =  300587\n",
            "i =  301812\n",
            "i =  302632\n",
            "i =  303193\n",
            "i =  303518\n",
            "i =  304079\n",
            "i =  304859\n",
            "i =  305454\n",
            "i =  305779\n",
            "i =  306275\n",
            "i =  306626\n",
            "i =  307122\n",
            "i =  307825\n",
            "i =  308290\n",
            "i =  308920\n",
            "i =  309173\n",
            "i =  310254\n",
            "i =  310995\n",
            "i =  311898\n",
            "i =  312363\n",
            "i =  312769\n",
            "i =  313175\n",
            "i =  313475\n",
            "i =  314906\n",
            "i =  315371\n",
            "i =  316151\n",
            "i =  316647\n",
            "i =  317025\n",
            "i =  318978\n",
            "i =  319413\n",
            "i =  320359\n",
            "i =  320659\n",
            "i =  320959\n",
            "i =  321365\n",
            "i =  321690\n",
            "i =  322186\n",
            "i =  322852\n",
            "i =  323447\n",
            "i =  323882\n",
            "i =  324410\n",
            "i =  325151\n",
            "i =  325817\n",
            "i =  326807\n",
            "i =  327548\n",
            "i =  329033\n",
            "i =  329529\n",
            "i =  329739\n",
            "i =  329970\n",
            "i =  330750\n",
            "i =  331345\n",
            "i =  331780\n",
            "i =  332341\n",
            "i =  332692\n",
            "i =  333253\n",
            "i =  333688\n",
            "i =  334864\n",
            "i =  335215\n",
            "i =  336161\n",
            "i =  336657\n",
            "i =  337287\n",
            "i =  338190\n",
            "i =  338655\n",
            "i =  339033\n",
            "i =  339663\n",
            "i =  340014\n",
            "i =  340609\n",
            "i =  341239\n",
            "i =  341980\n",
            "i =  342170\n",
            "i =  342698\n",
            "i =  343439\n",
            "i =  344180\n",
            "i =  344741\n",
            "i =  345482\n",
            "i =  345947\n",
            "i =  346542\n",
            "i =  348888\n",
            "i =  349518\n",
            "i =  350184\n",
            "i =  351174\n",
            "i =  351580\n",
            "i =  352076\n",
            "i =  352541\n",
            "i =  353102\n",
            "i =  353427\n",
            "i =  354207\n",
            "i =  354613\n",
            "i =  355243\n",
            "i =  355771\n",
            "i =  356401\n",
            "i =  357067\n",
            "i =  357887\n",
            "i =  358352\n",
            "i =  358982\n",
            "i =  359447\n",
            "i =  360042\n",
            "i =  360745\n",
            "i =  361411\n",
            "i =  361972\n",
            "i =  362567\n",
            "i =  363063\n",
            "i =  363363\n",
            "i =  363924\n",
            "i =  364200\n",
            "i =  365061\n",
            "i =  366546\n",
            "i =  366897\n",
            "i =  368122\n",
            "i =  368717\n",
            "i =  369663\n",
            "i =  370293\n",
            "i =  370854\n",
            "i =  371382\n",
            "i =  371977\n",
            "i =  372572\n",
            "i =  372923\n",
            "i =  373664\n",
            "i =  374525\n",
            "i =  375386\n",
            "i =  375914\n",
            "i =  376320\n",
            "i =  377223\n",
            "i =  377688\n",
            "i =  378013\n",
            "i =  378364\n",
            "i =  378925\n",
            "i =  379555\n",
            "i =  379906\n",
            "i =  380536\n",
            "i =  380836\n",
            "i =  381656\n",
            "i =  381981\n",
            "i =  382477\n",
            "i =  383038\n",
            "i =  384469\n",
            "i =  384904\n",
            "i =  385310\n",
            "i =  386300\n",
            "i =  386861\n",
            "i =  387564\n",
            "i =  388890\n",
            "i =  389296\n",
            "i =  390242\n",
            "i =  390738\n",
            "i =  391333\n",
            "i =  391684\n",
            "i =  392090\n",
            "i =  392441\n",
            "i =  393431\n",
            "i =  393927\n",
            "i =  394423\n",
            "i =  395963\n",
            "i =  396629\n",
            "i =  397259\n",
            "i =  397820\n",
            "i =  398415\n",
            "i =  398850\n",
            "i =  399630\n",
            "i =  400191\n",
            "i =  401137\n",
            "i =  401957\n",
            "i =  402363\n",
            "i =  403353\n",
            "i =  403818\n",
            "i =  404638\n",
            "i =  406591\n",
            "i =  407056\n",
            "i =  407917\n",
            "i =  408193\n",
            "i =  408788\n",
            "i =  409418\n",
            "i =  409946\n",
            "i =  410352\n",
            "i =  411018\n",
            "i =  412503\n",
            "i =  413323\n",
            "i =  415468\n",
            "i =  416209\n",
            "i =  416804\n",
            "i =  417300\n",
            "i =  417553\n",
            "i =  418114\n",
            "i =  418390\n",
            "i =  418768\n",
            "i =  419146\n",
            "i =  419524\n",
            "i =  420085\n",
            "i =  420865\n",
            "i =  421330\n",
            "i =  421960\n",
            "i =  422425\n",
            "i =  423601\n",
            "i =  424267\n",
            "i =  424763\n",
            "i =  424973\n",
            "i =  425379\n",
            "i =  426009\n",
            "i =  427387\n",
            "i =  427822\n",
            "i =  428173\n",
            "i =  428734\n",
            "i =  429329\n",
            "i =  429794\n",
            "i =  430535\n",
            "i =  431063\n",
            "i =  432053\n",
            "i =  432488\n",
            "i =  433016\n",
            "i =  433682\n",
            "i =  434088\n",
            "i =  435169\n",
            "i =  435697\n",
            "i =  436600\n",
            "i =  437195\n",
            "i =  438141\n",
            "i =  438882\n",
            "i =  439443\n",
            "i =  440263\n",
            "i =  440929\n",
            "i =  441632\n",
            "i =  442038\n",
            "i =  442818\n",
            "i =  443346\n",
            "i =  443976\n",
            "i =  444441\n",
            "i =  445981\n",
            "i =  446927\n",
            "i =  448202\n",
            "i =  448905\n",
            "i =  449283\n",
            "i =  449748\n",
            "i =  450528\n",
            "i =  451089\n",
            "i =  451719\n",
            "i =  452184\n",
            "i =  452745\n",
            "i =  453180\n",
            "i =  454261\n",
            "i =  454586\n",
            "i =  455811\n",
            "i =  456406\n",
            "i =  456967\n",
            "i =  457708\n",
            "i =  458173\n",
            "i =  458734\n",
            "i =  459262\n",
            "i =  460003\n",
            "i =  460633\n",
            "i =  463261\n",
            "i =  463667\n",
            "i =  464408\n",
            "i =  464759\n",
            "i =  465749\n",
            "i =  466344\n",
            "i =  467047\n",
            "i =  467512\n",
            "i =  467812\n",
            "i =  468247\n",
            "i =  468808\n",
            "i =  469369\n",
            "i =  469999\n",
            "i =  470702\n",
            "i =  471053\n",
            "i =  472088\n",
            "i =  472278\n",
            "i =  472774\n",
            "i =  473302\n",
            "i =  474205\n",
            "i =  474985\n",
            "i =  475336\n",
            "i =  476767\n",
            "i =  477433\n",
            "i =  477929\n",
            "i =  478307\n",
            "i =  479847\n",
            "i =  481863\n",
            "i =  483633\n",
            "i =  484536\n",
            "i =  485064\n",
            "i =  486054\n",
            "i =  487089\n",
            "i =  487830\n",
            "i =  488650\n",
            "i =  489056\n",
            "i =  489521\n",
            "i =  490382\n",
            "i =  490910\n",
            "i =  491235\n",
            "i =  491731\n",
            "i =  492196\n",
            "i =  492496\n",
            "i =  493091\n",
            "i =  493469\n",
            "i =  493997\n",
            "i =  494187\n",
            "i =  494967\n",
            "i =  495463\n",
            "i =  496024\n",
            "i =  496585\n",
            "i =  497146\n",
            "i =  497812\n",
            "i =  498673\n",
            "i =  499268\n",
            "i =  499934\n",
            "i =  500430\n",
            "i =  501376\n",
            "i =  502279\n",
            "i =  503099\n",
            "i =  503660\n",
            "i =  504521\n",
            "i =  506601\n",
            "i =  507129\n",
            "i =  507795\n",
            "i =  508291\n",
            "i =  508819\n",
            "i =  509380\n",
            "i =  509975\n",
            "i =  510300\n",
            "i =  510861\n",
            "i =  511422\n",
            "i =  512163\n",
            "i =  512299\n",
            "i =  512965\n",
            "i =  513430\n",
            "i =  513865\n",
            "i =  514855\n",
            "i =  515206\n",
            "i =  516026\n",
            "i =  516656\n",
            "i =  517121\n",
            "i =  517982\n",
            "i =  518723\n",
            "i =  519464\n",
            "i =  521879\n",
            "i =  522285\n",
            "i =  522880\n",
            "i =  523826\n",
            "i =  524322\n",
            "i =  524512\n",
            "i =  524702\n",
            "i =  525648\n",
            "i =  526351\n",
            "i =  526702\n",
            "i =  527563\n",
            "i =  528266\n",
            "i =  528896\n",
            "i =  529196\n",
            "i =  529574\n",
            "i =  531285\n",
            "i =  531750\n",
            "i =  532185\n",
            "i =  532681\n",
            "i =  533177\n",
            "i =  533918\n",
            "i =  534353\n",
            "i =  534759\n",
            "i =  535165\n",
            "i =  535661\n",
            "i =  538146\n",
            "i =  538776\n",
            "i =  539811\n",
            "i =  540276\n",
            "i =  541816\n",
            "i =  543091\n",
            "i =  544366\n",
            "i =  544996\n",
            "i =  545461\n",
            "i =  546322\n",
            "i =  546673\n",
            "i =  547619\n",
            "i =  548214\n",
            "i =  548844\n",
            "i =  549144\n",
            "i =  550225\n",
            "i =  550525\n",
            "i =  551851\n",
            "i =  553562\n",
            "i =  553752\n",
            "i =  554698\n",
            "i =  554974\n",
            "i =  555640\n",
            "i =  556046\n",
            "i =  558972\n",
            "i =  559500\n",
            "i =  559825\n",
            "i =  560353\n",
            "i =  560563\n",
            "i =  560863\n",
            "i =  561241\n",
            "i =  561871\n",
            "i =  562466\n",
            "i =  563792\n",
            "i =  564068\n",
            "i =  565014\n",
            "i =  565392\n",
            "i =  565582\n",
            "i =  565933\n",
            "i =  566753\n",
            "i =  567131\n",
            "i =  567566\n",
            "i =  568094\n",
            "i =  568835\n",
            "i =  569430\n",
            "i =  570705\n",
            "i =  571170\n",
            "i =  571911\n",
            "i =  572652\n",
            "i =  573282\n",
            "i =  573810\n",
            "i =  574551\n",
            "i =  575047\n",
            "i =  575788\n",
            "i =  576166\n",
            "i =  576601\n",
            "i =  577504\n",
            "i =  577969\n",
            "i =  578830\n",
            "i =  579265\n",
            "i =  579541\n",
            "i =  580669\n",
            "i =  583154\n",
            "i =  583934\n",
            "i =  584124\n",
            "i =  584790\n",
            "i =  586065\n",
            "i =  587193\n",
            "i =  587518\n",
            "i =  587924\n",
            "i =  588452\n",
            "i =  589313\n",
            "i =  589908\n",
            "i =  590404\n",
            "i =  591034\n",
            "i =  591737\n",
            "i =  592202\n",
            "i =  592553\n",
            "i =  593049\n",
            "i =  593325\n",
            "i =  593920\n",
            "i =  594866\n",
            "i =  595427\n",
            "i =  596168\n",
            "i =  596696\n",
            "i =  597399\n",
            "i =  597750\n",
            "i =  598026\n",
            "i =  598491\n",
            "i =  599157\n",
            "i =  599653\n",
            "i =  601423\n",
            "i =  601633\n",
            "i =  602374\n",
            "i =  603004\n",
            "i =  603599\n",
            "i =  604502\n",
            "i =  604967\n",
            "i =  605292\n",
            "i =  605958\n",
            "i =  607086\n",
            "i =  607362\n",
            "i =  607858\n",
            "i =  608599\n",
            "i =  609005\n",
            "i =  609440\n",
            "i =  609650\n",
            "i =  610028\n",
            "i =  610889\n",
            "i =  611592\n",
            "i =  612088\n",
            "i =  613414\n",
            "i =  614080\n",
            "i =  615971\n",
            "i =  616322\n",
            "i =  616757\n",
            "i =  617352\n",
            "i =  617505\n",
            "i =  618066\n",
            "i =  618732\n",
            "i =  619197\n",
            "i =  620523\n",
            "i =  621189\n",
            "i =  621784\n",
            "i =  622450\n",
            "i =  623828\n",
            "i =  624018\n",
            "i =  624613\n",
            "i =  625991\n",
            "i =  626552\n",
            "i =  626903\n",
            "i =  627399\n",
            "i =  627652\n",
            "i =  628555\n",
            "i =  629116\n",
            "i =  631744\n",
            "i =  632272\n",
            "i =  632867\n",
            "i =  633143\n",
            "i =  633608\n",
            "i =  634349\n",
            "i =  635210\n",
            "i =  635675\n",
            "i =  636203\n",
            "i =  636764\n",
            "i =  638304\n",
            "i =  639385\n",
            "i =  639791\n",
            "i =  640457\n",
            "i =  640757\n",
            "i =  641163\n",
            "i =  642109\n",
            "i =  642889\n",
            "i =  643592\n",
            "i =  643845\n",
            "i =  644406\n",
            "i =  645582\n",
            "i =  646078\n",
            "i =  646898\n",
            "i =  647198\n",
            "i =  648423\n",
            "i =  648858\n",
            "i =  650034\n",
            "i =  650895\n",
            "i =  652380\n",
            "i =  653010\n",
            "i =  654606\n",
            "i =  655347\n",
            "i =  656013\n",
            "i =  656754\n",
            "i =  658407\n",
            "i =  659785\n",
            "i =  660110\n",
            "i =  660776\n",
            "i =  661101\n",
            "i =  661377\n",
            "i =  663207\n",
            "i =  663672\n",
            "i =  664998\n",
            "i =  665494\n",
            "i =  666529\n",
            "i =  667025\n",
            "i =  667586\n",
            "i =  667739\n",
            "i =  668642\n",
            "i =  669632\n",
            "i =  669822\n",
            "i =  670147\n",
            "i =  670553\n",
            "i =  671148\n",
            "i =  672474\n",
            "i =  672799\n",
            "i =  673540\n",
            "i =  674101\n",
            "i =  674629\n",
            "i =  675449\n",
            "i =  676010\n",
            "i =  677045\n",
            "i =  677298\n",
            "i =  677704\n",
            "i =  678265\n",
            "i =  678671\n",
            "i =  679049\n",
            "i =  680324\n",
            "i =  681104\n",
            "i =  681632\n",
            "i =  682227\n",
            "i =  683173\n",
            "i =  683551\n",
            "i =  684497\n",
            "i =  685317\n",
            "i =  685642\n",
            "i =  687127\n",
            "i =  687655\n",
            "i =  688321\n",
            "i =  690337\n",
            "i =  691078\n",
            "i =  691484\n",
            "i =  692519\n",
            "i =  693080\n",
            "i =  693783\n",
            "i =  694218\n",
            "i =  695079\n",
            "i =  695485\n",
            "i =  696226\n",
            "i =  696722\n",
            "i =  697100\n",
            "i =  697661\n",
            "i =  698441\n",
            "i =  699071\n",
            "i =  699302\n",
            "i =  700383\n",
            "i =  701373\n",
            "i =  701626\n",
            "i =  701704\n",
            "i =  702169\n",
            "i =  702604\n",
            "i =  703039\n",
            "i =  703859\n",
            "Count: 1000\n",
            "Ref: челябинскую городскую больницу №6 из-за мизерных зарплат продолжают покидать врачи. в начале месяца оттуда ушли врачи-неонатологи, а на этой неделе — три травматолога. тем временем руководство больницы не обращает на ситуацию внимания, а лишь размещает новые вакансии для молодых специалистов.\n",
            "Hyp: однако руководство больницы никак не реагирует на происходящее. по их данным, с июня по октябрь 2019 года уволились не три, а два врача — они написали заявления по собственному желанию. стимулирующие выходили около 11 тыс., а теперь они уменьшились на семь тысяч. получилось, что шесть тысяч мне добавили, но при этом семь тысяч забрали», — поясняла сотрудница медучреждения.\n",
            "BLEU:  0.3528862514795895\n",
            "ROUGE:  {'rouge-1': {'f': 0.13871968584115682, 'p': 0.14217591097478538, 'r': 0.14324141105296279}, 'rouge-2': {'f': 0.023640086554633757, 'p': 0.024326534437949666, 'r': 0.02456779670768402}, 'rouge-l': {'f': 0.12074738028771058, 'p': 0.12940408747069782, 'r': 0.13025694511307265}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdTrfxycB7cd"
      },
      "source": [
        "## 2 Задание: Extractive RNN (порог: 0.35 BLEU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q7DeHDYFSjX"
      },
      "source": [
        "Второй метод, который вам предлагается улучшить – поиск предложений для summary с помощью RNN. В рассмотренной методе мы использовали LSTM для генерации sentence embedding. Попробуйте использовать другие архитектуры: CNN, Transformer; или добавьте предобученные модели, как и в первом задании.\n",
        "\n",
        "P.S. Тут предполагается, что придется изменять много кода в ячееках (например, поменять токенизацию). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZamxigdEc-"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Картинка для привлечения внимания:\n",
        "\n",
        "![img](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_14%2Fproject_398421%2Fimages%2Farchitecture.png)\n",
        "\n",
        "Статья с оригинальным методом:\n",
        "https://arxiv.org/pdf/1611.04230.pdf\n",
        "\n",
        "Список вдохновения: \n",
        "- https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b Пример того, как можно применять CNN в текстовых задачах\n",
        "- https://arxiv.org/pdf/1808.08745.pdf Очень крутой метод генерации summary без Transformers\n",
        "- https://towardsdatascience.com/super-easy-way-to-get-sentence-embedding-using-fasttext-in-python-a70f34ac5b7c – простой метод генерации sentence embedding\n",
        "- https://towardsdatascience.com/fse-2b1ffa791cf9 – Необычный метод генерации sentence embedding\n",
        "- https://github.com/UKPLab/sentence-transformers – BERT предобученный для sentence embedding\n",
        "\n",
        "P.S. Выше написанные ссылки нужны только для разогрева вашей фантазии, можно воспользоваться ими, а можно придумать свой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOH4ZbLkg_sM"
      },
      "source": [
        "Комментарий к заданию:\n",
        "Если посмотреть на архитектуру ~~почти~~ SummaRuNNer, то в ней есть два главных элемента: первая часть, которая читает предложения и возвращает векторы на каждое предложение, и вторая, которая выбирает предложения для суммаризации. Вторую часть мы не трогаем, а первую меняем. На что меняем – как вы решите. Главное: она должна иметь хорошее качество и встроиться в текущую модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxsc0Orf8hGq"
      },
      "source": [
        "import copy\n",
        "import random\n",
        "\n",
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    '''\n",
        "    Жадное построение oracle summary\n",
        "    '''\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "    # Делим текст на предложения\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "    oracle_summary_sentences = set()\n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(min(n_sentences, 2)):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "            # Добавляем какое-то предложения к уже существующему summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
        "            # Считаем метрики\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
        "        # Иначе на этом заканчиваем\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_ak-KDB8rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "2045e6589afb4c8fa90762454aea52db",
            "3921e425560f4986a37b7378649e5c60",
            "bd7fba2cdfa24f278c585b8a94352c96",
            "9b57ca855c1e484cb2c8ddab5f198b7f",
            "7c2a2084361f403bbdc1da09f0fb6a28",
            "3ff8523787e84922a264427aff18d5c8",
            "4689b9871d104dc2be7213077fc07d6c",
            "10fb66338fd14b238773cda4d7d4ab01"
          ]
        },
        "outputId": "6da7c46a-9038-453f-d91d-af169ff2761d"
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "def calc_oracle_score(records, nrows=1000, lower=True):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    rouge = Rouge()\n",
        "  \n",
        "    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_oracle_score(test_records)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning:\n",
            "\n",
            "This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2045e6589afb4c8fa90762454aea52db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Count: 1000\n",
            "Ref: челябинскую городскую больницу №6 из-за мизерных зарплат продолжают покидать врачи. в начале месяца оттуда ушли врачи-неонатологи, а на этой неделе — три травматолога. тем временем руководство больницы не обращает на ситуацию внимания, а лишь размещает новые вакансии для молодых специалистов.\n",
            "Hyp: однако руководство больницы никак не реагирует на происходящее. тем временем в челябинском горздраве тасс сообщили, что никакой волны увольнений в больнице нет.\n",
            "BLEU:  0.4340029354374597\n",
            "ROUGE:  {'rouge-1': {'f': 0.3539652034259989, 'p': 0.42831485382882784, 'r': 0.3189746999202045}, 'rouge-2': {'f': 0.20238897182275806, 'p': 0.2509194888085911, 'r': 0.18122458399379074}, 'rouge-l': {'f': 0.30342070422719, 'p': 0.3965986347144005, 'r': 0.29406334140187945}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgjewfWrbJZ"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код загрузки токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIRKm4TCHzN"
      },
      "source": [
        "import os\n",
        "\n",
        "import youtokentome as yttm\n",
        "\n",
        "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=30000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for text, summary in records[['text', 'summary']].values:\n",
        "            if lower:\n",
        "                summary = summary.lower()\n",
        "                text = text.lower()\n",
        "            if not text or not summary:\n",
        "                continue\n",
        "            temp.write(text + \"\\n\")\n",
        "            temp.write(summary + \"\\n\")\n",
        "    yttm.BPE.train(data=temp_file_name, vocab_size=vocab_size, model=model_path)\n",
        "\n",
        "train_bpe(train_records, \"BPE_model.bin\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkZ2f5LhWwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3c3249-9635-41ab-f0ed-38637a8bc8be"
      },
      "source": [
        "bpe_processor = yttm.BPE('BPE_model.bin')\n",
        "bpe_processor.encode([\"октябрь богат на изменения\"], output_type=yttm.OutputType.SUBWORD)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['▁октябрь', '▁богат', '▁на', '▁изменения']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkUL_YIGp-S"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код словаря"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhQYN1beiVEC"
      },
      "source": [
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, bpe_processor):\n",
        "        self.index2word = bpe_processor.vocab()\n",
        "        self.word2index = {w: i for i, w in enumerate(self.index2word)}\n",
        "        self.word2count = Counter()\n",
        "\n",
        "    def get_pad(self):\n",
        "        return self.word2index[\"<PAD>\"]\n",
        "\n",
        "    def get_sos(self):\n",
        "        return self.word2index[\"<SOS>\"]\n",
        "\n",
        "    def get_eos(self):\n",
        "        return self.word2index[\"<EOS>\"]\n",
        "\n",
        "    def get_unk(self):\n",
        "        return self.word2index[\"<UNK>\"]\n",
        "    \n",
        "    def has_word(self, word) -> bool:\n",
        "        return word in self.word2index\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        return self.get_unk()\n",
        "\n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def is_empty(self):\n",
        "        empty_size = 4\n",
        "        return self.size() <= empty_size\n",
        "\n",
        "    def reset(self):\n",
        "        self.word2count = Counter()\n",
        "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "        self.word2index = {word: index for index, word in enumerate(self.index2word)}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qvZtNcOifAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1446d3d9-e2d7-42c4-8f40-eb125112634f"
      },
      "source": [
        "vocabulary = Vocabulary(bpe_processor)\n",
        "vocabulary.size()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdb-39jO-72q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "955f186ebecf4fb69b51deeff5c3e363",
            "9686022110a8415891a13e1e0fe38b0f",
            "31442dc4f42c48b79388953e4553db69",
            "811f98ab01ec4e18a43be079d5e47642",
            "b73659f9732749ae8c33923089a5eeb2",
            "4f38433071924a8aa31c29569e2876ff",
            "ac408ec605d744ff8dea95635cf57fa1",
            "a820546969fb46d4ae887b68330d83e4",
            "e77aec435e384156b25f055c2f46bef1",
            "80d4d6b052854990b55ceacd552c3558",
            "4bb456f3630e4e3ca44fb9ca4b4167ce",
            "7ab88e8acb334208a65d4a9f5565d3d9",
            "3af62bffff6c48d0a9a63df37ced10d0",
            "4e41e563965e4de1b7f910bf85b3c5de",
            "3163dcca565b462bbb169ae04d1a2e14",
            "018faafbd7c349c9a2fcb8db3ddb1287",
            "df72cebf277145399d4f228ecd760845",
            "4460f66ee1d94d1f9ca596ff0ba992e8",
            "64b18189c28047fe9bb389e78c63e0d2",
            "01a3a80706374fa5b80a31e70837b04f",
            "39f352fa5f25436384b63331aabc6a35",
            "bdf47fd4010f4f6aa6c370b8c5ac39f3",
            "7b853402b7404163954bf0f84eaddf76",
            "732192e666ff4ce18e206666dd961427"
          ]
        },
        "outputId": "b9162232-9a82-4576-9ec2-26c596f4bd7f"
      },
      "source": [
        "from rouge import Rouge\n",
        "import razdel\n",
        "\n",
        "def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
        "    rouge = Rouge()\n",
        "    sentences_ = []\n",
        "    oracle_sentences_ = []\n",
        "    oracle_summary_ = []\n",
        "    if nrows is not None:\n",
        "        records = records.iloc[:nrows].copy()\n",
        "    else:\n",
        "        records = records.copy()\n",
        "\n",
        "    for text, summary in tqdm(records[['text', 'summary']].values):\n",
        "        summary = summary.lower() if lower else summary\n",
        "        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n",
        "                                                                         lower=lower, max_sentences=max_sentences)\n",
        "        sentences_ += [sentences]\n",
        "        oracle_sentences_ += [list(sentences_indicies)]\n",
        "        oracle_summary_ += [oracle_summary]\n",
        "    records['sentences'] = sentences_\n",
        "    records['oracle_sentences'] = oracle_sentences_\n",
        "    records['oracle_summary'] = oracle_summary_\n",
        "    return records\n",
        "\n",
        "ext_train_records = add_oracle_summary_to_records(train_records, nrows=30000)\n",
        "ext_val_records = add_oracle_summary_to_records(val_records, nrows=None)\n",
        "ext_test_records = add_oracle_summary_to_records(test_records, nrows=None)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning:\n",
            "\n",
            "This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "955f186ebecf4fb69b51deeff5c3e363",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e77aec435e384156b25f055c2f46bef1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5265.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df72cebf277145399d4f228ecd760845",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5770.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzo40GpvunE"
      },
      "source": [
        "Используй `pickle` для сохранения записей, чтобы потом не пересоздавать их потом. Если решаешь задание в колабе, можешь подключить свой гугл диск и сохранить данные в нём."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0UApsVBNPhH",
        "outputId": "1e8f4aac-4e41-4211-91cf-4621582b417a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKLVs38cvunE"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"train_records.bin\", 'wb') as file:\n",
        "    pickle.dump(ext_train_records, file)\n",
        "\n",
        "with open(\"val_records.bin\", 'wb') as file:\n",
        "    pickle.dump(ext_val_records, file)\n",
        "\n",
        "with open(\"test_records.bin\", 'wb') as file:\n",
        "    pickle.dump(ext_test_records, file)    "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr29_WQvNW97"
      },
      "source": [
        "# pickle_train = open(\"/content/drive/MyDrive/train_records.bin\",\"rb\")\n",
        "# pickle_test = open(\"/content/drive/MyDrive/test_records.bin\",\"rb\")\n",
        "# pickle_valid = open(\"/content/drive/MyDrive/val_records.bin\",\"rb\")\n",
        "\n",
        "# ext_test_records  = pickle.load(pickle_test)\n",
        "# ext_val_records = pickle.load(pickle_valid)\n",
        "# ext_train_records = pickle.load(pickle_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXXc8qUHC5m"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код генератора датасета и батчевалки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNyxstTChK3C"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import razdel\n",
        "import torch\n",
        "import numpy as np\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "class ExtDataset(data.Dataset):\n",
        "    def __init__(self, records, vocabulary, bpe_processor, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
        "        self.records = records\n",
        "        self.num_samples = records.shape[0]\n",
        "        self.bpe_processor = bpe_processor\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_sentences = max_sentences\n",
        "        self.max_sentence_length = max_sentence_length\n",
        "        self.device = device\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.records.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cur_record = self.records.iloc[idx]\n",
        "        inputs = list(map(lambda x: x[:self.max_sentence_length], self.bpe_processor.encode(cur_record['sentences'], output_type=yttm.OutputType.ID)))\n",
        "        outputs = [int(i in cur_record['oracle_sentences']) for i in range(len(cur_record['sentences']))]\n",
        "        return {'inputs': inputs, 'outputs': outputs}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvARjudojEDD"
      },
      "source": [
        "# Это батчевалка\n",
        "def collate_fn(records):\n",
        "    max_length = max(len(sentence) for record in records for sentence in record['inputs'])\n",
        "    max_sentences = max(len(record['outputs']) for record in records)\n",
        "\n",
        "    new_inputs = torch.zeros((len(records), max_sentences, max_length))\n",
        "    new_outputs = torch.zeros((len(records), max_sentences))\n",
        "    for i, record in enumerate(records):\n",
        "        for j, sentence in enumerate(record['inputs']):\n",
        "            new_inputs[i, j, :len(sentence)] += np.array(sentence)\n",
        "        new_outputs[i, :len(record['outputs'])] += np.array(record['outputs'])\n",
        "    return {'features': new_inputs.type(torch.LongTensor), 'targets': new_outputs}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWlf7XdheJUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c4a554-ea46-4dc9-b655-b5af3226ae55"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "\n",
        "class YourSentenceEncoder(nn.Module):\n",
        "    # Место для вашего Sentence Encoder-а. Разрешается использовать любые методы, которые вам нравятся.\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding_layer(inputs)\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "\n",
        "        return sentences_embeddings\n",
        "\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 token_embedding_dim=256,\n",
        "                 sentence_encoder_hidden_size=256,\n",
        "                 hidden_size=256,\n",
        "                 bidirectional=True,\n",
        "                 sentence_encoder_n_layers=2,\n",
        "                 sentence_encoder_dropout=0.3,\n",
        "                 sentence_encoder_bidirectional=True,\n",
        "                 n_layers=1,\n",
        "                 dropout=0.3):\n",
        "        super(SentenceTaggerRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Your sentence encoder model\n",
        "        self.sentence_encoder = YourSentenceEncoder(vocabulary_size, token_embedding_dim,\n",
        "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
        "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
        "        \n",
        "        self.rnn_layer = nn.LSTM(\n",
        "            sentence_encoder_hidden_size, \n",
        "            hidden_size, \n",
        "            n_layers, \n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional, \n",
        "            batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        batch_size = inputs.size(0)\n",
        "        sentences_count = inputs.size(1)\n",
        "        tokens_count = inputs.size(2)\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        outputs = self.dropout_layer(outputs)\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "        content = self.content_linear_layer(outputs).squeeze(2)\n",
        "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
        "        return content + salience\n",
        "\n",
        "model = SentenceTaggerRNN(vocabulary.size())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning:\n",
            "\n",
            "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2Gb6ODHHB_"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVDW8raJeQxn"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "loaders = {\n",
        "    'train': data.DataLoader(\n",
        "        ExtDataset(\n",
        "            ext_train_records, \n",
        "            vocabulary, \n",
        "            bpe_processor=bpe_processor\n",
        "        ), \n",
        "        batch_size=64, \n",
        "        collate_fn=collate_fn\n",
        "    ),\n",
        "    'valid': data.DataLoader(\n",
        "        ExtDataset(\n",
        "            ext_val_records, \n",
        "            vocabulary, \n",
        "            bpe_processor=bpe_processor\n",
        "        ), \n",
        "        batch_size=64, \n",
        "        collate_fn=collate_fn\n",
        "    ),\n",
        "    'test': data.DataLoader(\n",
        "        ExtDataset(\n",
        "            ext_test_records, \n",
        "            vocabulary, \n",
        "            bpe_processor=bpe_processor\n",
        "        ), \n",
        "        batch_size=64, \n",
        "        collate_fn=collate_fn\n",
        "    ),\n",
        "}\n",
        "\n",
        "lr = 1e-4\n",
        "num_epochs = 5\n",
        "\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# Maybe adding scheduler?"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGM6-P4MvunF"
      },
      "source": [
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.to(device)\n",
        "    pbar_loader = trange(len(loaders[\"train\"]) + len(loaders[\"valid\"]), desc=f\"Train Loss: {0}, Valid Loss: {0}\")\n",
        "    for e in trange(num_epochs, desc=\"Epoch\"):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "        train_it = 0\n",
        "        valid_it = 0\n",
        "        \n",
        "        model.train()\n",
        "        for batch in loaders[\"train\"]:\n",
        "            features = batch[\"features\"].to(device)\n",
        "            targets = batch[\"targets\"].to(device)\n",
        "            \n",
        "            logits = model(features)\n",
        "            \n",
        "            loss = criterion(logits, targets)\n",
        "            train_loss += loss.item()\n",
        "            train_it += 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Maybe adding scheduler?\n",
        "            \n",
        "            pbar_loader.update()\n",
        "            pbar_loader.set_description(\n",
        "                f\"Train Loss: {train_loss / train_it:.3}, Valid Loss: {0}\"\n",
        "            )\n",
        "            \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in loaders[\"valid\"]:\n",
        "                features = batch[\"features\"].to(device)\n",
        "                targets = batch[\"targets\"].to(device)\n",
        "\n",
        "                logits = model(features)\n",
        "\n",
        "                loss = criterion(logits, targets)\n",
        "                valid_loss += loss.item()\n",
        "                valid_it += 1\n",
        "                \n",
        "                pbar_loader.update()\n",
        "                pbar_loader.set_description(\n",
        "                    f\"Train Loss: {train_loss / train_it:.3},\"\n",
        "                    f\" Valid Loss: {valid_loss / valid_it:.3}\"\n",
        "                )\n",
        "        print(\n",
        "            f\"Epoch {e}; Train Loss: {train_loss / train_it:.3},\"\n",
        "            f\" Valid Loss: {valid_loss / valid_it:.3}\"\n",
        "        )\n",
        "        pbar_loader.reset()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQaTFEh5vunF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "0c8fc1e452a843f397661a38215cea78",
            "4171381ae7fc49398508458217823652",
            "e0bf13c03e9c440a82785e216611e5a7",
            "ed3bf220a2174857abd9be199749ecab",
            "12c83ab0c0e54f30b493ac24e18e6cab",
            "c3ab5d2e388248519bd9bcf0ba7cbb9c",
            "a8497f3aed7f4d7eb3fa7f9356161edf",
            "d98081a1541f4cc285c6b5a05d0a1376",
            "b692dd847a094df6a33fd2b14e9b43ea",
            "0be2609bd0724b059748cbfd4361f910",
            "7e73f596d4994e759ee2bdbe691a3881",
            "046ef077af114e289cad90860327c55b",
            "377c5d46faa94cd4a3b14a7beae47032",
            "2b5138531402495c80267bf28c870a37",
            "18e737d2eb7f44398e4b94fd148c4e9b",
            "a1ea69ffd83148b78f1a47297f8c5dff"
          ]
        },
        "outputId": "fa6a6429-4e4c-4b40-87c7-2ef862efe32d"
      },
      "source": [
        "train()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c8fc1e452a843f397661a38215cea78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Train Loss: 0, Valid Loss: 0', max=552.0, style=ProgressS…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b692dd847a094df6a33fd2b14e9b43ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0; Train Loss: 0.204, Valid Loss: 0.183\n",
            "Epoch 1; Train Loss: 0.189, Valid Loss: 0.181\n",
            "Epoch 2; Train Loss: 0.185, Valid Loss: 0.18\n",
            "Epoch 3; Train Loss: 0.181, Valid Loss: 0.179\n",
            "Epoch 4; Train Loss: 0.178, Valid Loss: 0.179\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwqhK2dyKuGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1b0716-0a7c-46b2-c077-ad6da3384f48"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "top_k = 3\n",
        "\n",
        "def postprocess(ref, hyp, is_multiple_ref=False, detokenize_after=False, tokenize_after=True):\n",
        "    if is_multiple_ref:\n",
        "        reference_sents = ref.split(\" s_s \")\n",
        "        decoded_sents = hyp.split(\"s_s\")\n",
        "        hyp = [w.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").strip() for w in decoded_sents]\n",
        "        ref = [w.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").strip() for w in reference_sents]\n",
        "        hyp = \" \".join(hyp)\n",
        "        ref = \" \".join(ref)\n",
        "    ref = ref.strip()\n",
        "    hyp = hyp.strip()\n",
        "    if detokenize_after:\n",
        "        hyp = punct_detokenize(hyp)\n",
        "        ref = punct_detokenize(ref)\n",
        "    if tokenize_after:\n",
        "        hyp = hyp.replace(\"@@UNKNOWN@@\", \"<unk>\")\n",
        "        hyp = \" \".join([token.text for token in razdel.tokenize(hyp)])\n",
        "        ref = \" \".join([token.text for token in razdel.tokenize(ref)])\n",
        "    return ref, hyp\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "model.eval()\n",
        "for num, batch in enumerate(loaders[\"test\"]):\n",
        "\n",
        "    logits = model(batch[\"features\"].to(device))\n",
        "    in_summary = torch.argsort(logits, dim=1)[:, -top_k:]\n",
        "    for i in range(len(batch['targets'])):\n",
        "\n",
        "        summary = ext_test_records.iloc[i]['summary']\n",
        "        summary = summary.lower()\n",
        "        predicted_summary = ' '.join([ext_test_records.iloc[i]['sentences'][idx] for idx in in_summary[i].sort()[0] if idx < len(ext_test_records.iloc[i]['sentences'])])\n",
        "        summary, predicted_summary = postprocess(summary, predicted_summary)\n",
        "\n",
        "        references.append(summary)\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "calc_scores(references, predictions)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 5770\n",
            "Ref: следователи возбудили дело против жительницы сургута , подозреваемой в убийстве 49-летнего приятеля . по данным регионального ск , 16 декабря женщина , ее возлюбленный и их сожитель устроили застолье — в ходе встречи между предполагаемой злоумышленницей и ее другом возник конфликт . в гневе женщина нанесла ему смертельные ножевые ранения , после чего вместе с любимым спрятала тело в чемодан и позвонила в полицию , сообщив о « находке » .\n",
            "Hyp: жительницу сургута подозревают в убийстве 49-летнего сожителя . по версии ведомства , 16 декабря женщина , ее возлюбленный и другой 49-летний сургутянин вместе выпивали алкоголь в квартире на проспекте мира — на тот момент второй мужчина уже некоторое время проживал с парой . по предварительным данным , подозреваемая планировала вынести чемодан на улицу , однако в итоге самостоятельно позвонила в полицию и сообщила о « находке » .\n",
            "BLEU:  0.4482006046197879\n",
            "ROUGE:  {'rouge-1': {'f': 0.30057638825676386, 'p': 0.28523669319955836, 'r': 0.3355716419539371}, 'rouge-2': {'f': 0.1271869639056966, 'p': 0.11778303569826938, 'r': 0.14889254463419968}, 'rouge-l': {'f': 0.25376088607061137, 'p': 0.2531279313285435, 'r': 0.29725678225327673}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kc0etEGfJ0p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}