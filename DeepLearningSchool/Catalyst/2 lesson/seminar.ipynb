{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "seminar_done.ipynb",
   "provenance": [],
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwRfuC6RDb1B",
    "colab_type": "text"
   },
   "source": [
    "# Seminar 2. PyTorch\n",
    "Hi! Today we are going to study PyTorch. We'll compare numpy and PyTorch commands, rewrite our previous neural network in two ways.\n",
    "\n",
    "!!! GPU ON !!!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ilG0uJwVcke4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!pip install mnist"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cMKPD9TZdokn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7gsxpRimFHF-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7xxXYAeFofM",
    "colab_type": "text"
   },
   "source": [
    "## Numpy vs Pytorch\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kbIPHFs6FmkB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = [1. , 1.4 , 2.5]\n",
    "print(f\"Simple way: {torch.tensor(a)}\")\n",
    "print(f\"Zeros:\\n {torch.zeros((2,3))}\")\n",
    "print(f\"Range: {torch.arange(0, 10)}\")\n",
    "print(f\"Complicated range: {torch.arange(4, 12, 2)}\")\n",
    "print(f\"Space: {torch.linspace(1, 4, 6)}\")\n",
    "print(f\"Identity matrix:\\n {torch.eye(4)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWKCkXaSGK1U",
    "colab_type": "text"
   },
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OHFgnpzOF5yb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(f\"From 0 to 1: {torch.rand(1)}\")\n",
    "print(f\"Vector from 0 to 1: {torch.rand(5)}\")\n",
    "print(f\"Vector from 0 to 10: {torch.randint(10, size=(5,))}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EmP3g0wGfzT",
    "colab_type": "text"
   },
   "source": [
    "### Matrix Operation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KfUdENnEF8-l",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "b = torch.linspace(-10, 10, 10)\n",
    "print(f\"a: {a}\\nshape: {a.size()}\")\n",
    "print(f\"b: {a}\\nshape: {b.size()}\")\n",
    "print(f\"a + b: {a + b},\\n a * b: {a * b}\")\n",
    "print(f\"Dot product: {a.dot(b)}\")\n",
    "print(f\"Mean: {a.mean()}, STD: {a.std()}\")\n",
    "print(f\"Sum: {a.sum()}, Min: {a.min()}, Max: {a.max()}\")\n",
    "print(f\"Reshape:\\n{a.reshape(-1, 1)}\\nshape: {a.reshape(-1, 1).size()}\")\n",
    "c = a.reshape(-1, 1).repeat(1, 5)\n",
    "print(f\"Repeat:\\n{c}\\nshape: {c.size()}\")\n",
    "print(f\"Transpose:\\n{c.T}\\nshape: {c.T.size()}\")\n",
    "print(f\"Unique items: {torch.unique(c)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdhrhXj9H0m6",
    "colab_type": "text"
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHqXM0bQGrRv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.arange(100).reshape(10, 10)\n",
    "print(f\"Array:\\n{a}\\nshape: {a.size()}\")\n",
    "print(f\"Get first column: {a[:, 0]}\")\n",
    "print(f\"Get last row: {a[-1, :]}\")\n",
    "print(f\"Add new awis:\\n{a[:, np.newaxis]}\\nshape: {a[:, np.newaxis].size()}\")\n",
    "print(f\"Specific indexing:\\n{a[4:6, 7:]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFQ0OwEkIHu8",
    "colab_type": "text"
   },
   "source": [
    "### Numpy <-> Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oueWvyMzH6sZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "a.numpy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VRCr6c78QeH1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "b = np.random.normal(size=(2, 4))\n",
    "torch.from_numpy(b)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJyktewrROPL",
    "colab_type": "text"
   },
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JshOGbX0RAb1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "b = torch.normal(mean=torch.zeros(2, 4))\n",
    "print(f\"a:\\n{a}\\nb:\\n{b}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mKUxAfveR6iQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = a.cuda()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "klvLnHmaSDbk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a + b"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "11l9FxZVSEDL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "(a + b.cuda()).cpu()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFkGBACsSmL4",
    "colab_type": "text"
   },
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yr46uuNNSR_U",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "\n",
    "c = torch.dot(a, b)\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\n(a,b): {c}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jmiq2lLnSvO4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "c.backward()\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\n(a,b): {c}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O8I2iLEyS3dU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(f\"Grad a: {a.grad}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFD2nov7UDlf",
    "colab_type": "text"
   },
   "source": [
    "Add function!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-z2P8UECTnEO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "c = torch.ones(1, requires_grad=True)\n",
    "\n",
    "d = torch.sigmoid(torch.dot(a, b) + c)\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\nSigmoid( (a,b) ): {d}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ur_QA6xbTzeG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(f\"Grad a: {a.grad}\\nGrad c: {c.grad}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PsheM7soT6sw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "d.backward()\n",
    "print(f\"Grad a: {a.grad}\\nGrad c: {c.grad}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf9pO1XJUFZI",
    "colab_type": "text"
   },
   "source": [
    "Okay, what about vectors?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ginrHkBT_HC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "\n",
    "c = a * b\n",
    "c.backward()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sNYtrJ3YxV3",
    "colab_type": "text"
   },
   "source": [
    "## Neural Network. Rewind"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_MKsdG6GdorV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "import mnist\n",
    "\n",
    "sns.set()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "waQtAlplIh6N",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "images = mnist.train_images() / 255\n",
    "labels = mnist.train_labels()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(images, labels)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BOHbffeqHyeF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_batches(dataset, batch_size):\n",
    "    X = dataset[0].reshape(-1, 28 * 28)\n",
    "    Y = dataset[1]\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "    \n",
    "        yield torch.FloatTensor(X[batch_idx]), torch.LongTensor(Y[batch_idx])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R402HnG8ULdl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class CustomLinear:\n",
    "    def __init__(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Simple linear layer\n",
    "        \"\"\"\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.w = ...\n",
    "        self.b = ...\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return ...\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.w.grad = None\n",
    "        self.b.grad = None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vzDzCXmtZivn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class CustomNeuralNetwork:\n",
    "    def __init__(self, dims, activation=\"sigmoid\"):\n",
    "        \"\"\"\n",
    "        Simple deep networks, that joins several linear layers. \n",
    "        \"\"\"\n",
    "        self.dims = dims\n",
    "\n",
    "        self.linears = ...\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return ...\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for l in self.linears:\n",
    "            l.zero_grad()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LZtMZC_dbmFS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class CustomCrossEntropy:\n",
    "    def __call__(self, x, target):\n",
    "        return ..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t47gvIlUkFpT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def simple_sgd(model, config):\n",
    "    with torch.no_grad():\n",
    "        for l in model.linears:\n",
    "            l.w -= config['learning_rate'] * l.w.grad\n",
    "            l.b -= config['learning_rate'] * l.b.grad"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4ER9Cs5jaoNi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = CustomNeuralNetwork((28 * 28, 10, 10))\n",
    "criterion = CustomCrossEntropy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gOQeiTU0Jnkr",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "optimizer_config = {\n",
    "    \"learning_rate\": 1e-1\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5nwAo4jfaxry",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train(model, optimizer_config, n_epoch=20, batch_size=256):\n",
    "    train_logs = {\"Train Loss\": [0,], \"Steps\": [0,]}\n",
    "    valid_logs = {\"Valid Loss\": [0,], \"Valid Accuracy\": [0,], \"Steps\": [0,]}\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            simple_sgd(model, optimizer_config)      \n",
    "            \n",
    "            step += 1\n",
    "            train_logs[\"Train Loss\"].append(loss.detach().item())\n",
    "            train_logs[\"Steps\"].append(step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch, np.argmax(predictions.numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "        valid_logs[\"Valid Loss\"].append(sum_loss / count_valid_steps)\n",
    "        valid_logs[\"Valid Accuracy\"].append(sum_acc / count_valid_steps)\n",
    "        valid_logs[\"Steps\"].append(step)\n",
    "\n",
    "        if best_valid_loss > sum_loss / count_valid_steps:\n",
    "            best_valid_loss = sum_loss / count_valid_steps\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    sns.lineplot(x=\"Steps\", y=\"Train Loss\", data=train_logs, ax=ax[0])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Loss\", data=valid_logs, ax=ax[1])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Accuracy\", data=valid_logs, ax=ax[2])\n",
    "    plt.plot()\n",
    "\n",
    "    return best_model, train_logs, valid_logs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ufy_8neBa3hG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net, _, _ = train(net, optimizer_config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWnI3eIEeLZT",
    "colab_type": "text"
   },
   "source": [
    "## Neural Network. Rewind #2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sLgLKCUfcCG3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.w = ...\n",
    "        self.b = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, in_size, alpha=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "\n",
    "        self.beta = ...\n",
    "        self.gamma = ...\n",
    "\n",
    "        self.epsilon = 1e-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_size, out_size, activation=\"sigmoid\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = Linear(in_size, out_size)\n",
    "        self.dropout = Dropout(p)\n",
    "        self.batch_norm = BatchNorm(out_size)\n",
    "        \n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = ...\n",
    "        x = ...\n",
    "        x = ...\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dims, activation=\"relu\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            list(Block(d_0, d_1, activation=activation, p=p) for d_0, d_1 in zip(dims[:-2], dims[1:-1]))\n",
    "        )\n",
    "        self.cl = Linear(dims[-2], dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.blocks:\n",
    "            x = m(x)\n",
    "        return self.cl(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PcqQ6AwPczjI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = Net((28 * 28, 100, 10), p=0.1).cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cZtluygsczgm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o2iqWQojL3J7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train(model, optimizer, n_epoch=20, batch_size=256, device=\"cpu\"):\n",
    "    train_logs = {\"Train Loss\": [0,], \"Steps\": [0,]}\n",
    "    valid_logs = {\"Valid Loss\": [0,], \"Valid Accuracy\": [0,], \"Steps\": [0,]}\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()   \n",
    "            \n",
    "            step += 1\n",
    "            train_logs[\"Train Loss\"].append(loss.detach().item())\n",
    "            train_logs[\"Steps\"].append(step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch.cpu().numpy(), np.argmax(predictions.cpu().numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "            valid_logs[\"Valid Loss\"].append(sum_loss / count_valid_steps)\n",
    "            valid_logs[\"Valid Accuracy\"].append(sum_acc / count_valid_steps)\n",
    "            valid_logs[\"Steps\"].append(step)\n",
    "\n",
    "            if best_valid_loss > sum_loss / count_valid_steps:\n",
    "                best_valid_loss = sum_loss / count_valid_steps\n",
    "                best_model = deepcopy(net)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    sns.lineplot(x=\"Steps\", y=\"Train Loss\", data=train_logs, ax=ax[0])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Loss\", data=valid_logs, ax=ax[1])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Accuracy\", data=valid_logs, ax=ax[2])\n",
    "    plt.plot()\n",
    "\n",
    "    return best_model, train_logs, valid_logs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QDkpB7TtL3IU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net, _, _ = train(net, optimizer, device=\"cuda:0\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcOEa7lcjiyO",
    "colab_type": "text"
   },
   "source": [
    "### Neural Network. Rewind #3. Logging\n",
    "\n",
    "Logging systems:\n",
    "- [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html)\n",
    "- [WandB](https://www.wandb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fjRHFJXSjn81",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_size, out_size, activation=\"relu\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = nn.ReLU\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "net = nn.Sequential(Block(28 * 28, 100, p=0.2), nn.Linear(100, 10)).cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QV1AxNFbfapY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%load_ext tensorboard"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cgo_htQZfamn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4qWa59wKf5Jd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train(model, optimizer, n_epoch=20, batch_size=256, device=\"cpu\"):\n",
    "    writer = SummaryWriter(Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()   \n",
    "            \n",
    "            step += 1\n",
    "            writer.add_scalar(\"Train Loss\", loss.detach().item(), step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch.cpu().numpy(), np.argmax(predictions.cpu().numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "            writer.add_scalar(\"Valid Loss\", sum_loss / count_valid_steps, step)\n",
    "            writer.add_scalar(\"Valid Accuracy\", sum_acc / count_valid_steps, step)\n",
    "\n",
    "            if best_valid_loss > sum_loss / count_valid_steps:\n",
    "                best_valid_loss = sum_loss / count_valid_steps\n",
    "                best_model = deepcopy(net)\n",
    "\n",
    "    return best_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qptL6E_Mf5G5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = train(net, optimizer, device=\"cuda:0\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SuzkIqc0f5FG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%tensorboard --logdir logs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7W1zyKnXFdxt",
    "colab_type": "text"
   },
   "source": [
    "## Spoiler - train loop with [Catalyst](https://github.com/catalyst-team/catalyst)\n",
    "\n",
    "- [A comprehensive step-by-step guide to basic and advanced features](https://github.com/catalyst-team/catalyst#step-by-step-guide)\n",
    "- [Docs](https://catalyst-team.github.io/catalyst/)\n",
    "- [What is Runner?](https://catalyst-team.github.io/catalyst/api/core.html#runner)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Y_cQnMeJJiU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!pip install catalyst"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gm2SIio7f5Cd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from catalyst import dl\n",
    "from catalyst.data.cv import ToTensor\n",
    "from catalyst.contrib.datasets import MNIST\n",
    "from catalyst.utils import metrics\n",
    "\n",
    "net = nn.Sequential(Block(28 * 28, 100, p=0.2), nn.Linear(100, 10))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loaders = {\n",
    "    \"train\": DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=ToTensor()), batch_size=32),\n",
    "    \"valid\": DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=ToTensor()), batch_size=32),\n",
    "}\n",
    "\n",
    "class CustomRunner(dl.Runner):\n",
    "\n",
    "    def predict_batch(self, batch):\n",
    "        # model inference step\n",
    "        return self.model(batch[0].to(self.device).view(batch[0].size(0), -1))\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        # model train/valid step\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x.view(x.size(0), -1))\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        accuracy01, accuracy03 = metrics.accuracy(y_hat, y, topk=(1, 3))\n",
    "        self.batch_metrics.update(\n",
    "            {\"loss\": loss, \"accuracy01\": accuracy01, \"accuracy03\": accuracy03}\n",
    "        )\n",
    "\n",
    "        if self.is_train_loader:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "runner = CustomRunner()\n",
    "runner.train(\n",
    "    model=net,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_epochs=5,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    ")\n",
    "\n",
    "traced_model = runner.trace(loader=loaders[\"valid\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZUz3o_kJJIHe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}