{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_GeneralConversation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAOLBaAj9SLV"
      },
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOau5Fvgzvze"
      },
      "source": [
        "Основано на: https://github.com/DanAnastasyev/DeepNLP-Course Week 13\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u079fXhsY5YO"
      },
      "source": [
        "# General Conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvisrsBNKHXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5361ed-0d00-4595-f42d-0669b8c469eb"
      },
      "source": [
        "!pip install --upgrade pyonmttok gensim torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyonmttok\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/21/7a69fa68de7de41ef70b35424d21523ebf2208f0c0fab1355cabc2305ff4/pyonmttok-1.22.2-cp36-cp36m-manylinux1_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 21.4MB/s \n",
            "\u001b[?25hCollecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Installing collected packages: pyonmttok, gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3 pyonmttok-1.22.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF6jgOYGY4Oy"
      },
      "source": [
        "## Данные для русского\n",
        "\n",
        "* Toloka Persona Chat Rus: https://toloka.yandex.ru/datasets/\n",
        "* Диалоги из литературы: https://github.com/Koziev/NLP_Datasets/blob/master/Conversations/Data/dialogues.zip\n",
        "* Open Subtitles:http://opus.nlpl.eu/OpenSubtitles-v2018.php\n",
        "\n",
        "Будем работать с датасетом Толоки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IwOBZ4BrVkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2866146b-985f-42ab-83c6-3f0e1b5bdbd2"
      },
      "source": [
        "!rm -f TlkPersonaChatRus.zip\n",
        "!rm -rf TlkPersonaChatRus\n",
        "!wget https://tlk.s3.yandex.net/dataset/TlkPersonaChatRus.zip\n",
        "!unzip TlkPersonaChatRus.zip\n",
        "!head -n 5 TlkPersonaChatRus/dialogues.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-22 18:03:23--  https://tlk.s3.yandex.net/dataset/TlkPersonaChatRus.zip\n",
            "Resolving tlk.s3.yandex.net (tlk.s3.yandex.net)... 93.158.134.158, 2a02:6b8::2:158\n",
            "Connecting to tlk.s3.yandex.net (tlk.s3.yandex.net)|93.158.134.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6139432 (5.9M) [application/zip]\n",
            "Saving to: ‘TlkPersonaChatRus.zip’\n",
            "\n",
            "TlkPersonaChatRus.z 100%[===================>]   5.85M  5.48MB/s    in 1.1s    \n",
            "\n",
            "2020-11-22 18:03:25 (5.48 MB/s) - ‘TlkPersonaChatRus.zip’ saved [6139432/6139432]\n",
            "\n",
            "Archive:  TlkPersonaChatRus.zip\n",
            "   creating: TlkPersonaChatRus/\n",
            "  inflating: TlkPersonaChatRus/dialogues.tsv  \n",
            "  inflating: TlkPersonaChatRus/readme_TlkPersonaChatRus.txt  \n",
            "  inflating: TlkPersonaChatRus/profiles.tsv  \n",
            "persona_1_profile\tpersona_2_profile\tdialogue\n",
            "\"<span class=participant_1>У меня любимая работа.<br />Я уважаю людей.<br />У меня есть животное.<br />У меня хороший друг.<br />Я люблю кофе.<br /></span>\"\t\"<span class=participant_2>Ищу принца.<br />Веду активный образ жизни.<br />Люблю читать классику.<br />Выращиваю фиалки.<br />Люблю общение.<br /></span>\"\t\"<span class=participant_2>Пользователь 2: Привет) расскажи о себе</span><br /><span class=participant_1>Пользователь 1: Привет) под вкусный кофеек настроение поболтать появилось<br />)</span><br /><span class=participant_2>Пользователь 2: Что читаешь? Мне нравится классика</span><br /><span class=participant_2>Пользователь 2: Я тоже люблю пообщаться</span><br /><span class=participant_1>Пользователь 1: Люблю животных, просто обожаю, как и свою работу)</span><br /><span class=participant_1>Пользователь 1: Я фантастику люблю</span><br /><span class=participant_2>Пользователь 2: А я выращиваю фиалки</span><br /><span class=participant_2>Пользователь 2: И веду здоровый и активный образ жизни!</span><br /><span class=participant_1>Пользователь 1: Ух ты, интересно.</span><br /><span class=participant_2>Пользователь 2: Ты случайно не принц на белом коне? Я его очень жду<br />..</span><br /><span class=participant_1>Пользователь 1: А у меня из хобби каждую неделю тусить с моим лучшим<br />другом)</span><br />\"\n",
            "\"<span class=participant_1>Я работаю учителем<br />У меня есть собака<br />Я люблю петь<br />Я живу сама<br />Я люблю цветы<br /></span>\"\t\"<span class=participant_2>Я бизнесмен<br />У меня скоро свадьба<br />Меня любят только за деньги<br />Я не люблю людей<br />не люблю тупые опросы<br /></span>\"\t\"<span class=participant_1>Пользователь 1: Привет!</span><br /><span class=participant_2>Пользователь 2: Привет,Как жизнь?</span><br /><span class=participant_1>Пользователь 1: Отлично) Солнышко светит, птички поют!</span><br /><span class=participant_2>Пользователь 2: Я вот сегодня понял, что меня тупо используют, всем<br />нужны от меня лишь деньги, ненавижу людей</span><br /><span class=participant_2>Пользователь 2: Чем занимаешься по жизни, я вот бизнесмен.</span><br /><span class=participant_1>Пользователь 1: А я вот учу детей, работаю с начальными классами</span><br /><span class=participant_1>Пользователь 1: Не все люди такие, как ты говоришь</span><br /><span class=participant_1>Пользователь 1: Помимо работы чем еще ты занимаешься?</span><br /><span class=participant_2>Пользователь 2: К свадьбе готовлюсь</span><br /><span class=participant_2>Пользователь 2: А ты?</span><br /><span class=participant_1>Пользователь 1: Вот видишь) значит, нашел такую женщину, которой не<br />нужны от тебя деньги</span><br /><span class=participant_2>Пользователь 2: Да я надеюсь на это,люблю ее</span><br />\"\n",
            "\"<span class=participant_1>Я купила дом<br />Я бегаю по утрам<br />Я работаю на работе<br />Я поеду в отпуск<br />Я люблю арбуз<br /></span>\"\t\"<span class=participant_2>Я пою в караоке<br />У меня есть супруга<br />Хорошо готовлю пасту<br />Люблю собак<br />Аллергия на кошек<br /></span>\"\t\"<span class=participant_1>Пользователь 1: Привет</span><br /><span class=participant_1>Пользователь 1: Как дела ?</span><br /><span class=participant_2>Пользователь 2: Добрый день!</span><br /><span class=participant_2>Пользователь 2: Хорошо,  чем увлекаетесь?</span><br /><span class=participant_1>Пользователь 1: Я бегаю по утрам а ты?</span><br /><span class=participant_1>Пользователь 1: Есть любимые вещи или еда ?</span><br /><span class=participant_1>Пользователь 1: Занят ?</span><br /><span class=participant_2>Пользователь 2: Я люблю петь в караоке)</span><br /><span class=participant_1>Пользователь 1: Круто )</span><br /><span class=participant_2>Пользователь 2: Люблю готовить пасту,  у меня классно получается!</span><br /><span class=participant_2>Пользователь 2: Любишь готовить?</span><br /><span class=participant_1>Пользователь 1: Это хорошо</span><br /><span class=participant_1>Пользователь 1: Я не эксперт</span><br /><span class=participant_1>Пользователь 1: Я люблю есть арбуз</span><br />\"\n",
            "\"<span class=participant_1>я врач и женат<br />у меня трое детей<br />не люблю свою работу<br />нравиться ездить на велосипеде<br />люблю пиво<br /></span>\"\t\"<span class=participant_2>Я мальчик<br />Я учусь в 6-ом классе<br />Хочу стать гонщиком<br />У меня есть сестра<br />Мечтаю о машине<br /></span>\"\t\"<span class=participant_2>Пользователь 2: Здравствуйте</span><br /><span class=participant_2>Пользователь 2: Я Леша</span><br /><span class=participant_1>Пользователь 1: Здравствуйте</span><br /><span class=participant_1>Пользователь 1: Я Егор</span><br /><span class=participant_2>Пользователь 2: Я учусь в 6 классе</span><br /><span class=participant_1>Пользователь 1: А мне 30 и я уже работаю</span><br /><span class=participant_2>Пользователь 2: А я тоже хочу. На машину скопить.</span><br /><span class=participant_1>Пользователь 1: Правда мне не нравится моя работа</span><br /><span class=participant_2>Пользователь 2: Почему?</span><br /><span class=participant_1>Пользователь 1: Мало платят</span><br /><span class=participant_1>Пользователь 1: На семью не хватает</span><br /><span class=participant_1>Пользователь 1: Жена и трое детей</span><br /><span class=participant_2>Пользователь 2: А... а я на машину...</span><br /><span class=participant_2>Пользователь 2: Ого</span><br />\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfZIA6qpeM05"
      },
      "source": [
        "Парсим HTML, схлопываем подряд идущие реплики одного человека, убираем пометки о номере пользователя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmDpI-YfruVk"
      },
      "source": [
        "import csv\n",
        "import copy\n",
        "from html.parser import HTMLParser\n",
        "\n",
        "class DialogueParser(HTMLParser):\n",
        "    def __init__(self):\n",
        "        HTMLParser.__init__(self)\n",
        "        self.lines = []\n",
        "        self.current_line = \"\"\n",
        "        self.is_line = False\n",
        "\n",
        "    def handle_starttag(self, tag, attrs):\n",
        "        if tag == \"span\":\n",
        "            self.is_line = True\n",
        "\n",
        "    def handle_endtag(self, tag):\n",
        "        if tag == \"span\":\n",
        "            self.lines.append(self.current_line)\n",
        "            self.is_line = False\n",
        "            self.current_line = \"\"\n",
        "\n",
        "    def handle_data(self, data):\n",
        "        if self.is_line:\n",
        "            self.current_line += data\n",
        "    \n",
        "    def pop_dialogue(self):\n",
        "        dialogue = copy.copy(self.lines)\n",
        "        self.lines = []\n",
        "        return dialogue\n",
        "\n",
        "\n",
        "dialogues = []\n",
        "parser = DialogueParser()\n",
        "with open(\"TlkPersonaChatRus/dialogues.tsv\", \"r\") as r:\n",
        "    next(r)\n",
        "    reader = csv.reader(r, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        dialogue = row[2]\n",
        "        dialogue = dialogue.replace(\"<br />\", \" \").replace(\"<br/>\", \" \")\n",
        "        parser.feed(dialogue)\n",
        "        dialogue = parser.pop_dialogue()\n",
        "        if not dialogue:\n",
        "            continue\n",
        "        user1_start = \"Пользователь 1: \"\n",
        "        user2_start = \"Пользователь 2: \"\n",
        "        for line in dialogue:\n",
        "            assert line.startswith(user1_start) or line.startswith(user2_start)\n",
        "\n",
        "        def get_user(line):\n",
        "            return 1 if line.startswith(user1_start) else 2\n",
        "        def clean_line(line):\n",
        "            return line.replace(user1_start, \"\").replace(user2_start, \"\").replace(\"\\n\", \" \").strip()\n",
        "\n",
        "        new_dialogue = []\n",
        "        current_user = get_user(dialogue[0])\n",
        "        current_line = clean_line(dialogue[0])\n",
        "        for line in dialogue[1:]:\n",
        "            user = get_user(line)\n",
        "            line = clean_line(line)\n",
        "            if current_user == user:\n",
        "                current_line += \" \" + line\n",
        "                continue\n",
        "            new_dialogue.append(current_line)\n",
        "            current_line = line\n",
        "            current_user = user\n",
        "        new_dialogue.append(current_line)\n",
        "        dialogues.append(new_dialogue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqwV4-tEwRRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b9274b-1739-4d18-da41-691643dd347a"
      },
      "source": [
        "dialogues[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Привет) расскажи о себе',\n",
              " 'Привет) под вкусный кофеек настроение поболтать появилось )',\n",
              " 'Что читаешь? Мне нравится классика Я тоже люблю пообщаться',\n",
              " 'Люблю животных, просто обожаю, как и свою работу) Я фантастику люблю',\n",
              " 'А я выращиваю фиалки И веду здоровый и активный образ жизни!',\n",
              " 'Ух ты, интересно.',\n",
              " 'Ты случайно не принц на белом коне? Я его очень жду ..',\n",
              " 'А у меня из хобби каждую неделю тусить с моим лучшим другом)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs--X5vWbg4T"
      },
      "source": [
        "Делаем примеры, состоящие из контекста и ответа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRPH0kEewnl8"
      },
      "source": [
        "blocks = []\n",
        "max_context_length = 1\n",
        "max_answer_length = 100\n",
        "for dialogue in dialogues:\n",
        "    for i in range(1, len(dialogue)):\n",
        "        context = tuple(dialogue[max(0, i-max_context_length):i])\n",
        "        answer = dialogue[i]\n",
        "        blocks.append({\"context\": context, \"answer\": answer})\n",
        "blocks = [block for block in blocks if len(block[\"answer\"]) < max_answer_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfTedPl-HOK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0QHh7qSxs5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f47126-3fa8-44c6-d691-e7af0b702962"
      },
      "source": [
        "len(blocks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxH5a-yJbzj9"
      },
      "source": [
        "Разбиваем на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT30jjYzkjH4"
      },
      "source": [
        "import random\n",
        "random.shuffle(blocks)\n",
        "test_part = 0.9\n",
        "border = int(len(blocks) * test_part)\n",
        "train_blocks = blocks[:border]\n",
        "test_blocks = blocks[border:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS020Pyxb-kP"
      },
      "source": [
        "BatchIterator разбивает примеры на батчи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6jKqXyjxU2"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BatchIterator():\n",
        "    def __init__(self, blocks, batch_size, vector_model, tokenizer, shuffle=True):\n",
        "        self.blocks = blocks\n",
        "        self.num_samples = len(blocks)\n",
        "        self.batch_size = batch_size\n",
        "        self.vector_model = vector_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.shuffle = shuffle\n",
        "        self.batches_count = int(math.ceil(len(blocks) / batch_size))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.batches_count\n",
        "    \n",
        "    def __iter__(self):\n",
        "        indices = np.arange(self.num_samples)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, self.num_samples, self.batch_size):\n",
        "            end = min(start + self.batch_size, self.num_samples)\n",
        "            batch_indices = indices[start:end]\n",
        "            pivots = []\n",
        "            positives = []\n",
        "            for data_ind in batch_indices:\n",
        "                block = self.blocks[data_ind]\n",
        "                \n",
        "                pivots.append(block[\"context\"])\n",
        "                positives.append(block[\"answer\"])\n",
        "\n",
        "            yield {\n",
        "                'pivot_lines': pivots,\n",
        "                'positive_lines': positives\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2jzf2YicKhQ"
      },
      "source": [
        "А дальше у нас есть 2 базовых варианта: ранжирующая и порождающая модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs16j-qbcD_9"
      },
      "source": [
        "## Ранжирующая модель\n",
        "\n",
        "Начнём с ранжирующей модели, она во многом проще в реализации. Нужно заранее составить большую базу ответов и просто выбирать наиболее подходящий к контексту каждый раз. \n",
        "\n",
        "![](https://habrastorage.org/web/c79/942/608/c79942608160404ab398033e97283c51.jpg)\n",
        "\n",
        "*From [Neural conversational models: как научить нейронную сеть светской беседе. Лекция в Яндексе](https://habr.com/ru/company/yandex/blog/333912/)*\n",
        "\n",
        "Сеть состоит из пары башен: левая кодирует контекст, правая - ответ. Задача - научиться считать близость между представлениями контекста и ответа.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUMAMonPepbb"
      },
      "source": [
        "Будем брать готовые предобученные векторы с https://rusvectores.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US5ydz-leo7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4baab64e-5e6b-412e-ab71-2c903de00024"
      },
      "source": [
        "!mkdir ru_fasttext\n",
        "!wget http://vectors.nlpl.eu/repository/20/187.zip\n",
        "!mv 187.zip ru_fasttext/187.zip\n",
        "!cd ru_fasttext && unzip 187.zip\n",
        "!rm ru_fasttext/187.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-22 18:05:45--  http://vectors.nlpl.eu/repository/20/187.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2692389554 (2.5G) [application/zip]\n",
            "Saving to: ‘187.zip’\n",
            "\n",
            "187.zip             100%[===================>]   2.51G  25.2MB/s    in 1m 44s  \n",
            "\n",
            "2020-11-22 18:07:30 (24.7 MB/s) - ‘187.zip’ saved [2692389554/2692389554]\n",
            "\n",
            "Archive:  187.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.model             \n",
            "  inflating: model.model.vectors_ngrams.npy  \n",
            "  inflating: model.model.vectors.npy  \n",
            "  inflating: model.model.vectors_vocab.npy  \n",
            "  inflating: README                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UQXDHHEey5N"
      },
      "source": [
        "import gensim\n",
        "import pyonmttok\n",
        "\n",
        "vector_model = gensim.models.KeyedVectors.load(\"ru_fasttext/model.model\")\n",
        "tokenizer = pyonmttok.Tokenizer(\"conservative\", joiner_annotate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCObsXR1d_Zn"
      },
      "source": [
        "train_iter = BatchIterator(train_blocks, 64, vector_model, tokenizer)\n",
        "test_iter = BatchIterator(test_blocks, 64, vector_model, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQwGw4WOeCr9"
      },
      "source": [
        "for batch in train_iter:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-scw7_SeWm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd07e46-5944-4d48-bab3-cd774e672a75"
      },
      "source": [
        "batch['pivot_lines'][:3], batch['positive_lines'][:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Не люблю вообще. А вредную еду кушаешь?',),\n",
              "  ('Здраствуйте',),\n",
              "  ('У меня 4 собаки,многовато ,но я их люблю',)],\n",
              " ['Конечно, обожаю фастфуд А ты?',\n",
              "  'Привет! Я с краснодарского края! Хочу свою пасеку',\n",
              "  'Вот вы любите рыбалку ? Я например очень люблю рыбалку'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9duNDyHe0LM"
      },
      "source": [
        "Для бейзлайна архитектура башен максимально простая: cat(avg, min, max) по всем пословным векторам и умножение на матрицу. Матрицы разные для башен контекста и ответа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImvPFl1HgqdZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class WordVectorEncoder(nn.Module):\n",
        "    def __init__(self, vector_model, tokenizer):\n",
        "        super().__init__()\n",
        "        self.vector_model = vector_model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = str(text).strip().replace(\"\\n\", \" \").replace(\"\\xa0\", \" \").lower() # \\xa0 - это неразрывный пробел.\n",
        "        tokens, _ = self.tokenizer.tokenize(text)\n",
        "        return tokens\n",
        "    \n",
        "    def to_matrix(self, lines):\n",
        "        batch_size = len(lines)\n",
        "        tokens = [self.tokenize(line) for line in lines]\n",
        "        max_sen_len = max([len(line) for line in tokens])\n",
        "        vector_size = self.vector_model.vector_size\n",
        "\n",
        "        matrix = np.zeros((batch_size, max_sen_len, vector_size))\n",
        "        for i, line in enumerate(tokens):\n",
        "            for j, token in enumerate(line):\n",
        "                matrix[i, j, :] = self.vector_model.get_vector(token)\n",
        "\n",
        "        return torch.cuda.FloatTensor(matrix)\n",
        "        #return torch.FloatTensor(matrix)\n",
        "\n",
        "class NaiveEncoder(WordVectorEncoder):\n",
        "    def __init__(self, vector_model, tokenizer, embedding_dim=300, output_dim=300):\n",
        "        super().__init__(vector_model, tokenizer)\n",
        "        self.mapping_layer = nn.Linear(embedding_dim * 3, output_dim).cuda()\n",
        "\n",
        "    def forward(self, lines):\n",
        "        in_vectors = self.to_matrix(lines)\n",
        "        norm = in_vectors.norm(p=2, dim=1, keepdim=True)\n",
        "        in_vectors = in_vectors.div(norm)\n",
        "\n",
        "        avg_vectors = torch.mean(in_vectors, dim=1)\n",
        "        max_vectors = torch.max(in_vectors, dim=1)[0]\n",
        "        min_vectors = torch.min(in_vectors, dim=1)[0]\n",
        "\n",
        "        projections = self.mapping_layer(torch.cat([avg_vectors, max_vectors, min_vectors], dim=1))\n",
        "        norm = projections.norm(p=2, dim=1, keepdim=True)\n",
        "        projections = projections.div(norm)\n",
        "        return projections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-KaTegnferj"
      },
      "source": [
        "В самой модели применяем 2 трюка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRC3Jrsgfh0f"
      },
      "source": [
        "### Triplet Loss\n",
        "\n",
        "Мы хотим не просто научить энкодер строить эмбеддинги для предложений. Мы хотим, чтобы притягивать векторы правильных ответов к вопросам и отталкивать неправильные. Для этого используют, например, *Triplet Loss*:\n",
        "\n",
        "$$ L = \\frac 1N \\underset {q, a^+, a^-} \\sum max(0, \\space \\delta - sim[V_q(q), V_a(a^+)] + sim[V_q(q), V_a(a^-)] ),$$\n",
        "\n",
        "где\n",
        "* $sim[a, b]$ функция похожести (например, dot product или cosine similarity)\n",
        "* $\\delta$ - гиперпараметр модели. Если $sim[a, b]$ линейно по $b$, то все $\\delta > 0$ эквиватентны.\n",
        "\n",
        "![img](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/margin.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swXGvQ0mfzgS"
      },
      "source": [
        "### Hard-negatives mining\n",
        "\n",
        "Берём в качестве отрицательного примера самый близкий из неправильных примеров в батче:\n",
        "$$a^-_{hard} = \\underset {a^-} {argmax} \\space sim[V_q(q), V_a(a^-)]$$\n",
        "\n",
        "Неправильные в данном случае - все, кроме правильного :)\n",
        "\n",
        "Реализуется это как-то так:\n",
        "* Батч состоит из правильных пар.\n",
        "* Для всех контекстов и всех ответов считаем эмбеддинги.\n",
        "* Положительные примеры у нас есть - осталось найти для каждого контекста наиболее похожие на него ответы, которые предназначались другим контекстам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEvH3Ey5falF"
      },
      "source": [
        "class DSSMTripletLoss(nn.Module):\n",
        "    def __init__(self, vector_model, tokenizer, embedding_dim=300, hidden_dim=300, margin=0.1):\n",
        "        super().__init__()\n",
        "        self.left_encoder = NaiveEncoder(vector_model, tokenizer, embedding_dim, hidden_dim)\n",
        "        self.right_encoder = NaiveEncoder(vector_model, tokenizer, embedding_dim, hidden_dim)\n",
        "        self.similarity = nn.CosineSimilarity(dim=1)\n",
        "        self.margin = margin\n",
        "\n",
        "    def apply(self, pivot_lines, positive_lines, hard_negatives_part=0.0):\n",
        "        pivots = self.left_encoder(pivot_lines)\n",
        "        positives = self.right_encoder(positive_lines)\n",
        "\n",
        "        batch_size = pivots.size(0)\n",
        "        shift = random.randint(1, batch_size - 1)\n",
        "\n",
        "        negative_indices = torch.LongTensor([(i + shift) % batch_size for i in range(batch_size)])\n",
        "        negatives = positives[negative_indices]\n",
        "\n",
        "        return pivots, positives, negatives\n",
        "    \n",
        "    def calc_recall_at_1(self, pivots, positives, negatives):\n",
        "        batch_size = pivots.size(0)\n",
        "\n",
        "        scores = pivots.matmul(positives.transpose(0, 1))\n",
        "        predicted_indices = torch.argmax(scores, dim=1)\n",
        "\n",
        "        true_indices = torch.linspace(0, batch_size-1, steps=batch_size)\n",
        "        correct_count = torch.sum(predicted_indices.cpu() == true_indices).item()\n",
        "        return correct_count\n",
        "\n",
        "    def forward(self, pivots, positives, negatives):\n",
        "\n",
        "        distance = -self.similarity(pivots, positives) + self.similarity(pivots, negatives) + self.margin\n",
        "        loss = torch.mean(torch.max(distance, torch.zeros_like(distance)))\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def left_apply(self, lines):\n",
        "        return self.left_encoder(lines)\n",
        "  \n",
        "    def right_apply(self, lines):\n",
        "        return self.right_encoder(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4D0LiLjM-I"
      },
      "source": [
        "class ModelTrainer():\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        return '{:>5s} Loss = {:.5f}, Recall@1 = {:.2%}'.format(\n",
        "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
        "        )\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        pivot_lines = batch['pivot_lines']\n",
        "        positive_lines = batch['positive_lines']\n",
        "        pivot_lines = [\" \".join(context) for context in pivot_lines]\n",
        "        #loss\n",
        "        pivots, positives, negatives = self.model.apply(pivot_lines, positive_lines)\n",
        "        loss = self.model(pivots, positives, negatives)\n",
        "        #predicts\n",
        "        self.correct_count += self.model.calc_recall_at_1(pivots, positives, negatives)\n",
        "        self.total_count += len(pivot_lines)\n",
        "        self.epoch_loss += loss.item()\n",
        "        \n",
        "        if self.is_train:\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), 1.)\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return '{:>5s} Loss = {:.5f}, Recall@1 = {:.2%}'.format(\n",
        "            self.name, loss.item(), self.correct_count / self.total_count\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-DS0q1PjRED"
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(trainer, data_iter, is_train, name=None):\n",
        "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=len(data_iter)) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                batch_progress = trainer.on_batch(batch)\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(batch_progress)\n",
        "                \n",
        "            epoch_progress = trainer.on_epoch_end()\n",
        "            progress_bar.set_description(epoch_progress)\n",
        "            progress_bar.refresh()\n",
        "\n",
        "            \n",
        "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
        "        \n",
        "        if val_iter is not None:\n",
        "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmake6ysdrHU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "DEVICE = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaOaSx9RjjsX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "59d97f4b-0f90-4bc9-c2cb-93454793fbd5"
      },
      "source": [
        "import torch.optim as optim\n",
        "model = DSSMTripletLoss(vector_model, tokenizer)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "#collect all\n",
        "trainer = ModelTrainer(model, optimizer)\n",
        "fit(trainer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 0.06849, Recall@1 = 7.94%: 100%|██████████| 1944/1944 [00:53<00:00, 36.31it/s]\n",
            "[1 / 30]   Val: Loss = 0.06259, Recall@1 = 9.25%: 100%|██████████| 216/216 [00:05<00:00, 42.11it/s]\n",
            "[2 / 30] Train: Loss = 0.06100, Recall@1 = 10.20%: 100%|██████████| 1944/1944 [00:53<00:00, 36.32it/s]\n",
            "[2 / 30]   Val: Loss = 0.05906, Recall@1 = 11.19%: 100%|██████████| 216/216 [00:05<00:00, 41.78it/s]\n",
            "[3 / 30] Train: Loss = 0.05846, Recall@1 = 11.17%: 100%|██████████| 1944/1944 [00:53<00:00, 36.23it/s]\n",
            "[3 / 30]   Val: Loss = 0.06006, Recall@1 = 10.93%: 100%|██████████| 216/216 [00:05<00:00, 41.43it/s]\n",
            "[4 / 30] Train: Loss = 0.05638, Recall@1 = 11.82%: 100%|██████████| 1944/1944 [00:53<00:00, 36.36it/s]\n",
            "[4 / 30]   Val: Loss = 0.05806, Recall@1 = 11.73%: 100%|██████████| 216/216 [00:05<00:00, 41.54it/s]\n",
            "[5 / 30] Train: Loss = 0.05513, Recall@1 = 12.33%: 100%|██████████| 1944/1944 [00:53<00:00, 36.38it/s]\n",
            "[5 / 30]   Val: Loss = 0.05627, Recall@1 = 12.46%: 100%|██████████| 216/216 [00:05<00:00, 41.46it/s]\n",
            "[6 / 30] Train: Loss = 0.05393, Recall@1 = 12.73%: 100%|██████████| 1944/1944 [00:54<00:00, 35.98it/s]\n",
            "[6 / 30]   Val: Loss = 0.05662, Recall@1 = 12.24%: 100%|██████████| 216/216 [00:05<00:00, 41.01it/s]\n",
            "[7 / 30] Train: Loss = 0.05303, Recall@1 = 12.94%: 100%|██████████| 1944/1944 [00:53<00:00, 36.26it/s]\n",
            "[7 / 30]   Val: Loss = 0.05624, Recall@1 = 11.75%: 100%|██████████| 216/216 [00:05<00:00, 41.74it/s]\n",
            "[8 / 30] Train: Loss = 0.05189, Recall@1 = 13.41%: 100%|██████████| 1944/1944 [00:53<00:00, 36.30it/s]\n",
            "[8 / 30]   Val: Loss = 0.05637, Recall@1 = 12.84%: 100%|██████████| 216/216 [00:05<00:00, 41.48it/s]\n",
            "[9 / 30] Train: Loss = 0.05118, Recall@1 = 13.56%: 100%|██████████| 1944/1944 [00:53<00:00, 36.47it/s]\n",
            "[9 / 30]   Val: Loss = 0.05630, Recall@1 = 12.92%: 100%|██████████| 216/216 [00:05<00:00, 41.29it/s]\n",
            "[10 / 30] Train: Loss = 0.05359, Recall@1 = 13.71%:   7%|▋         | 134/1944 [00:03<00:49, 36.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2ce7ff3a6ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#collect all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-71b022f80836>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(trainer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-71b022f80836>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(trainer, data_iter, is_train, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mbatch_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-4a7129f7ae6c>\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpivot_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpivot_lines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpivots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#predicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-47bdc69fb2d3>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, pivot_lines, positive_lines, hard_negatives_part)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_negatives_part\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpivots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpositives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0dbca90ffd30>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0min_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0min_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0dbca90ffd30>\u001b[0m in \u001b[0;36mto_matrix\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmax_sen_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0dbca90ffd30>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmax_sen_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0dbca90ffd30>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\xa0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# \\xa0 - это неразрывный пробел.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO7v2X63EUhI"
      },
      "source": [
        "answers = [block[\"answer\"] for block in blocks]\n",
        "answers = list(set(answers))\n",
        "random.shuffle(answers)\n",
        "answers = answers[:50000]\n",
        "answers_embeddings = model.right_apply(answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p-z7odbkzBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32288858-9b6c-4a8d-e00f-6e969da4b9d9"
      },
      "source": [
        "answers_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RAR3UBL1LOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "af93a96d-8266-4392-857a-5ffe4924f6cb"
      },
      "source": [
        "similarity = nn.CosineSimilarity(dim=1)\n",
        "conversation = []\n",
        "while True:\n",
        "    user_text = input()\n",
        "    conversation.append(user_text)\n",
        "    conversation = conversation[-max_context_length:]\n",
        "\n",
        "    left_embedding = model.left_apply([\" \".join(conversation)])\n",
        "    left_embeddings = left_embedding.expand(answers_embeddings.size(0), answers_embeddings.size(1))\n",
        "\n",
        "    scores = similarity(left_embeddings, answers_embeddings)\n",
        "    answer = answers[torch.argmax(scores, dim=0)]\n",
        "    print(answer)\n",
        "    conversation.append(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Привет\n",
            "Привет привет)\n",
            "Как дела?\n",
            "Как отлично все клубнично А ваши как дела?\n",
            "У меня отлично тоже\n",
            "Да, у меня все хорошо Работаю учителем А ваша профессия какая?\n",
            "Повар\n",
            "Я повар\n",
            "Пока\n",
            "😉 Пока пока\n",
            "Как зовут?\n",
            "Привет! Все отлично, как твои дела? Меня зовут Марина , а твоё имя как?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5873a9fecf1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0muser_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mconversation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmax_context_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIROaw6wFBIa"
      },
      "source": [
        "## Seq2Seq\n",
        "А в этом варианте просто берём модельку от машинного перевода и адаптируем её под предсказание ответа"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nms-ihmAuamd"
      },
      "source": [
        "<img src=\"https://www.pvsm.ru/images/2017/07/22/Neural-conversational-models-kak-nauchit-neironnuyu-set-svetskoi-besede-lekciya-v-yandekse-10.jpg\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEjaBoEjF-LB"
      },
      "source": [
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.index2word = list()\n",
        "        self.word2index = dict()\n",
        "        self.word2count = Counter()\n",
        "        self.reset()\n",
        "\n",
        "    def get_pad(self):\n",
        "        return self.word2index[\"<pad>\"]\n",
        "\n",
        "    def get_sos(self):\n",
        "        return self.word2index[\"<sos>\"]\n",
        "\n",
        "    def get_eos(self):\n",
        "        return self.word2index[\"<eos>\"]\n",
        "\n",
        "    def get_unk(self):\n",
        "        return self.word2index[\"<unk>\"]\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.strip().split():\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = len(self.index2word)\n",
        "            self.word2count[word] += 1\n",
        "            self.index2word.append(word)\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    \n",
        "    def has_word(self, word) -> bool:\n",
        "        return word in self.word2index\n",
        "\n",
        "    def add_file(self, filename: str):\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as r:\n",
        "            for line in r:\n",
        "                for word in line.strip().split():\n",
        "                    self.add_word(word)\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        return self.get_unk()\n",
        "\n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def is_empty(self):\n",
        "        empty_size = 4\n",
        "        return self.size() <= empty_size\n",
        "\n",
        "    def shrink(self, n):\n",
        "        best_words = self.word2count.most_common(n)\n",
        "        self.reset()\n",
        "        for word, count in best_words:\n",
        "            self.add_word(word)\n",
        "            self.word2count[word] = count\n",
        "\n",
        "    def reset(self):\n",
        "        self.word2count = Counter()\n",
        "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "        self.word2index = {word: index for index, word in enumerate(self.index2word)}\n",
        "\n",
        "    def get_indices(self, sentence: str) -> List[int]:\n",
        "        return [self.get_index(word) for word in sentence.strip().split()] + [self.get_eos()]\n",
        "\n",
        "    def pad_indices(self, indices: List[int], max_length: int):\n",
        "        return indices + [self.get_pad() for _ in range(max_length - len(indices))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIcD2Ek5GCcI"
      },
      "source": [
        "vocabulary = Vocabulary()\n",
        "for dialogue in dialogues:\n",
        "    for line in dialogue:\n",
        "        text = line.strip().replace(\"\\n\", \" \").replace(\"\\xa0\", \" \").lower()\n",
        "        tokens, _ = tokenizer.tokenize(text)\n",
        "        for token in tokens:\n",
        "            vocabulary.add_word(token)\n",
        "vocabulary.shrink(20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPy9oL_Uot3d"
      },
      "source": [
        "<img src=\"https://www.pvsm.ru/images/2017/07/22/Neural-conversational-models-kak-nauchit-neironnuyu-set-svetskoi-besede-lekciya-v-yandekse-12.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGNbGcrJovk3"
      },
      "source": [
        "$$\\operatorname{PMI}(x, y) \\equiv \\log \\frac{p(x, y)}{p(x) p(y)}$$\n",
        "---------\n",
        "$$ - \\operatorname{Loss}(x, y, a) = \\log {p(y \\mid \\text x)}-a \\log {p(y)} $$\n",
        "---------\n",
        "$$ - \\operatorname{Loss}(x, y, 1) = \\log {p(y \\mid \\text x)} - \\log {p(y)} = \\log \\frac{p(x, y)}{p(x) p(y)} =  \\operatorname{PMI}(x, y)$$\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1b2Z1uow1NA"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://www.pvsm.ru/images/2017/07/22/Neural-conversational-models-kak-nauchit-neironnuyu-set-svetskoi-besede-lekciya-v-yandekse-13.jpg\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4FlOeebFe_h"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, input_seqs, hidden=None):\n",
        "        embedded = self.embedding(input_seqs)\n",
        "        outputs, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            n = hidden[0].size(0)\n",
        "            hidden = (torch.cat([hidden[0][0:n:2], hidden[0][1:n:2]], 2),\n",
        "                      torch.cat([hidden[1][0:n:2], hidden[1][1:n:2]], 2))\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        assert inputs.size(1) == self.hidden_size\n",
        "        return self.sm(self.out(inputs))\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_size, output_size, max_length, n_layers=3, \n",
        "                 dropout=0.3, use_cuda=True, use_attention=True):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.use_cuda = use_cuda\n",
        "        self.max_length = max_length\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        \n",
        "        if self.use_attention:\n",
        "            self.attn = nn.Linear(embedding_dim, hidden_size)\n",
        "            self.attn_sm = nn.Softmax(dim=1)\n",
        "            self.attn_ctx = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
        "            self.attn_tanh = nn.Tanh()\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout)\n",
        "        self.generator = Generator(hidden_size, output_size)\n",
        "        \n",
        "    def step(self, batch_input, hidden, encoder_output):\n",
        "        # batch_input: B\n",
        "        # hidden: (n_layers x B x N, n_layers x B x N)\n",
        "        # encoder_output: L x B x N\n",
        "        # output: 1 x B x N\n",
        "        # embedded:  B x E\n",
        "        # attn_weights: B x 1 x L\n",
        "        # context: B x 1 x N\n",
        "        # rnn_input: B x N\n",
        "        \n",
        "        embedded = self.embedding(batch_input)\n",
        "        _, hidden = self.rnn(embedded.unsqueeze(0), hidden)\n",
        "        if self.use_attention:\n",
        "            mapped_encoder_outputs = self.attn(encoder_output)\n",
        "            h_t = hidden[0][-1].unsqueeze(2)\n",
        "            mapped_encoder_outputs = mapped_encoder_outputs.transpose(0, 1)\n",
        "            attn_weights = self.attn_sm(torch.bmm(mapped_encoder_outputs, h_t)).transpose(1, 2)\n",
        "            max_length = encoder_output.size(0)\n",
        "            context = torch.bmm(attn_weights[:, :, :max_length], encoder_output.transpose(0, 1))\n",
        "            output = self.attn_tanh(self.attn_ctx(torch.cat((context, h_t.transpose(1, 2)), 2)))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_state(self, batch_size, sos_index):\n",
        "        initial_input = Variable(torch.zeros((batch_size,)).type(torch.LongTensor), requires_grad=False)\n",
        "        initial_input = torch.add(initial_input, sos_index)\n",
        "        initial_input = initial_input.cuda() if self.use_cuda else initial_input\n",
        "        return initial_input\n",
        "\n",
        "    def forward(self, current_input, hidden, length, encoder_output, gtruth=None):\n",
        "        outputs = Variable(torch.zeros(length, current_input.size(0), self.output_size), requires_grad=False)\n",
        "        outputs = outputs.cuda() if self.use_cuda else outputs\n",
        "\n",
        "        for t in range(length):\n",
        "            output, hidden = self.step(current_input, hidden, encoder_output)\n",
        "            scores = self.generator.forward(output.squeeze(1))\n",
        "            outputs[t] = scores\n",
        "            if gtruth is None:\n",
        "                top_indices = scores.topk(1, dim=1)[1].view(-1)\n",
        "                current_input = top_indices\n",
        "            else:\n",
        "                current_input = gtruth[t]\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocabulary, embedding_dim=100,\n",
        "                 rnn_size=100, encoder_n_layers=2, \n",
        "                 decoder_n_layers=2, dropout=0.3,\n",
        "                 max_length=50, use_cuda=True, \n",
        "                 bidirectional=True, use_attention=True):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.vocabulary = vocabulary\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.output_size = vocabulary.size()\n",
        "        self.rnn_size = rnn_size\n",
        "        self.encoder_n_layers = encoder_n_layers\n",
        "        self.decoder_n_layers = decoder_n_layers\n",
        "        self.dropout = dropout\n",
        "        self.max_length = max_length\n",
        "        self.use_cuda = use_cuda\n",
        "        self.bidirectional = bidirectional\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        self.encoder = EncoderRNN(self.output_size, embedding_dim, rnn_size, dropout=dropout,\n",
        "                                  n_layers=encoder_n_layers, bidirectional=bidirectional)\n",
        "        self.decoder = DecoderRNN(embedding_dim, rnn_size, self.output_size, dropout=dropout,\n",
        "                                  max_length=max_length, n_layers=decoder_n_layers, use_cuda=use_cuda, \n",
        "                                  use_attention=use_attention)\n",
        "\n",
        "    def forward(self, variable, sos_index, gtruth=None):\n",
        "        encoder_output, encoder_hidden = self.encoder.forward(variable)\n",
        "        current_input = self.decoder.init_state(variable.size(1), sos_index)\n",
        "        max_length = self.max_length\n",
        "        if gtruth is not None:\n",
        "            max_length = min(self.max_length, gtruth.size(0))\n",
        "        decoder_output, _ = self.decoder.forward(current_input, encoder_hidden, max_length,\n",
        "                                                 encoder_output, gtruth)\n",
        "\n",
        "        return encoder_output, decoder_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc6RV_N_HPOt"
      },
      "source": [
        "def index(vocabulary, line):\n",
        "    line = line.strip().replace(\"\\n\", \" \").replace(\"\\xa0\", \" \").lower()\n",
        "    tokens, _ = tokenizer.tokenize(line)\n",
        "    return [vocabulary.get_index(token) for token in tokens]\n",
        "\n",
        "def to_matrix(lines, vocabulary):\n",
        "    indices = [index(vocabulary, line) for line in lines]\n",
        "    max_len = max([len(line) for line in indices])\n",
        "    matrix = np.zeros((len(indices), max_len))\n",
        "    for i, line in enumerate(indices):\n",
        "        matrix[i, :len(line)] = line\n",
        "    return torch.cuda.LongTensor(matrix)\n",
        "\n",
        "class Seq2SeqModelTrainer():\n",
        "    def __init__(self, model, optimizer, vocabulary):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = nn.NLLLoss()\n",
        "        self.vocabulary = vocabulary\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        return '{:>5s} Loss = {:.5f}'.format(self.name, self.epoch_loss / self.batches_count)\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        pivot_lines = batch['pivot_lines']\n",
        "        positive_lines = batch['positive_lines']\n",
        "        pivot_lines = [\" \".join(context) for context in pivot_lines]\n",
        "\n",
        "        input_matrix = to_matrix(pivot_lines, self.vocabulary).transpose(0, 1)\n",
        "        output_matrix = to_matrix(positive_lines, self.vocabulary).transpose(0, 1)\n",
        "        _, output = self.model.forward(input_matrix, self.vocabulary.get_sos(), output_matrix)\n",
        "        loss = self.criterion(output.transpose(1, 2), output_matrix)\n",
        "        self.epoch_loss += loss.item()\n",
        "        \n",
        "        if self.is_train:\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), 1.)\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return '{:>5s} Loss = {:.5f}'.format(self.name, loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScPs4bl1KhtN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "544cead9-5e2a-4236-b05d-4f58fbcda63d"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = Seq2Seq(vocabulary).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "#collect all\n",
        "trainer = Seq2SeqModelTrainer(model, optimizer, vocabulary)\n",
        "train_iter = BatchIterator(train_blocks, 64, vector_model, tokenizer)\n",
        "test_iter = BatchIterator(test_blocks, 64, vector_model, tokenizer)\n",
        "fit(trainer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 2.13105: 100%|██████████| 1944/1944 [04:49<00:00,  6.71it/s]\n",
            "[1 / 30]   Val: Loss = 1.89710: 100%|██████████| 216/216 [00:18<00:00, 11.90it/s]\n",
            "[2 / 30] Train: Loss = 2.01168:  45%|████▍     | 866/1944 [02:09<02:41,  6.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e394255c913f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-71b022f80836>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(trainer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-71b022f80836>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(trainer, data_iter, is_train, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mbatch_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-15defe0aa384>\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAUaIs98rJah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b1cb89c0-a39f-467c-e9a6-349eedbda6b3"
      },
      "source": [
        "while True:\n",
        "    user_text = input()\n",
        "    input_matrix = to_matrix([user_text], vocabulary).transpose(0, 1)\n",
        "    model.eval()\n",
        "    _, output = model(input_matrix, model.vocabulary.get_sos())\n",
        "\n",
        "    answer_idx = output.argmax(dim=2).cpu().numpy().ravel()\n",
        "    print(' '.join(vocabulary.get_word(idx) for idx in answer_idx if idx != vocabulary.get_pad()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Привет\n",
            "привет ! как дела ?\n",
            "Хорошо\n",
            "отлично , а ты ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-0d2478f35739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNYbbyLxxOtt"
      },
      "source": [
        "<img src=\"https://www.pvsm.ru/images/2017/07/22/Neural-conversational-models-kak-nauchit-neironnuyu-set-svetskoi-besede-lekciya-v-yandekse-20.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2x9-j4oz08p"
      },
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Курс Дани Анастасьева\n",
        "https://github.com/DanAnastasyev/DeepNLP-Course\n",
        "\n",
        "## Статьи\n",
        "* Learning Deep Structured Semantic Models for Web Search using Clickthrough Data, 2013 [[pdf]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf)  \n",
        "* Deep Learning and Continuous Representations for Natural Language Processing, Microsoft tutorial, 2016 [[pdf]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/NAACL-HLT-2015_tutorial.pdf)\n",
        "* Neural Utterance Ranking Model for Conversational Dialogue Systems, 2016 [[pdf]](https://www.aclweb.org/anthology/W16-3648.pdf)\n",
        "* A Persona-Based Neural Conversation Model, 2016 [[pdf]](https://www.aclweb.org/anthology/P16-1094.pdf)\n",
        "\n",
        "## Блоги\n",
        "* [Neural conversational models: как научить нейронную сеть светской беседе](https://habr.com/company/yandex/blog/333912/)  \n",
        "* [Искусственный интеллект в поиске. Как Яндекс научился применять нейронные сети, чтобы искать по смыслу, а не по словам](https://habr.com/company/yandex/blog/314222/)  \n",
        "* [Triplet loss, Olivier Moindrot](https://omoindrot.github.io/triplet-loss)\n",
        "* [Triplet loss in pytorch](https://discuss.pytorch.org/t/triplet-loss-in-pytorch/30634/3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0lOW1BkMUbo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}