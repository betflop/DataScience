{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_GoalOriented.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nIJt4hPLPYtO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMhIlxWLddNU"
      },
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2POVHVpWnlb"
      },
      "source": [
        "Основано на: https://github.com/DanAnastasyev/DeepNLP-Course Week 12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEkFqrLGz0ms"
      },
      "source": [
        "# GoalOriented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4WlMyJVRkzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8320306d-c6ef-4e8d-a46e-40b71b121320"
      },
      "source": [
        "!git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
        "!wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SlotGated-SLU'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Total 51 (delta 0), reused 0 (delta 0), pack-reused 51\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvJKy3mtVOpw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "DEVICE = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QR5dTAfVhLD"
      },
      "source": [
        "# Диалоговые системы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fox5ub_GKSLL"
      },
      "source": [
        "Диалоговые системы делятся на два типа - *goal-orientied* и *general conversation*.\n",
        "\n",
        "**General conversation** - это болталка, разговор на свободную тему:  \n",
        "<img src=\"https://i.ibb.co/bFwwGpc/alice.jpg\" width=\"200\"/>\n",
        "\n",
        "Сегодня будем говорить не про них, а про **goal-orientied** системы:\n",
        "\n",
        "<img src=\"https://hsto.org/webt/gj/3y/xl/gj3yxlqbr7ujuqr9r2akacxmkee.jpeg\" width=\"600\"/>\n",
        "\n",
        "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
        "\n",
        "Пользователь говорит что-то, это что-то распознается. По распознанному определяется - что, где и когда он хотел. Дальше диалоговый движок решает, действительно ли пользователь знает, чего хотел попросить. Происходит поход в источники - узнать информацию, которую (кажется) запросил пользователь. Исходя из всего этого генерируется некоторый ответ:\n",
        "\n",
        "<img src=\"https://i.ibb.co/8XcdpJ7/goal-orientied.png\" width=\"600\"/>\n",
        "\n",
        "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
        "\n",
        "Будем учить ту часть, которая посередине - классификатор и теггер. Всё остальное обычно - эвристики и захардкоженные ответы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIJt4hPLPYtO"
      },
      "source": [
        "## Данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUZ8xjG_PT7C"
      },
      "source": [
        "Есть условно стандартный датасет - atis, который неприлично маленький, на самом деле.\n",
        "\n",
        "К нему можно взять еще датасет snips - он больше и разнообразнее.\n",
        "\n",
        "Оба датасета возьмем из репозитория статьи [Slot-Gated Modeling for Joint Slot Filling and Intent Prediction](http://aclweb.org/anthology/N18-2118).\n",
        "\n",
        "Начнем с atis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw_FnOVOVgdX"
      },
      "source": [
        "import os \n",
        "\n",
        "def read_dataset(path):\n",
        "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
        "            open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
        "            open(os.path.join(path, 'label')) as f_intents:\n",
        "        \n",
        "        return [\n",
        "            (words.strip().split(), tags.strip().split(), intent.strip()) \n",
        "            for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrAgjAFVWnh9"
      },
      "source": [
        "train_data = read_dataset('SlotGated-SLU/data/atis/train/') + read_dataset('SlotGated-SLU/data/snips/train/')\n",
        "val_data = read_dataset('SlotGated-SLU/data/atis/valid/') + read_dataset('SlotGated-SLU/data/snips/valid/')\n",
        "test_data = read_dataset('SlotGated-SLU/data/atis/test/') + read_dataset('SlotGated-SLU/data/snips/test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3zvT5BsWv0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24a3514-8beb-48d0-82b4-36a56e86e7c1"
      },
      "source": [
        "intent_to_example = {example[2]: example for example in train_data}\n",
        "for example in intent_to_example.values():\n",
        "    print('Intent:\\t', example[2])\n",
        "    print('Text:\\t', '\\t'.join(example[0]))\n",
        "    print('Tags:\\t', '\\t'.join(example[1]))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intent:\t atis_flight\n",
            "Text:\t is\tthere\ta\tdelta\tflight\tfrom\tdenver\tto\tsan\tfrancisco\n",
            "Tags:\t O\tO\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
            "\n",
            "Intent:\t atis_airfare\n",
            "Text:\t what\tis\tthe\tmost\texpensive\tone\tway\tfare\tfrom\tboston\tto\tatlanta\ton\tamerican\tairlines\n",
            "Tags:\t O\tO\tO\tB-cost_relative\tI-cost_relative\tB-round_trip\tI-round_trip\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\n",
            "\n",
            "Intent:\t atis_airline\n",
            "Text:\t list\tairlines\tserving\tbetween\tdenver\tand\tsan\tfrancisco\n",
            "Tags:\t O\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
            "\n",
            "Intent:\t atis_ground_service\n",
            "Text:\t tell\tme\tabout\tground\ttransportation\tbetween\torlando\tinternational\tand\torlando\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
            "\n",
            "Intent:\t atis_quantity\n",
            "Text:\t how\tmany\tairlines\thave\tflights\twith\tservice\tclass\tyn\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-fare_basis_code\n",
            "\n",
            "Intent:\t atis_city\n",
            "Text:\t where\tis\tlester\tpearson\tairport\n",
            "Tags:\t O\tO\tB-airport_name\tI-airport_name\tI-airport_name\n",
            "\n",
            "Intent:\t atis_flight#atis_airfare\n",
            "Text:\t all\tflights\tand\tfares\tfrom\tatlanta\tto\tdallas\tround\ttrip\tafter\t12\tpm\tless\tthan\t1100\tdollars\n",
            "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tB-round_trip\tI-round_trip\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tB-cost_relative\tO\tB-fare_amount\tI-fare_amount\n",
            "\n",
            "Intent:\t atis_abbreviation\n",
            "Text:\t what\tis\tfare\tcode\tm\n",
            "Tags:\t O\tO\tO\tO\tB-fare_basis_code\n",
            "\n",
            "Intent:\t atis_aircraft\n",
            "Text:\t i\twant\tto\tgo\tand\ttake\ta\tplane\tin\tatlanta\tand\tfly\tto\tboston\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tO\tO\tB-toloc.city_name\n",
            "\n",
            "Intent:\t atis_distance\n",
            "Text:\t how\tfar\tis\tit\tfrom\torlando\tairport\tto\torlando\n",
            "Tags:\t O\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
            "\n",
            "Intent:\t atis_ground_fare\n",
            "Text:\t what\tare\tthe\trental\tcar\trates\tin\tdallas\n",
            "Tags:\t O\tO\tO\tB-transport_type\tI-transport_type\tO\tO\tB-city_name\n",
            "\n",
            "Intent:\t atis_capacity\n",
            "Text:\t what\tis\tthe\tseating\tcapacity\tof\ta\tboeing\t767\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-aircraft_code\n",
            "\n",
            "Intent:\t atis_flight_time\n",
            "Text:\t what\ttimes\tdoes\tcontinental\tdepart\tfrom\tboston\tto\tsan\tfrancisco\n",
            "Tags:\t O\tB-flight_time\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
            "\n",
            "Intent:\t atis_meal\n",
            "Text:\t what\tare\tall\tthe\tavailable\tmeals\n",
            "Tags:\t O\tO\tO\tO\tO\tB-meal\n",
            "\n",
            "Intent:\t atis_aircraft#atis_flight#atis_flight_no\n",
            "Text:\t i\twant\tto\tfly\tfrom\tdetroit\tto\tst.\tpetersburg\ton\tnorthwest\tairlines\tand\tleave\taround\t9\tam\ttell\tme\twhat\taircraft\tare\tused\tby\tthis\tflight\tand\ttell\tme\tthe\tflight\tnumber\n",
            "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
            "\n",
            "Intent:\t atis_flight_no\n",
            "Text:\t i'm\ttrying\tto\tfind\tthe\tflight\tnumber\tfrom\ta\tflight\tfrom\torlando\tto\tcleveland\ton\tus\tair\tand\tit\tarrives\taround\t10\tpm\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tO\tB-arrive_time.time_relative\tB-arrive_time.time\tI-arrive_time.time\n",
            "\n",
            "Intent:\t atis_restriction\n",
            "Text:\t what\tis\trestriction\tap80\n",
            "Tags:\t O\tO\tO\tB-restriction_code\n",
            "\n",
            "Intent:\t atis_airport\n",
            "Text:\t what's\tthe\tname\tof\tthe\tdenver\tairport\n",
            "Tags:\t O\tO\tO\tO\tO\tB-airport_name\tI-airport_name\n",
            "\n",
            "Intent:\t atis_airline#atis_flight_no\n",
            "Text:\t airline\tand\tflight\tnumber\tfrom\tcolumbus\tto\tminneapolis\n",
            "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\n",
            "\n",
            "Intent:\t atis_cheapest\n",
            "Text:\t show\tme\tthe\tcheapest\tfare\tin\tthe\tdatabase\n",
            "Tags:\t O\tO\tO\tB-cost_relative\tO\tO\tO\tO\n",
            "\n",
            "Intent:\t atis_ground_service#atis_ground_fare\n",
            "Text:\t what\tground\ttransportation\tis\tavailable\tfrom\tthe\tpittsburgh\tairport\tto\tdowntown\tand\thow\tmuch\tdoes\tit\tcost\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tO\tO\tO\tO\tO\tO\tO\n",
            "\n",
            "Intent:\t PlayMusic\n",
            "Text:\t play\tfunky\theavy\tbluesy\n",
            "Tags:\t O\tB-playlist\tI-playlist\tI-playlist\n",
            "\n",
            "Intent:\t AddToPlaylist\n",
            "Text:\t add\tgabrial\tmcnair\tto\tmy\tlove\tin\tparis\tlist\n",
            "Tags:\t O\tB-artist\tI-artist\tO\tB-playlist_owner\tB-playlist\tI-playlist\tI-playlist\tO\n",
            "\n",
            "Intent:\t RateBook\n",
            "Text:\t rate\trichard\tcarvel\t4\tout\tof\t6\n",
            "Tags:\t O\tB-object_name\tI-object_name\tB-rating_value\tO\tO\tB-best_rating\n",
            "\n",
            "Intent:\t SearchScreeningEvent\n",
            "Text:\t can\ti\tget\tthe\tmovie\tschedule\tfor\tloews\tcineplex\tentertainment\n",
            "Tags:\t O\tO\tO\tO\tB-object_type\tI-object_type\tO\tB-location_name\tI-location_name\tI-location_name\n",
            "\n",
            "Intent:\t BookRestaurant\n",
            "Text:\t i\twant\tto\teat\tchoucroute\tat\ta\tbrasserie\tfor\t8\n",
            "Tags:\t O\tO\tO\tO\tB-served_dish\tO\tO\tB-restaurant_type\tO\tB-party_size_number\n",
            "\n",
            "Intent:\t GetWeather\n",
            "Text:\t tell\tme\twhen\tit\tll\tbe\tchillier\tin\tcavalero\tcorner\tid\n",
            "Tags:\t O\tO\tO\tO\tO\tO\tB-condition_temperature\tO\tB-city\tI-city\tB-state\n",
            "\n",
            "Intent:\t SearchCreativeWork\n",
            "Text:\t go\tto\tthe\tphotograph\tthe\tinflated\ttear\n",
            "Tags:\t O\tO\tO\tB-object_type\tB-object_name\tI-object_name\tI-object_name\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EoT_us7Y23P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f382da99-4a2e-4585-c6b2-4718fd6bcaac"
      },
      "source": [
        "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
        "\n",
        "tokens_field = Field()\n",
        "tags_field = Field(unk_token=None)\n",
        "intent_field = LabelField()\n",
        "\n",
        "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
        "\n",
        "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
        "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
        "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
        "\n",
        "tokens_field.build_vocab(train_dataset)\n",
        "tags_field.build_vocab(train_dataset)\n",
        "intent_field.build_vocab(train_dataset)\n",
        "\n",
        "print('Vocab size =', len(tokens_field.vocab))\n",
        "print('Tags count =', len(tags_field.vocab))\n",
        "print('Intents count =', len(intent_field.vocab))\n",
        "\n",
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
        "    shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size = 11804\n",
            "Tags count = 192\n",
            "Intents count = 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHL9kt5UCFi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d516f518-a4ec-44ce-ce92-c5bc93dbbb6d"
      },
      "source": [
        "print('Num train batch =', len(train_iter))\n",
        "print('Num val batch =', len(val_iter))\n",
        "print('Num test batch =', len(test_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num train batch = 549\n",
            "Num val batch = 10\n",
            "Num test batch = 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0p0NlWheamv"
      },
      "source": [
        "## LSTM-pytorch(напоминание)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxuyRTEPejN2"
      },
      "source": [
        "batch_first=False<br>\n",
        "hidden - [num_layers * num_direction, batch_size, hid_dim]<br>\n",
        "output - [len_seq, batch_size, hid_dim * num_direction]<br>\n",
        "<br>\n",
        "batch_first=True<br>\n",
        "hidden - [num_layers * num_direction, batch_size, hid_dim]<br>\n",
        "output - [batch_size, len_seq, hid_dim * num_direction]<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx8tY7_xQIpi"
      },
      "source": [
        "## Классификатор интентов\n",
        "\n",
        "Начнем с классификатора: к какому интенту относится данный запрос.\n",
        "\n",
        "Ничего умного - берём rnn'ку и учимся предсказывать метки-интенты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4pZR9IRckK-"
      },
      "source": [
        "class IntentClassifierModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, emb_dim=64,\n",
        "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True)\n",
        "        self.out_layer = nn.Linear(lstm_hidden_dim * 2, intents_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        projections = self.embeddings_layer(inputs)\n",
        "        _, (final_hidden_state, _) = self.lstm_layer(projections)\n",
        "        # cat final_hidden_state\n",
        "        hidden = self.dropout(torch.cat([final_hidden_state[0], final_hidden_state[1]], dim=1))\n",
        "\n",
        "        output = self.out_layer(hidden)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI3IraPvod_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3126f8b3-6144-4d9a-e3e0-3bfa514f379a"
      },
      "source": [
        "model = IntentClassifierModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
        "for x in train_iter:\n",
        "    break\n",
        "print(x.tokens.shape)\n",
        "print(x.intent.shape)\n",
        "model(x.tokens.transpose(0, 1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 32])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f847ofCFQsly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837016db-084d-4058-95a2-433ba4e128f3"
      },
      "source": [
        "!pip install colorama\n",
        "from colorama import Fore, Style"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfKFMfeg_RLV"
      },
      "source": [
        "class ModelTrainer():\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.correct_count, self.total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self, is_train):\n",
        "        if is_train:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Accuracy = {:.2%}{}'.format(\n",
        "                Fore.RED, self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count, Style.RESET_ALL\n",
        "            )\n",
        "        else:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Accuracy = {:.2%}{}'.format(\n",
        "                Fore.GREEN, self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count, Style.RESET_ALL\n",
        "            )\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        logits = self.model(batch.tokens.transpose(0, 1))\n",
        "\n",
        "        # loss\n",
        "        loss = self.criterion(logits, batch.intent)\n",
        "        # predicts\n",
        "        predicted_intent = logits.argmax(dim=1)\n",
        "        self.total_count += predicted_intent.size(0)\n",
        "        self.correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
        "        if self.is_train:\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "        self.epoch_loss += loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqCvQEByddtj"
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(trainer, data_iter, is_train, name=None):\n",
        "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                batch_progress = trainer.on_batch(batch)\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(batch_progress)\n",
        "\n",
        "            epoch_progress = trainer.on_epoch_end(is_train)\n",
        "            progress_bar.set_description(epoch_progress)\n",
        "            progress_bar.refresh()\n",
        "\n",
        "            \n",
        "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBsP8SHhjqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed38e4d-83d2-4fce-94e4-b5a554dd9da9"
      },
      "source": [
        "model = IntentClassifierModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#collect all\n",
        "trainer = ModelTrainer(model, criterion, optimizer)\n",
        "fit(trainer, train_iter, epochs_count=10, val_iter=val_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[1 / 10] Train: Loss = 0.55999, Accuracy = 85.79%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 114.84it/s]\n",
            "\u001b[32m[1 / 10]   Val: Loss = 0.32010, Accuracy = 91.33%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 153.52it/s]\n",
            "\u001b[31m[2 / 10] Train: Loss = 0.17612, Accuracy = 95.32%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 118.86it/s]\n",
            "\u001b[32m[2 / 10]   Val: Loss = 0.19864, Accuracy = 94.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 163.03it/s]\n",
            "\u001b[31m[3 / 10] Train: Loss = 0.10052, Accuracy = 97.37%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.40it/s]\n",
            "\u001b[32m[3 / 10]   Val: Loss = 0.17302, Accuracy = 95.75%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 148.90it/s]\n",
            "\u001b[31m[4 / 10] Train: Loss = 0.06026, Accuracy = 98.44%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 115.37it/s]\n",
            "\u001b[32m[4 / 10]   Val: Loss = 0.16303, Accuracy = 96.25%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 151.14it/s]\n",
            "\u001b[31m[5 / 10] Train: Loss = 0.03737, Accuracy = 99.11%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 115.05it/s]\n",
            "\u001b[32m[5 / 10]   Val: Loss = 0.17019, Accuracy = 96.58%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 153.30it/s]\n",
            "\u001b[31m[6 / 10] Train: Loss = 0.02925, Accuracy = 99.23%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 116.54it/s]\n",
            "\u001b[32m[6 / 10]   Val: Loss = 0.13321, Accuracy = 97.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 168.09it/s]\n",
            "\u001b[31m[7 / 10] Train: Loss = 0.01698, Accuracy = 99.60%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 117.08it/s]\n",
            "\u001b[32m[7 / 10]   Val: Loss = 0.12405, Accuracy = 97.08%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 133.74it/s]\n",
            "\u001b[31m[8 / 10] Train: Loss = 0.01159, Accuracy = 99.72%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 117.29it/s]\n",
            "\u001b[32m[8 / 10]   Val: Loss = 0.12300, Accuracy = 96.92%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 147.82it/s]\n",
            "\u001b[31m[9 / 10] Train: Loss = 0.01248, Accuracy = 99.69%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.15it/s]\n",
            "\u001b[32m[9 / 10]   Val: Loss = 0.16533, Accuracy = 96.58%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 161.97it/s]\n",
            "\u001b[31m[10 / 10] Train: Loss = 0.00401, Accuracy = 99.93%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 118.97it/s]\n",
            "\u001b[32m[10 / 10]   Val: Loss = 0.15305, Accuracy = 96.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 156.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxHshnyZjMuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366a1ecd-283b-4331-8847-88a64cbc631a"
      },
      "source": [
        "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTest: Loss = 0.26252, Accuracy = 94.16%\u001b[0m: 100%|██████████| 13/13 [00:00<00:00, 154.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zsAJJCEQ8Ti"
      },
      "source": [
        "## Теггер\n",
        "\n",
        "![](https://commons.bmstu.wiki/images/0/00/NER1.png)  \n",
        "*From [NER](https://ru.bmstu.wiki/NER_(Named-Entity_Recognition)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUZ1Wmw1a-Qo"
      },
      "source": [
        "#### **Задание 1.1**\n",
        "Напишите простой теггер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwphVxmdkChy"
      },
      "source": [
        "class TokenTaggerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, tags_count, emb_dim=64,\n",
        "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True)\n",
        "        self.out_layer = nn.Linear(lstm_hidden_dim * 2, tags_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings_layer(inputs)\n",
        "        output, _ = self.lstm_layer(projections)\n",
        "\n",
        "        output = self.out_layer(self.dropout(output))\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bfBgpv11_YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929c9fa7-183d-4400-b7cc-0dbf1a010727"
      },
      "source": [
        "model = TokenTaggerModel(vocab_size=len(tokens_field.vocab), tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "for x in train_iter:\n",
        "    break\n",
        "print(x.tokens.shape)\n",
        "print(x.tags.shape)\n",
        "model(x.tokens.transpose(0, 1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18, 32])\n",
            "torch.Size([18, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 18, 192])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mzyxM0502wy"
      },
      "source": [
        "#### **Задание 1.2**\n",
        "Обновите `ModelTrainer`: считать нужно всё те же лосс и accuracy, только теперь немного по-другому."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMRwby_NnyvJ"
      },
      "source": [
        "class TagModelTrainer():\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.correct_count, self.total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self, is_train):\n",
        "        if is_train:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Accuracy = {:.2%}{}'.format(\n",
        "                Fore.RED, self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count, Style.RESET_ALL\n",
        "            )\n",
        "        else:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Accuracy = {:.2%}{}'.format(\n",
        "                Fore.GREEN, self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count, Style.RESET_ALL\n",
        "            )\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        logits = self.model(batch.tokens.transpose(0, 1))\n",
        "        #loss\n",
        "        true_tags = batch.tags.transpose(0, 1)\n",
        "        loss = self.criterion(logits.transpose(1, 2), true_tags)\n",
        "        #predicts\n",
        "        predicted_tags = logits.argmax(dim=2)\n",
        "        self.correct_count += torch.sum(true_tags == predicted_tags).item() - torch.sum(true_tags == 0).item()\n",
        "        self.total_count += torch.sum(true_tags != 0).item()\n",
        "        if self.is_train:\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "        self.epoch_loss += loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QXaapt3nuF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068413f4-6149-473d-ec96-28202c2a0713"
      },
      "source": [
        "model = TokenTaggerModel(vocab_size=len(tokens_field.vocab), tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#collect all\n",
        "trainer = TagModelTrainer(model, criterion, optimizer)\n",
        "fit(trainer, train_iter, epochs_count=10, val_iter=val_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[1 / 10] Train: Loss = 0.77032, Accuracy = 68.60%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 118.83it/s]\n",
            "\u001b[32m[1 / 10]   Val: Loss = 0.23957, Accuracy = 84.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 147.13it/s]\n",
            "\u001b[31m[2 / 10] Train: Loss = 0.24152, Accuracy = 87.24%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 117.75it/s]\n",
            "\u001b[32m[2 / 10]   Val: Loss = 0.14454, Accuracy = 90.65%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 145.17it/s]\n",
            "\u001b[31m[3 / 10] Train: Loss = 0.15128, Accuracy = 91.63%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 117.45it/s]\n",
            "\u001b[32m[3 / 10]   Val: Loss = 0.10156, Accuracy = 92.15%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 150.84it/s]\n",
            "\u001b[31m[4 / 10] Train: Loss = 0.10950, Accuracy = 93.90%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.60it/s]\n",
            "\u001b[32m[4 / 10]   Val: Loss = 0.08291, Accuracy = 94.06%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 150.99it/s]\n",
            "\u001b[31m[5 / 10] Train: Loss = 0.08215, Accuracy = 95.35%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.04it/s]\n",
            "\u001b[32m[5 / 10]   Val: Loss = 0.07692, Accuracy = 94.86%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 155.68it/s]\n",
            "\u001b[31m[6 / 10] Train: Loss = 0.06301, Accuracy = 96.48%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 120.74it/s]\n",
            "\u001b[32m[6 / 10]   Val: Loss = 0.06892, Accuracy = 95.30%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 148.52it/s]\n",
            "\u001b[31m[7 / 10] Train: Loss = 0.05052, Accuracy = 97.19%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 118.89it/s]\n",
            "\u001b[32m[7 / 10]   Val: Loss = 0.06620, Accuracy = 95.46%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 139.93it/s]\n",
            "\u001b[31m[8 / 10] Train: Loss = 0.03900, Accuracy = 97.85%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.15it/s]\n",
            "\u001b[32m[8 / 10]   Val: Loss = 0.06010, Accuracy = 96.03%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 150.33it/s]\n",
            "\u001b[31m[9 / 10] Train: Loss = 0.03085, Accuracy = 98.31%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 119.86it/s]\n",
            "\u001b[32m[9 / 10]   Val: Loss = 0.06039, Accuracy = 95.74%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 151.88it/s]\n",
            "\u001b[31m[10 / 10] Train: Loss = 0.02447, Accuracy = 98.73%\u001b[0m: 100%|██████████| 549/549 [00:04<00:00, 118.29it/s]\n",
            "\u001b[32m[10 / 10]   Val: Loss = 0.06287, Accuracy = 96.09%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 154.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6spi0nfWA6uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcded6b-6041-46ac-cbc5-b852d5e3e78e"
      },
      "source": [
        "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTest: Loss = 0.08637, Accuracy = 95.22%\u001b[0m: 100%|██████████| 13/13 [00:00<00:00, 154.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeXWjs7pE35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080a887e-7a67-46d3-a196-d02c97c65d35"
      },
      "source": [
        "from conlleval import evaluate\n",
        "\n",
        "def eval_tagger(model, test_iter):\n",
        "    true_seqs, pred_seqs = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iter:\n",
        "            pred = model.forward(batch.tokens.transpose(0, 1)).transpose(1, 2).argmax(dim=1).cpu().tolist()\n",
        "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
        "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in batch.tags.transpose(0, 1).cpu().tolist()])\n",
        "\n",
        "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
        "\n",
        "eval_tagger(model, test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 88.01%, Recall = 89.83%, F1 = 88.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APcntGZ0ReXl"
      },
      "source": [
        "## Multi-task learning\n",
        "\n",
        "Реализуем модель, которая умеет сразу и предсказывать теги и интенты. Идея в том, что в этом всем есть общая информация, которая должна помочь как одной, так и другой задаче: зная интент, можно понять, какие слоты вообще могут быть, а зная слоты, можно угадать и интент."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkWuh_QMbeOM"
      },
      "source": [
        "#### **Задание 2.1**\n",
        "Реализуйте объединенную модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goLcDk-Tu0uM"
      },
      "source": [
        "class SharedModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=300,\n",
        "                 lstm_hidden_dim=256, num_layers=2, dropout_p=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        self.lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True)\n",
        "        self.out_layer_intent = nn.Linear(2 * lstm_hidden_dim, intents_count)\n",
        "        self.out_layer_tags = nn.Linear(2 * lstm_hidden_dim, tags_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings_layer(inputs)\n",
        "        output, (hidden, _) = self.lstm_layer(projections)\n",
        "        hidden = torch.cat([hidden[0], hidden[1]], dim=1)\n",
        "\n",
        "        intent_output = self.out_layer_intent(self.dropout(hidden))\n",
        "        tags_output = self.out_layer_tags(self.dropout(output))\n",
        "        \n",
        "        return tags_output, intent_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvLAm2_VxAlU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2722d3-49ea-435f-8f47-b9f4420c3a2b"
      },
      "source": [
        "model = SharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
        "                    tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "\n",
        "for x in train_iter:\n",
        "    break\n",
        "print(x.tokens.shape)\n",
        "print(x.intent.shape)\n",
        "print(x.tags.shape)\n",
        "tags_output, intent_output = model(x.tokens.transpose(0, 1))\n",
        "tags_output.shape, intent_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([17, 32])\n",
            "torch.Size([32])\n",
            "torch.Size([17, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 17, 192]), torch.Size([32, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz2A9hHybrWZ"
      },
      "source": [
        "#### **Задание 2.2**\n",
        "Допишите SharedModelTrainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5semraSfv56f"
      },
      "source": [
        "class SharedModelTrainer():\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.tags_correct_count, self.tags_total_count = 0, 0\n",
        "        self.intent_correct_count, self.intent_total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self, is_train):\n",
        "        if is_train:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}{}'.format(\n",
        "                Fore.RED, self.name, self.epoch_loss / self.batches_count, self.tags_correct_count / self.tags_total_count, self.intent_correct_count / self.intent_total_count,\\\n",
        "                Style.RESET_ALL\n",
        "            )\n",
        "        else:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}{}'.format(\n",
        "                Fore.GREEN, self.name, self.epoch_loss / self.batches_count, self.tags_correct_count / self.tags_total_count, self.intent_correct_count / self.intent_total_count,\\\n",
        "                Style.RESET_ALL\n",
        "            )\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        tags_logits, intent_logits = self.model(batch.tokens.transpose(0, 1))\n",
        "        true_tags = batch.tags.transpose(0, 1)\n",
        "        true_intent = batch.intent\n",
        "\n",
        "        #loss\n",
        "        tags_loss = self.criterion(tags_logits.transpose(1, 2), true_tags)\n",
        "        intent_loss = self.criterion(intent_logits, true_intent)\n",
        "        loss = tags_loss + intent_loss\n",
        "\n",
        "        #predicts\n",
        "        predicted_tags = tags_logits.argmax(axis=2)\n",
        "        predicted_intent = intent_logits.argmax(axis=1)\n",
        "\n",
        "        self.tags_correct_count += torch.sum(true_tags == predicted_tags).item() - torch.sum(true_tags == 0).item()\n",
        "        self.tags_total_count += torch.sum(true_tags != 0).item()\n",
        "        self.intent_correct_count += torch.sum(true_intent == predicted_intent).item()\n",
        "        self.intent_total_count += true_intent.size(0)\n",
        "\n",
        "        if self.is_train:\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "        self.epoch_loss += loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BP4b-4zxU0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0df7fc-9966-49ba-e1bd-2ae7a938cf4b"
      },
      "source": [
        "model = SharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
        "                    tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#collect all\n",
        "trainer = SharedModelTrainer(model, criterion, optimizer)\n",
        "fit(trainer, train_iter, epochs_count=20, val_iter=val_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[1 / 20] Train: Loss = 0.81605, Tags accuracy = 78.42%, Intents accuracy = 91.70%\u001b[0m: 100%|██████████| 549/549 [00:06<00:00, 80.83it/s]\n",
            "\u001b[32m[1 / 20]   Val: Loss = 0.27999, Tags accuracy = 91.95%, Intents accuracy = 95.75%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 102.38it/s]\n",
            "\u001b[31m[2 / 20] Train: Loss = 0.17738, Tags accuracy = 93.94%, Intents accuracy = 98.02%\u001b[0m: 100%|██████████| 549/549 [00:06<00:00, 82.24it/s]\n",
            "\u001b[32m[2 / 20]   Val: Loss = 0.16572, Tags accuracy = 94.85%, Intents accuracy = 97.58%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 98.76it/s] \n",
            "\u001b[31m[3 / 20] Train: Loss = 0.08127, Tags accuracy = 96.94%, Intents accuracy = 99.28%\u001b[0m: 100%|██████████| 549/549 [00:06<00:00, 79.60it/s]\n",
            "\u001b[32m[3 / 20]   Val: Loss = 0.13905, Tags accuracy = 95.95%, Intents accuracy = 97.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 99.00it/s] \n",
            "\u001b[31m[4 / 20] Train: Loss = 0.04059, Tags accuracy = 98.43%, Intents accuracy = 99.73%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.96it/s]\n",
            "\u001b[32m[4 / 20]   Val: Loss = 0.14471, Tags accuracy = 96.01%, Intents accuracy = 97.67%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 99.85it/s] \n",
            "\u001b[31m[5 / 20] Train: Loss = 0.02143, Tags accuracy = 99.17%, Intents accuracy = 99.89%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.17it/s]\n",
            "\u001b[32m[5 / 20]   Val: Loss = 0.13743, Tags accuracy = 96.16%, Intents accuracy = 98.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 105.25it/s]\n",
            "\u001b[31m[6 / 20] Train: Loss = 0.01199, Tags accuracy = 99.51%, Intents accuracy = 99.97%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.91it/s]\n",
            "\u001b[32m[6 / 20]   Val: Loss = 0.14062, Tags accuracy = 96.46%, Intents accuracy = 98.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 104.74it/s]\n",
            "\u001b[31m[7 / 20] Train: Loss = 0.00908, Tags accuracy = 99.68%, Intents accuracy = 99.94%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 75.92it/s]\n",
            "\u001b[32m[7 / 20]   Val: Loss = 0.14136, Tags accuracy = 96.43%, Intents accuracy = 97.75%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 101.29it/s]\n",
            "\u001b[31m[8 / 20] Train: Loss = 0.01088, Tags accuracy = 99.68%, Intents accuracy = 99.90%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.35it/s]\n",
            "\u001b[32m[8 / 20]   Val: Loss = 0.15006, Tags accuracy = 96.18%, Intents accuracy = 97.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 87.21it/s]\n",
            "\u001b[31m[9 / 20] Train: Loss = 0.01897, Tags accuracy = 99.59%, Intents accuracy = 99.68%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 74.04it/s]\n",
            "\u001b[32m[9 / 20]   Val: Loss = 0.16743, Tags accuracy = 95.99%, Intents accuracy = 97.92%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 99.55it/s] \n",
            "\u001b[31m[10 / 20] Train: Loss = 0.01353, Tags accuracy = 99.65%, Intents accuracy = 99.86%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 73.81it/s]\n",
            "\u001b[32m[10 / 20]   Val: Loss = 0.15613, Tags accuracy = 96.41%, Intents accuracy = 97.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 98.89it/s]\n",
            "\u001b[31m[11 / 20] Train: Loss = 0.00702, Tags accuracy = 99.73%, Intents accuracy = 99.95%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.98it/s]\n",
            "\u001b[32m[11 / 20]   Val: Loss = 0.16597, Tags accuracy = 96.34%, Intents accuracy = 98.33%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 99.84it/s] \n",
            "\u001b[31m[12 / 20] Train: Loss = 0.00468, Tags accuracy = 99.86%, Intents accuracy = 99.97%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 75.88it/s]\n",
            "\u001b[32m[12 / 20]   Val: Loss = 0.14865, Tags accuracy = 96.48%, Intents accuracy = 98.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 95.40it/s]\n",
            "\u001b[31m[13 / 20] Train: Loss = 0.00247, Tags accuracy = 99.90%, Intents accuracy = 99.99%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 75.59it/s]\n",
            "\u001b[32m[13 / 20]   Val: Loss = 0.19873, Tags accuracy = 96.84%, Intents accuracy = 98.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 103.67it/s]\n",
            "\u001b[31m[14 / 20] Train: Loss = 0.00229, Tags accuracy = 99.92%, Intents accuracy = 99.99%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 74.71it/s]\n",
            "\u001b[32m[14 / 20]   Val: Loss = 0.17089, Tags accuracy = 96.40%, Intents accuracy = 98.33%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 109.03it/s]\n",
            "\u001b[31m[15 / 20] Train: Loss = 0.00581, Tags accuracy = 99.82%, Intents accuracy = 99.93%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 75.76it/s]\n",
            "\u001b[32m[15 / 20]   Val: Loss = 0.18525, Tags accuracy = 96.28%, Intents accuracy = 97.75%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 101.97it/s]\n",
            "\u001b[31m[16 / 20] Train: Loss = 0.01021, Tags accuracy = 99.73%, Intents accuracy = 99.86%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.81it/s]\n",
            "\u001b[32m[16 / 20]   Val: Loss = 0.20640, Tags accuracy = 96.06%, Intents accuracy = 97.75%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 99.46it/s] \n",
            "\u001b[31m[17 / 20] Train: Loss = 0.00514, Tags accuracy = 99.80%, Intents accuracy = 99.96%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.76it/s]\n",
            "\u001b[32m[17 / 20]   Val: Loss = 0.16335, Tags accuracy = 96.50%, Intents accuracy = 98.08%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 103.46it/s]\n",
            "\u001b[31m[18 / 20] Train: Loss = 0.00284, Tags accuracy = 99.91%, Intents accuracy = 99.98%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.71it/s]\n",
            "\u001b[32m[18 / 20]   Val: Loss = 0.20341, Tags accuracy = 96.57%, Intents accuracy = 97.92%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 106.69it/s]\n",
            "\u001b[31m[19 / 20] Train: Loss = 0.00178, Tags accuracy = 99.94%, Intents accuracy = 99.99%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.67it/s]\n",
            "\u001b[32m[19 / 20]   Val: Loss = 0.18683, Tags accuracy = 96.27%, Intents accuracy = 98.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 101.91it/s]\n",
            "\u001b[31m[20 / 20] Train: Loss = 0.00383, Tags accuracy = 99.85%, Intents accuracy = 99.97%\u001b[0m: 100%|██████████| 549/549 [00:07<00:00, 76.59it/s]\n",
            "\u001b[32m[20 / 20]   Val: Loss = 0.17140, Tags accuracy = 96.56%, Intents accuracy = 98.58%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 94.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlTbVSOezMD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffea8cef-79c8-426e-f1b9-c884693414cc"
      },
      "source": [
        "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTest: Loss = 0.32141, Tags accuracy = 96.04%, Intents accuracy = 95.98%\u001b[0m: 100%|██████████| 13/13 [00:00<00:00, 106.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-6XO9lsyhJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1f0f19-9294-4f37-b4d9-8a609381b9c0"
      },
      "source": [
        "from conlleval import evaluate\n",
        "\n",
        "def eval_tagger(model, test_iter):\n",
        "    true_seqs, pred_seqs = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iter:\n",
        "            pred = model.forward(batch.tokens.transpose(0, 1))[0].transpose(1, 2).max(dim=1)[1].cpu().tolist()\n",
        "            true = batch.tags.transpose(0, 1).cpu().tolist()\n",
        "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
        "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in true])\n",
        "\n",
        "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
        "\n",
        "eval_tagger(model, test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 90.77%, Recall = 92.08%, F1 = 91.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP2kTm0r5h8A"
      },
      "source": [
        " ## Асинхронное обучение\n",
        "\n",
        "Идея описана в статье [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](http://aclweb.org/anthology/N18-2050).\n",
        "\n",
        "<img src=\"https://i.ibb.co/qrgVSqF/2018-11-27-2-11-17.png\" width=\"600\"/>\n",
        "\n",
        "Основное отличие от того, что уже реализовали в том, в каком порядке все оптимизируется. Вместо объединенного обучения всех слоев, сети для теггера и для классификатора обучаются отдельно.\n",
        "\n",
        "На каждом шаге обучения генерируются последовательности скрытых состояний $h^1$ и $h^2$ - для классификатора и для теггера.\n",
        "\n",
        "Дальше сначала считаются потери от предсказания интента и делается шаг оптимизатора, а затем потери от предсказания теггов - и опять шаг оптимизатора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fadD_b4Lb5PW"
      },
      "source": [
        "#### **Задание 3.1**\n",
        "Реализуйте асинхронное обучение совместной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLlVOYfG-dRY"
      },
      "source": [
        "class AsyncSharedModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=300,\n",
        "                 lstm_hidden_dim=256, num_layers=1, dropout_p=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.inner_lstm_layer_tags = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True, bidirectional=True, num_layers=num_layers)\n",
        "        self.inner_lstm_layer_intent = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True, bidirectional=True, num_layers=num_layers)\n",
        "        \n",
        "        self.outer_lstm_layer_tags = nn.LSTM(lstm_hidden_dim * 4, lstm_hidden_dim, batch_first=True)\n",
        "        self.outer_lstm_layer_intent = nn.LSTM(lstm_hidden_dim * 4, lstm_hidden_dim, batch_first=True)\n",
        "        \n",
        "        self.out_layer_intent = nn.Linear(lstm_hidden_dim, intents_count)\n",
        "        self.out_layer_tags = nn.Linear(lstm_hidden_dim, tags_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        out_intent, _ = self.inner_lstm_layer_intent(projections)\n",
        "        out_tags, _ = self.inner_lstm_layer_tags(projections)\n",
        "\n",
        "        h = torch.cat((out_intent, out_tags), dim=2)\n",
        "        tags_output, _ = self.outer_lstm_layer_tags(h)\n",
        "        _, (hidden, _) = self.outer_lstm_layer_intent(h)\n",
        "        intent_output = hidden[-1]\n",
        "        \n",
        "        tags_output = self.dropout(tags_output)\n",
        "        intent_output = self.dropout(intent_output)\n",
        "        intent_output = self.out_layer_intent.forward(intent_output)\n",
        "        tags_output = self.out_layer_tags.forward(tags_output)\n",
        "\n",
        "        #print(tags_output.shape, intent_output.shape)\n",
        "        return tags_output, intent_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAoT0TXbPJEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458e4d5a-600d-4c63-ef80-32384ef598da"
      },
      "source": [
        "model = AsyncSharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
        "                         tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "for x in train_iter:\n",
        "    break\n",
        "print(x.tokens.shape)\n",
        "print(x.intent.shape)\n",
        "print(x.tags.shape)\n",
        "tags_output, intent_output = model(x.tokens.transpose(0, 1))\n",
        "tags_output.shape, intent_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 32])\n",
            "torch.Size([32])\n",
            "torch.Size([15, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 15, 192]), torch.Size([32, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEYVn6IXBRiR"
      },
      "source": [
        "class AsyncSharedModelTrainer():\n",
        "    def __init__(self, model, criterion, tags_optimizer, intent_optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.tags_optimizer = tags_optimizer\n",
        "        self.intent_optimizer = intent_optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        self.epoch_loss = 0\n",
        "        self.tags_correct_count, self.tags_total_count = 0, 0\n",
        "        self.intent_correct_count, self.intent_total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self, is_train):\n",
        "        if is_train:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}{}'.format(\n",
        "                Fore.RED, self.name, self.epoch_loss / self.batches_count, self.tags_correct_count / self.tags_total_count, self.intent_correct_count / self.intent_total_count,\\\n",
        "                Style.RESET_ALL\n",
        "            )\n",
        "        else:\n",
        "            return '{}{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}{}'.format(\n",
        "                Fore.GREEN, self.name, self.epoch_loss / self.batches_count, self.tags_correct_count / self.tags_total_count, self.intent_correct_count / self.intent_total_count,\\\n",
        "                Style.RESET_ALL\n",
        "            )\n",
        "        \n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        tags_logits, intent_logits = self.model(batch.tokens.transpose(0, 1))\n",
        "        true_tags = batch.tags.transpose(0, 1)\n",
        "        true_intent = batch.intent\n",
        "        #loss\n",
        "        tags_loss = self.criterion(tags_logits.transpose(1, 2), true_tags)\n",
        "        intent_loss = self.criterion(intent_logits, true_intent)\n",
        "        #predicts\n",
        "        predicted_tags = tags_logits.max(axis=2)[1]\n",
        "        predicted_intent = intent_logits.max(axis=1)[1]\n",
        "        self.tags_correct_count += torch.sum(true_tags == predicted_tags).item() - torch.sum(true_tags == 0).item()\n",
        "        self.tags_total_count += torch.sum(true_tags != 0).item()\n",
        "        self.intent_correct_count += torch.sum(true_intent == predicted_intent).item()\n",
        "        self.intent_total_count += true_intent.size(0)\n",
        "        if self.is_train:\n",
        "    \n",
        "            self.intent_optimizer.zero_grad()\n",
        "            self.tags_optimizer.zero_grad()\n",
        "\n",
        "            intent_loss.backward(retain_graph=True)\n",
        "            tags_loss.backward()\n",
        "\n",
        "            self.intent_optimizer.step()\n",
        "            # model.embeddings_layer.zero_grad()\n",
        "            self.tags_optimizer.step()\n",
        "            \n",
        "        self.epoch_loss += tags_loss.item() + intent_loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohdJLy4DNUT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4a3140-9f5b-4cf1-88ba-8f67562da3fa"
      },
      "source": [
        "tags_parameters_names = [name for name, param in model.named_parameters() if not 'intent' in name]\n",
        "intent_parameters_names = [name for name, param in model.named_parameters() if not 'tags' in name]\n",
        "tags_parameters_names, intent_parameters_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['embeddings_layer.weight',\n",
              "  'inner_lstm_layer_tags.weight_ih_l0',\n",
              "  'inner_lstm_layer_tags.weight_hh_l0',\n",
              "  'inner_lstm_layer_tags.bias_ih_l0',\n",
              "  'inner_lstm_layer_tags.bias_hh_l0',\n",
              "  'inner_lstm_layer_tags.weight_ih_l0_reverse',\n",
              "  'inner_lstm_layer_tags.weight_hh_l0_reverse',\n",
              "  'inner_lstm_layer_tags.bias_ih_l0_reverse',\n",
              "  'inner_lstm_layer_tags.bias_hh_l0_reverse',\n",
              "  'outer_lstm_layer_tags.weight_ih_l0',\n",
              "  'outer_lstm_layer_tags.weight_hh_l0',\n",
              "  'outer_lstm_layer_tags.bias_ih_l0',\n",
              "  'outer_lstm_layer_tags.bias_hh_l0',\n",
              "  'out_layer_tags.weight',\n",
              "  'out_layer_tags.bias'],\n",
              " ['embeddings_layer.weight',\n",
              "  'inner_lstm_layer_intent.weight_ih_l0',\n",
              "  'inner_lstm_layer_intent.weight_hh_l0',\n",
              "  'inner_lstm_layer_intent.bias_ih_l0',\n",
              "  'inner_lstm_layer_intent.bias_hh_l0',\n",
              "  'inner_lstm_layer_intent.weight_ih_l0_reverse',\n",
              "  'inner_lstm_layer_intent.weight_hh_l0_reverse',\n",
              "  'inner_lstm_layer_intent.bias_ih_l0_reverse',\n",
              "  'inner_lstm_layer_intent.bias_hh_l0_reverse',\n",
              "  'outer_lstm_layer_intent.weight_ih_l0',\n",
              "  'outer_lstm_layer_intent.weight_hh_l0',\n",
              "  'outer_lstm_layer_intent.bias_ih_l0',\n",
              "  'outer_lstm_layer_intent.bias_hh_l0',\n",
              "  'out_layer_intent.weight',\n",
              "  'out_layer_intent.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMNscGmZ4APl"
      },
      "source": [
        "Затем их нужно передать в отдельные оптимизаторы и учить отдельно.\n",
        "\n",
        "*Еще, может быть, пригодится retain_graph параметр метода backward()*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmMt811LBUXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d28ab60-7ad3-41a5-aab3-5314631023ff"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = AsyncSharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
        "                         tags_count=len(tags_field.vocab)).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "tags_parameters = [param for name, param in model.named_parameters() if not 'intent' in name]\n",
        "intent_parameters = [param for name, param in model.named_parameters() if not 'tags' in name]\n",
        "\n",
        "\n",
        "tags_optimizer = optim.Adam(tags_parameters)\n",
        "intent_optimizer = optim.Adam(intent_parameters)\n",
        "#collect all\n",
        "trainer = AsyncSharedModelTrainer(model, criterion, tags_optimizer, intent_optimizer)\n",
        "fit(trainer, train_iter, epochs_count=10, val_iter=val_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[1 / 10] Train: Loss = 1.29559, Tags accuracy = 78.14%, Intents accuracy = 76.69%\u001b[0m: 100%|██████████| 549/549 [00:12<00:00, 45.71it/s]\n",
            "\u001b[32m[1 / 10]   Val: Loss = 0.45093, Tags accuracy = 91.20%, Intents accuracy = 92.58%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 62.99it/s]\n",
            "\u001b[31m[2 / 10] Train: Loss = 0.26203, Tags accuracy = 93.65%, Intents accuracy = 96.52%\u001b[0m: 100%|██████████| 549/549 [00:12<00:00, 45.40it/s]\n",
            "\u001b[32m[2 / 10]   Val: Loss = 0.25837, Tags accuracy = 94.86%, Intents accuracy = 95.25%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 63.71it/s]\n",
            "\u001b[31m[3 / 10] Train: Loss = 0.12315, Tags accuracy = 97.09%, Intents accuracy = 98.38%\u001b[0m: 100%|██████████| 549/549 [00:12<00:00, 45.50it/s]\n",
            "\u001b[32m[3 / 10]   Val: Loss = 0.15893, Tags accuracy = 96.23%, Intents accuracy = 97.67%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 66.74it/s]\n",
            "\u001b[31m[4 / 10] Train: Loss = 0.05998, Tags accuracy = 98.56%, Intents accuracy = 99.35%\u001b[0m: 100%|██████████| 549/549 [00:11<00:00, 46.12it/s]\n",
            "\u001b[32m[4 / 10]   Val: Loss = 0.14456, Tags accuracy = 96.38%, Intents accuracy = 97.83%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 66.53it/s]\n",
            "\u001b[31m[5 / 10] Train: Loss = 0.03312, Tags accuracy = 99.23%, Intents accuracy = 99.60%\u001b[0m: 100%|██████████| 549/549 [00:11<00:00, 45.95it/s]\n",
            "\u001b[32m[5 / 10]   Val: Loss = 0.15368, Tags accuracy = 96.72%, Intents accuracy = 97.92%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 69.41it/s]\n",
            "\u001b[31m[6 / 10] Train: Loss = 0.02034, Tags accuracy = 99.53%, Intents accuracy = 99.77%\u001b[0m: 100%|██████████| 549/549 [00:12<00:00, 45.48it/s]\n",
            "\u001b[32m[6 / 10]   Val: Loss = 0.17723, Tags accuracy = 96.83%, Intents accuracy = 97.00%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 67.88it/s]\n",
            "\u001b[31m[7 / 10] Train: Loss = 0.01154, Tags accuracy = 99.69%, Intents accuracy = 99.91%\u001b[0m: 100%|██████████| 549/549 [00:12<00:00, 45.63it/s]\n",
            "\u001b[32m[7 / 10]   Val: Loss = 0.13588, Tags accuracy = 97.15%, Intents accuracy = 98.25%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 69.16it/s]\n",
            "\u001b[31m[8 / 10] Train: Loss = 0.00659, Tags accuracy = 99.82%, Intents accuracy = 99.95%\u001b[0m: 100%|██████████| 549/549 [00:11<00:00, 45.77it/s]\n",
            "\u001b[32m[8 / 10]   Val: Loss = 0.16197, Tags accuracy = 96.86%, Intents accuracy = 98.17%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 65.96it/s]\n",
            "\u001b[31m[9 / 10] Train: Loss = 0.00422, Tags accuracy = 99.87%, Intents accuracy = 99.99%\u001b[0m: 100%|██████████| 549/549 [00:11<00:00, 45.83it/s]\n",
            "\u001b[32m[9 / 10]   Val: Loss = 0.15550, Tags accuracy = 97.27%, Intents accuracy = 98.25%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 67.62it/s]\n",
            "\u001b[31m[10 / 10] Train: Loss = 0.00416, Tags accuracy = 99.83%, Intents accuracy = 100.00%\u001b[0m: 100%|██████████| 549/549 [00:11<00:00, 45.86it/s]\n",
            "\u001b[32m[10 / 10]   Val: Loss = 0.17772, Tags accuracy = 97.00%, Intents accuracy = 98.25%\u001b[0m: 100%|██████████| 10/10 [00:00<00:00, 67.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbroXzacJJlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8d729e-3bec-45e5-c05a-259adef70f31"
      },
      "source": [
        "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mTest: Loss = 0.29915, Tags accuracy = 96.54%, Intents accuracy = 96.36%\u001b[0m: 100%|██████████| 13/13 [00:00<00:00, 74.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMw5L4iG5Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f0df14-2cca-426a-ac1b-40f0e1671e70"
      },
      "source": [
        "from conlleval import evaluate\n",
        "\n",
        "def eval_tagger(model, test_iter):\n",
        "    true_seqs, pred_seqs = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iter:\n",
        "            pred = model.forward(batch.tokens.transpose(0, 1))[0].transpose(1, 2).max(dim=1)[1].cpu().tolist()\n",
        "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
        "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in batch.tags.transpose(0, 1).cpu().tolist()])\n",
        "\n",
        "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
        "\n",
        "eval_tagger(model, test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 91.19%, Recall = 92.88%, F1 = 92.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE-5oyMUU40L"
      },
      "source": [
        "#### **Задание 3.2**\n",
        "Посмотрите на параметры в статье и попробуйте добиться похожего качества.\n",
        "\n",
        "#### **Задание 4**\n",
        "Посмотрите результаты на SNIPS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NujuoWDU195f"
      },
      "source": [
        "## Async Multi-task Learning for POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Q0ip3p2a5v"
      },
      "source": [
        "Ещё одна статья: [Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings](https://arxiv.org/pdf/1805.08237.pdf)\n",
        "\n",
        "Архитектура там такая:\n",
        "\n",
        "<img src=\"https://i.ibb.co/0nSX6CC/2018-11-27-9-26-15.png\" width=\"400\"/>\n",
        "\n",
        "Multi-task задача - обучение отдельных классификаторов более низкого уровня (над символами и словами) для предсказания тегов отдельными оптимизаторами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyB8YIO6SH9T"
      },
      "source": [
        "## DeepPavlov go_bot\n",
        "\n",
        "http://docs.deeppavlov.ai/en/master/features/skills/go_bot.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD670nqlWZOM"
      },
      "source": [
        "Поддробные туториалы:\n",
        "\n",
        "Simple: https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/gobot_tutorial.ipynb\n",
        "\n",
        "Extended: https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/gobot_extended_tutorial.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2x9-j4oz08p"
      },
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Статьи\n",
        "A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling, 2018 [[pdf]](http://aclweb.org/anthology/N18-2050)\n",
        "\n",
        "Slot-Gated Modeling for Joint Slot Filling and Intent Prediction, 2018 [[pdf]](http://aclweb.org/anthology/N18-2118) \n",
        "\n",
        "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings, 2018 [[pdf]](https://arxiv.org/pdf/1805.08237.pdf)\n",
        "\n",
        "BERT for Joint Intent Classification and Slot Filling\n",
        " [[pdf]](https://arxiv.org/pdf/1902.10909.pdf)\n",
        "\n",
        "## Блоги\n",
        "[Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)  "
      ]
    }
  ]
}