{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New!!!6 сетей+1 сверху!!!!!!!!!ansamble_of_simpsons_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG47vhLxKNln",
        "colab_type": "text"
      },
      "source": [
        "###Подготовка библиотек"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhH-mUbczYYH",
        "colab_type": "text"
      },
      "source": [
        "Установка torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITX8q-BMkKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq7IMuaPymiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjdBEfBCFRBS",
        "colab_type": "text"
      },
      "source": [
        "Импортируем нужные библиотеки, делаем настройки для работы с GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-YekKLfK-3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmJbT3iE9rq",
        "colab_type": "text"
      },
      "source": [
        "Импортируем нужные библиотеки, проверяем доступность GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWgcwKwCLBfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbuUymvjFuVC",
        "colab_type": "text"
      },
      "source": [
        "Удалим старую версию Pillow и установим новую Pillow 5.3.0 (в конце необходимо перегрузить runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXno2OSeLF3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip uninstall -y Pillow\n",
        "!pip install Pillow==5.3.0\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qDaoveuygpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InEP9gMlygzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUKR5_xdyg35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTQXgo_oYDx8",
        "colab_type": "text"
      },
      "source": [
        "Подключаем google drive (для google colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA3o2xC3MlMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAdXKQJOGxVr",
        "colab_type": "text"
      },
      "source": [
        "Расзиповываем архив"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGt7YicMxYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/gdrive/My\\ Drive/simpsons/data/simpsons4.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2iElNKzSp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-MIeZxqGfqM",
        "colab_type": "text"
      },
      "source": [
        "Просматриваем папки из архива\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2dg3IHMMo-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'train/simpsons_dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eql8-ma0zBHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJu_GHdnHFv9",
        "colab_type": "text"
      },
      "source": [
        "Импортируем torch и разрешаем ему доступ к GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvWhlkiRMxih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD_8gK6PmgXk",
        "colab_type": "text"
      },
      "source": [
        "Импортируем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naD6xsZzMxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from skimage import io\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
        "# мы будем игнорировать warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTdzMtgJP15N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# разные режимы датасета \n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру RESCALE_SIZExRESCALE_SIZE px\n",
        "RESCALE_SIZE = 299\n",
        "# работаем на видеокарте\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ecnkB2xK1aE",
        "colab_type": "text"
      },
      "source": [
        "Фиксируем генераторы случайных чисел"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbUf1h8u3iU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cfQ9X-zzIQG",
        "colab_type": "text"
      },
      "source": [
        "###Подготовка датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae3KpjIJIocv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Загружаем картинки. Переопределяем метод __getitem_ для удобства работы с данной структурой данных. Конвертируем,  немного аугументируем, масштабируем.\n",
        " Используем LabelEncoder для преобразования строковых меток классов в id и обратно. Приводим картинки к одному размеру (_prepare_sample).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj32U5iTQUe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "  \n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "     \n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "            self.label_encoder.fit(self.labels)\n",
        "\n",
        "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                  pickle.dump(self.label_encoder, le_dump_file)\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        \n",
        "        if self.mode == 'test':\n",
        "          transform = transforms.Compose([\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "                 \n",
        "                       \n",
        "          x = self.load_sample(self.files[index])\n",
        "          x = self._prepare_sample(x)\n",
        "          x = np.array(x / 255, dtype='float32')\n",
        "          x = transform(x)\n",
        "          return x\n",
        "        else:\n",
        "          transform = transforms.Compose([\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.ToPILImage(),\n",
        "                                          transforms.RandomChoice([transforms.ColorJitter(brightness=np.random.uniform(0,0.2),contrast=np.random.uniform(0,0.2),hue=0,saturation=0),\n",
        "                                                                   transforms.ColorJitter(brightness=0,contrast=0,hue=np.random.uniform(0,0.1),saturation=np.random.uniform(0,0.1)),\n",
        "                                                                   transforms.RandomHorizontalFlip(),\n",
        "                                                                   transforms.RandomRotation(np.random.uniform(0,5))]),\n",
        "                                          \n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                          ])\n",
        "          x = self.load_sample(self.files[index])\n",
        "          x = self._prepare_sample(x)\n",
        "          x = np.array(x / 255, dtype='float32')\n",
        "          x = transform(x)\n",
        "       \n",
        "          label = self.labels[index]\n",
        "          label_id = self.label_encoder.transform([label])\n",
        "          y = label_id.item()\n",
        "          return x, y\n",
        "        \n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYvHAhxvyxLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLW_rI2ByzAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lJ1mXmpyIRb",
        "colab_type": "text"
      },
      "source": [
        "Показ картинок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_odtTEzcaWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    \"\"\"Imshow для тензоров\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC5QWB9cx7gm",
        "colab_type": "text"
      },
      "source": [
        "Прописываем пути для файлов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUhzOq1zRJil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = Path('train/simpsons_dataset')\n",
        "TEST_DIR = Path('testset/testset')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyvnwM5oyLcz",
        "colab_type": "text"
      },
      "source": [
        "Делим исходную  train часть датасета на train и валидационную часть "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPhhKKlRyCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
        "                                          stratify=train_val_labels, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAimOLjSQGTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMgIbm6hRwdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmKSdyv1b7PD",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на героев внутри датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltitWp3lXAZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6YcZk8vQR47",
        "colab_type": "text"
      },
      "source": [
        "### Построение нейросетей\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PJcWAhuji-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4F06T4JGn4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrpe8S3tqtcz",
        "colab_type": "text"
      },
      "source": [
        "Импортируем предобученную модель Inseption V3 и посмотрим ее архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc9bMCv-GoBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.inception import inception_v3\n",
        "inception_model0=inception_v3(pretrained=True, aux_logits=False)\n",
        "\n",
        "print(inception_model0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KaZsr6Uqkb7",
        "colab_type": "text"
      },
      "source": [
        "Список слоев Inception:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTrWrSM7qK2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('Слои Inception:')\n",
        "for name, child in inception_model0.named_children():\n",
        "    for name2, params in child.named_parameters():\n",
        "        print(name, name2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S8d1S9E9DCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I9nyz9srYHD",
        "colab_type": "text"
      },
      "source": [
        "Импортируем предобученную модель Resnet50 и посмотрим ее архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKG8M6JkGoFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.resnet import resnet50\n",
        "resnet_model0=resnet50(pretrained=True)\n",
        "\n",
        "print(resnet_model0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9W8RWBjrkuc",
        "colab_type": "text"
      },
      "source": [
        "Список слоев Resnet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAxWWoieGoI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('Слои Resnet:')\n",
        "for name, child in resnet_model0.named_children():\n",
        "    for name2, params in child.named_parameters():\n",
        "        print(name, name2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5odlo6JGoMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlyQe7UNGoQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-7sPNPb41Kn",
        "colab_type": "text"
      },
      "source": [
        "Описываем метод fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2mk7MNtcUhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "    \n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "              \n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    \n",
        "    \n",
        "    return train_loss, train_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMny9A8v5BDW",
        "colab_type": "text"
      },
      "source": [
        "Описываем метод eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_CD9--hcUjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiUXejyLxCmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6NQ9N8v3uma",
        "colab_type": "text"
      },
      "source": [
        "Тренируем сеть. Делаем градиентный спуск, оптимизацию. Ставим Scheduler для изменения learning rate каждые 5 эпох. Применяем кроссэнтропию. Считаем loss и accuracy. Сохраняем веса в файл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaxYIwB3cUmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_files, val_files, model, epochs, batch_size, ml):\n",
        "    \n",
        "    \n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    \n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "      params_to_update = []\n",
        "      for param in model.parameters():\n",
        "        if param.requires_grad == True:\n",
        "          params_to_update.append(param)\n",
        "      opt = torch.optim.Adam(params_to_update, lr=0.0001)\n",
        "      scheduler=torch.optim.lr_scheduler.StepLR(opt,7,gamma=0.1)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      best_acc=0\n",
        "      for epoch in range(epochs):\n",
        "        train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "        print(\"loss\", train_loss)\n",
        "        scheduler.step(train_loss)\n",
        "        val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "        history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "        \n",
        "        if train_acc > best_acc:\n",
        "\n",
        "        # copy the model weights. Cохраним веса в файлы        \n",
        "          if ml == 'i0':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/inception_model0_weights.pth\") \n",
        "          if ml == 'i1':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/inception_model1_weights.pth\") \n",
        "          if ml == 'i2':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/inception_model2_weights.pth\") \n",
        "          if ml == 'i3':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/inception_model3_weights.pth\") \n",
        "          if ml == 'i4':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/inception_model4_weights.pth\") \n",
        "          if ml == 'r0':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/resnet_model0_weights.pth\") \n",
        "          if ml == 'r1':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/resnet_model1_weights.pth\")\n",
        "          if ml == 'r2':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/resnet_model2_weights.pth\")\n",
        "          if ml == 'a':\n",
        "            torch.save(model.state_dict(), \"/content/gdrive/My Drive/simpsons/1/ansamble_weights.pth\")   \n",
        "          best_acc =   train_acc\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "        pbar_outer.update(1)\n",
        "        tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                       v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "            \n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4cxggkq4goo",
        "colab_type": "text"
      },
      "source": [
        "Делаем предсказание. Применяем softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6G7qbYqcUpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J_tcyXAZQ24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH41SdoItGsC",
        "colab_type": "text"
      },
      "source": [
        "Посчитаем количество классов в классификаторе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbZWQm7-tCP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "print(\"we will classify :{}\".format(n_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-BrWsTEtEyp",
        "colab_type": "text"
      },
      "source": [
        "Заморозим первые 7 слоев в Inception. Модифицируем слой fc. Установим использование GPU. Посмотрим на модель еще раз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzwhB4K3dQOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "ct=0\n",
        "for name, child in inception_model0.named_children():\n",
        "    ct += 1\n",
        "    if ct < 7:\n",
        "        for name2, par in child.named_parameters():\n",
        "          par.requires_grad = False\n",
        "\n",
        "inception_model0.fc = nn.Sequential(\n",
        "    nn.Dropout2d(),\n",
        "    nn.Linear(2048, out_features=n_classes))\n",
        "\n",
        "inception_model0=inception_model0.to(DEVICE)\n",
        "\n",
        "print(inception_model0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESP2wb5ZtnNf",
        "colab_type": "text"
      },
      "source": [
        "Заморозим первые 7 слоев в Resnet. Разморозим Bottleneck-и: layer1, layer2, layer3. Модифицируем слой fc. Установим использование GPU. Посмотрим на модель еще раз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xluix5FnHpR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ct=0\n",
        "for name, child in resnet_model0.named_children():\n",
        "    ct += 1\n",
        "    if ct < 7:\n",
        "        for name2, par in child.named_parameters():\n",
        "          par.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "for param in resnet_model0.fc.parameters() or resnet_model0.layer1.parameters() or resnet_model0.layer2.parameters() or resnet_model0.layer3.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "\n",
        "resnet_model0.fc = nn.Sequential(\n",
        "    nn.Dropout2d(),\n",
        "    nn.Linear(resnet_model0.fc.in_features, out_features=n_classes)\n",
        "    )\n",
        "\n",
        "resnet_model0=resnet_model0.to(DEVICE)\n",
        "\n",
        "print(\"we will classify :{}\".format(n_classes))\n",
        "print(resnet_model0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UlUdgM3JSMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#val_dataset = SimpsonsDataset(val_files, mode='val')\n",
        "#train_dataset = SimpsonsDataset(train_files, mode='train')\n",
        "\n",
        "#train(train_dataset, val_dataset, model=inception_model0, epochs=1, batch_size=128, ml='i0')\n",
        "#train(train_dataset, val_dataset, model=resnet_model0, epochs=1, batch_size=128, ml='r0')\n",
        "\n",
        "torch.save(resnet_model0.state_dict(), \"/content/gdrive/My Drive/simpsons/1/r0_weights.pth\")\n",
        "torch.save(inception_model0.state_dict(), \"/content/gdrive/My Drive/simpsons/1/i0_weights.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8LU-k1FJSRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZISKfXb6JSKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJfn9JArJSHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqO_7UYXz7Yu",
        "colab_type": "text"
      },
      "source": [
        "###Обучение нейросетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo3UND5RdgVg",
        "colab_type": "text"
      },
      "source": [
        "Запустим обучение ансамбля"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDkcxZ1kfD4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc-srRk23bcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "n_folds = 3\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(train_val_files, label_encoder.transform(train_val_labels))):\n",
        "    print('\\nFOLD', fold+1)\n",
        "    val_dataset = SimpsonsDataset(np.array(train_val_files)[val_idx], mode='val')\n",
        "    train_dataset = SimpsonsDataset(np.array(train_val_files)[train_idx], mode='train')\n",
        "    \n",
        "    \n",
        "\n",
        "    print('Inception model ',str(fold+1))\n",
        "    inception_model0.load_state_dict(torch.load( \"/content/gdrive/My Drive/simpsons/1/i0_weights.pth\"))\n",
        "    history=train(train_dataset, val_dataset, model=inception_model0, epochs=15, batch_size=128, ml=('i'+str(fold)))\n",
        "\n",
        "    plt.figure(figsize=(15, 9))\n",
        "    plt.title('Обучение Inception ', str(fold+1))\n",
        "    loss0, acc0, val_loss0, val_acc0 = zip(*history)\n",
        "    plt.plot(loss0, label=\"train_loss\")\n",
        "    plt.plot(val_loss0, label=\"val_loss\")\n",
        "\n",
        "    print('Resnet model ', str(fold+1))\n",
        "    resnet_model0.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/r0_weights.pth\"))\n",
        "      \n",
        "    history=train(train_dataset, val_dataset, model=resnet_model0, epochs=15, batch_size=128, ml=('r'+str(fold)))\n",
        "\n",
        "    plt.figure(figsize=(15, 9))\n",
        "    plt.title('Обучение Resnet ', str(fold+1))\n",
        "    loss0, acc0, val_loss0, val_acc0 = zip(*history)\n",
        "    plt.plot(loss0, label=\"train_loss\")\n",
        "    plt.plot(val_loss0, label=\"val_loss\")\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7BxT-QRpjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDXoR8PIdfLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfVfGrEuQj0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJJs1Ooudb-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryD_9yFdfNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8hCTEBqRwqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD1K9Zg2H_pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VKOr5eiV1RK",
        "colab_type": "text"
      },
      "source": [
        "Загрузка весов обученных моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NULkB8cIB0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Если надо, загружаем сохраненные состояния весов нейросетей, пропуская блок \"Обучение нейросетей\". Во избежание утери данных при повторной распаковке архива, файлы с весами\n",
        "# храним на google drive.\n",
        "\n",
        "inception_model1 = inception_model0\n",
        "inception_model2 = inception_model0\n",
        "\n",
        "inception_model0.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/inception_model0_weights.pth\"))\n",
        "inception_model1.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/inception_model1_weights.pth\"))\n",
        "inception_model2.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/inception_model2_weights.pth\"))\n",
        "\n",
        "resnet_model1 = resnet_model0\n",
        "resnet_model2 = resnet_model0\n",
        "\n",
        "resnet_model0.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/resnet_model0_weights.pth\"))\n",
        "resnet_model1.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/resnet_model1_weights.pth\"))\n",
        "resnet_model2.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/resnet_model2_weights.pth\"))\n",
        "\n",
        "#inception_model0.eval()# переключаем нейросеть в режим обучения\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btxrvxJJE-wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JV7LkowIay1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8upvMZE8q9R",
        "colab_type": "text"
      },
      "source": [
        "###Обучаем новую нейросеть находить лучшие предсказания из ансамбля"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxI1BdS3SJn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyEnsemble(nn.Module):   \n",
        "    def __init__(self, inception_model0, inception_model1, inception_model2, resnet_model0, resnet_model1, resnet_model2, n_classes):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.inception_model0 = inception_model0\n",
        "        self.inception_model1 = inception_model1\n",
        "        self.inception_model2 = inception_model2\n",
        "\n",
        "        self.resnet_model0 = resnet_model0\n",
        "        self.resnet_model1 = resnet_model1\n",
        "        self.resnet_model2 = resnet_model2\n",
        "\n",
        "        self.classifier = nn.Linear(n_classes * 6, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.inception_model0(x)\n",
        "        x2 = self.inception_model1(x)\n",
        "        x3 = self.inception_model2(x)\n",
        "\n",
        "        x4 = self.resnet_model0(x)\n",
        "        x5 = self.resnet_model1(x)\n",
        "        x6 = self.resnet_model2(x)\n",
        "\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4, x5, x6), dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcAQ-jsRClkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ensemble = MyEnsemble(inception_model0, inception_model1, inception_model2, resnet_model0, resnet_model1, resnet_model2, n_classes=42).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKzhTPKNSJlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# замораживаем параметры (веса) не входящие в layers_to_unfreeze\n",
        "for param in model_ensemble.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model_ensemble.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw8oe4bfSJh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DE7VWNqSJe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
        "    \n",
        "train_dataset = SimpsonsDataset(train_files, mode='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JyWNKX98VkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Загрузить веса\n",
        "#model_ensemble.load_state_dict(torch.load(\"/content/gdrive/My Drive/simpsons/1/ansamble_weights.pth\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3A3wA-SJcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = train(train_dataset, val_dataset, model=model_ensemble, epochs=15, batch_size=128, ml='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_lCrlfcSJYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, val_loss, val_acc = zip(*history)\n",
        "plt.figure(figsize=(15, 9))\n",
        "plt.title('Обучение Ansamble')\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbTFFi7aSTmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wysfZMshuZkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub40CkaGwGkg",
        "colab_type": "text"
      },
      "source": [
        "###Делаем предсказания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DXbGod2wJin",
        "colab_type": "text"
      },
      "source": [
        "Предсказание одной картинки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_sAUBn5uZuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_one_sample(model, inputs, device=DEVICE):\n",
        "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
        "    with torch.no_grad():\n",
        "        inputs = inputs.to(device)\n",
        "        model.eval()\n",
        "        logit = model(inputs).cpu()\n",
        "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
        "    return probs\n",
        "random_characters = int(np.random.uniform(0,1000))\n",
        "ex_img, true_label = val_dataset[random_characters]\n",
        "probs_im = predict_one_sample(model_ensemble, ex_img.unsqueeze(0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDXqTh3CvNjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random_characters = int(np.random.uniform(0,1000))\n",
        "#ex_img, true_label = val_dataset[random_characters]\n",
        "#probs_im = predict_one_sample(model_ensemble, ex_img.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5FYNoNwfLW",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на предсказания на валидационной выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpPNPKwlIbD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
        "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
        "\n",
        "probs_ims = predict(model_ensemble, imgs)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usXsaOHUvGmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQvwC561w0Ct",
        "colab_type": "text"
      },
      "source": [
        "Вычислим целевую метрику F1-score на валидационной выборке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeFSp6OkIgme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfcMqgCDJN0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.argmax(probs_ims,-1)\n",
        "\n",
        "actual_labels = [val_dataset[id][1] for id in idxs]\n",
        "\n",
        "preds_class = [label_encoder.classes_[i] for i in y_pred]\n",
        "\n",
        "print(\"Предсказание: \", y_pred)\n",
        "print (\"Правильный ответ: \", actual_labels)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"f1_score: \", f1_score(actual_labels, y_pred, average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W02GKlpFe0lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIRV0c2svnja",
        "colab_type": "text"
      },
      "source": [
        "Сделаем визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbNSZHyEvhC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    \n",
        "    \n",
        "\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)\n",
        "    \n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "            \n",
        "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    font.set_family(\"fantasy\")\n",
        "    prob_pred = predict_one_sample(model_ensemble, im_val.unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "    \n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
        "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "            \n",
        "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40SVhmEuvhGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U07oEA3mvhNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFpG7rb9vhKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft7Kt6_YyEDS",
        "colab_type": "text"
      },
      "source": [
        "Confusion matrix, accurancy for each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLummoWK5QKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "    \n",
        "   \n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    cm = cm.T\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    \n",
        "    plt.figure(figsize=(16,11))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    \n",
        "def show_confusion_matrix_fucn(model):\n",
        "    \"\"\"Построить и посчитать точность классов по confusion matrix\"\"\"\n",
        "    y_test_all = torch.Tensor().long()\n",
        "    predictions_all = torch.Tensor().long()\n",
        "\n",
        "    # Пройдём по всему validation датасету и запишем ответы сети\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            predictions = model(inputs.to(DEVICE))\n",
        "            y_test = labels\n",
        "            _, predictions = torch.max(predictions.cpu(), 1)\n",
        "\n",
        "            # Аналог append для list\n",
        "            y_test_all = torch.cat((y_test_all, y_test), 0)\n",
        "            predictions_all = torch.cat((predictions_all, predictions), 0)\n",
        "\n",
        "    feature_names = sorted(set(dataloaders['val'].dataset.labels))\n",
        "\n",
        "    y_test_all = y_test_all.numpy()\n",
        "    predictions_all = predictions_all.numpy()\n",
        "\n",
        "    # Функция из sklearn, создаёт confusion матрицу\n",
        "    cm = confusion_matrix(y_test_all, predictions_all, np.arange(n_classes))\n",
        "    # Выведем её\n",
        "    plot_confusion_matrix(cm, feature_names, normalize=True)\n",
        "    \n",
        "    return y_test_all, predictions_all\n",
        "  \n",
        "def accurancy_for_each_class(y_test_all, predictions_all):\n",
        "    class_correct = [0 for i in range(n_classes)]\n",
        "    class_total = [0 for i in range(n_classes)]\n",
        "    feature_names = sorted(set(dataloaders['val'].dataset.labels))\n",
        "\n",
        "    c = (predictions_all == y_test_all).squeeze()\n",
        "    for i in range(len(predictions_all)):\n",
        "        label = predictions_all[i]            \n",
        "        class_correct[label] += c[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    print(class_total)\n",
        "    print(len(class_total))\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            (feature_names[i], (100 * class_correct[i] / class_total[i]) if class_total[i] != 0 else -1)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZTlEQfIx3jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "# DataLoader достаёт данные из dataset батчами\n",
        "dataloaders = {'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
        "               'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)}\n",
        "dataset_sizes = {'train': len(train_dataset), 'val':len(val_dataset) }\n",
        "print ('Для сети model_ensemble:')\n",
        "y_test_all, predictions_all = show_confusion_matrix_fucn(model_ensemble)\n",
        "# Выведем точность для каждого класса\n",
        "accurancy_for_each_class(y_test_all, predictions_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXYU368Tx3uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKM1DM5x3dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUqO5HVXx3YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdlcNA-2e9mF",
        "colab_type": "text"
      },
      "source": [
        "Submit на Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBOl4Ssbe06-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(model_ensemble, test_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4wOqzoIe1L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu6P_qXGe1J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pA9jxaNe1E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#my_submit = pd.read_csv(\"gdrive/My Drive/simpsons/data/labels.csv\")\n",
        "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "my_submit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky2lRtnofM6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_submit.to_csv('gdrive/My Drive/simpsons/ansamble_cnn_baseline.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipjnUDDJfNF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGWcqAZVfNCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}