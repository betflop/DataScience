{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ODS_Alice.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavlyk/DataScience/blob/master/ODS_Alice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-tHxgLCV4mt",
        "colab_type": "code",
        "outputId": "6307bf9d-0243-41f0-c588-e00024b59df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pathlib2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.6/dist-packages (2.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pathlib2) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR4495u3PZUS",
        "colab_type": "code",
        "outputId": "758fcf33-4eb1-4368-9912-eacc14641764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAnoOEOTXMuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from pathlib2 import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZfmUV0KV5Lh",
        "colab_type": "code",
        "outputId": "d4fa2159-94b4-4392-b0d2-d80bfcf9ff80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Read the training and test data sets, change paths if needed\n",
        "PATH_TO_DATA = Path('drive/My Drive/_ODS/CatchMe/')\n",
        "\n",
        "times = ['time%s' % i for i in range(1, 11)]\n",
        "df_train = pd.read_csv(PATH_TO_DATA / 'train_sessions.csv',\n",
        "                       index_col='session_id', parse_dates=times)\n",
        "df_test  = pd.read_csv(PATH_TO_DATA / 'test_sessions.csv',\n",
        "                      index_col='session_id', parse_dates=times)\n",
        "\n",
        "# Sort the data by time\n",
        "df_train = df_train.sort_values(by='time1')\n",
        "\n",
        "# Look at the first rows of the training set\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>time5</th>\n",
              "      <th>site6</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:05:57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54843</th>\n",
              "      <td>56</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 08:37:23</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2013-01-12 09:07:07</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2013-01-12 09:07:09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77292</th>\n",
              "      <td>946</td>\n",
              "      <td>2013-01-12 08:50:13</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:14</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:15</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>784.0</td>\n",
              "      <td>2013-01-12 08:50:16</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114021</th>\n",
              "      <td>945</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:17</td>\n",
              "      <td>949.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:18</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>945.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:19</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146670</th>\n",
              "      <td>947</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>948.0</td>\n",
              "      <td>2013-01-12 08:50:20</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>952.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:21</td>\n",
              "      <td>951.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>946.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>947.0</td>\n",
              "      <td>2013-01-12 08:50:22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            site1               time1  ...              time10 target\n",
              "session_id                             ...                           \n",
              "21669          56 2013-01-12 08:05:57  ...                 NaT      0\n",
              "54843          56 2013-01-12 08:37:23  ...                 NaT      0\n",
              "77292         946 2013-01-12 08:50:13  ... 2013-01-12 08:50:17      0\n",
              "114021        945 2013-01-12 08:50:17  ... 2013-01-12 08:50:20      0\n",
              "146670        947 2013-01-12 08:50:20  ... 2013-01-12 08:50:22      0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lEQZGB5WIZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(2, 11):\n",
        "    df_train['time{}'.format(i)] = pd.to_datetime(df_train['time{}'.format(i)])\n",
        "for i in range(2, 11):\n",
        "    df_test['time{}'.format(i)] = pd.to_datetime(df_test['time{}'.format(i)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDXBYxdBWOKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyrH2LLXWOyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataPreparator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Fill NaN with zero values.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        sites = ['site%s' % i for i in range(1, 11)]\n",
        "        return X[sites].fillna(0).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6IreO_wWQ3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ListPreparator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Prepare a CountVectorizer friendly 2D-list from data.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X = X.values.tolist()\n",
        "        # Convert dataframe rows to strings\n",
        "        return [\" \".join([str(site) for site in row]) for row in X]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAU6jzUjWTDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Add new attributes to training and test set.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self \n",
        "    def transform(self, X, y=None):\n",
        "        # intraday features\n",
        "        hour = X['time1'].apply(lambda ts: ts.hour)\n",
        "        morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
        "        day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
        "        evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
        "        \n",
        "        # season features\n",
        "        month = X['time1'].apply(lambda ts: ts.month)\n",
        "        \n",
        "        summer = ((month >= 6) & (month <= 8)).astype('int')\n",
        "       \n",
        "      \n",
        "        weekday = X['time1'].apply(lambda ts: ts.weekday()).astype('int')\n",
        "        \n",
        "        # day of the week features\n",
        "        holiday = X['time1'].apply(lambda ts: 1 if (ts.weekday() > 5) else 0).astype('int')\n",
        "        \n",
        "        # year features\n",
        "        year = X['time1'].apply(lambda ts: ts.year).astype('int')\n",
        "        \n",
        "        fsite = X['site1'].apply(lambda ts: 1 if (ts == 76 or ts == 77 or ts == 80 or ts == 21 or ts == 29) else 0).astype('int')\n",
        "        \n",
        "\n",
        "        X = np.c_[morning.values, day.values, evening.values, summer.values, weekday.values, holiday.values, year.values, fsite.values]\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnIwE_LWWdMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ScaledAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Add new features, that should be scaled.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        # session time features\n",
        "        times = ['time%s' % i for i in range(1, 11)]\n",
        "        # session duration: take to the power of 1/5 to normalize the distribution\n",
        "        session_duration = (X[times].max(axis=1) - X[times].min(axis=1)).astype('timedelta64[ms]').astype(int) ** 0.2\n",
        "        # number of sites visited in a session\n",
        "        number_of_sites = X[times].isnull().sum(axis=1).apply(lambda x: 10 - x)\n",
        "        # average time spent on one site during a session\n",
        "        time_per_site = (session_duration / number_of_sites) ** 0.2\n",
        "        \n",
        "        weekday = X['time1'].apply(lambda ts: ts.weekday()).astype('int')\n",
        "        \n",
        "        # season features\n",
        "        month = X['time1'].apply(lambda ts: ts.month)\n",
        "        \n",
        "        start_month = X['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
        "             \n",
        "        X = np.c_[session_duration.values, number_of_sites.values, weekday.values, start_month.values]\n",
        "        \n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B00Oa5NWfZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_pipeline = Pipeline([\n",
        "    (\"preparator\", DataPreparator()),\n",
        "    (\"list_preparator\", ListPreparator()),\n",
        "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 3), max_features=50000))\n",
        "])\n",
        "\n",
        "attributes_pipeline = Pipeline([\n",
        "    (\"adder\", AttributesAdder())\n",
        "])\n",
        "\n",
        "scaled_attributes_pipeline = Pipeline([\n",
        "    (\"adder\", ScaledAttributesAdder()),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xvxybmqWhZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        "('vectorizer_pipeline', vectorizer_pipeline),\n",
        "('attributes_pipeline', attributes_pipeline),\n",
        "('scaled_attributes_pipeline', scaled_attributes_pipeline)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVhah9DgWjV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = full_pipeline.fit_transform(df_train)\n",
        "X_test = full_pipeline.transform(df_test)\n",
        "\n",
        "y_train = df_train[\"target\"].astype('int').values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gtUkIvhWl2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlXq3J23Wn7C",
        "colab_type": "code",
        "outputId": "53dbdc11-59de-4579-e0d0-7c4e0b35aae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "logit = LogisticRegression(C=0.17, solver='liblinear')\n",
        "\n",
        "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
        "                        scoring='roc_auc', n_jobs=1)\n",
        "\n",
        "cv_scores.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9224545030877671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfiwAumCWqKn",
        "colab_type": "code",
        "outputId": "1a9adfac-197e-45fc-ae76-20501d117e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "logit.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.17, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkBv33ujWsaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_to_submission_file(predicted_labels, out_file,\n",
        "                             target='target', index_label=\"session_id\"):\n",
        "    predicted_df = pd.DataFrame(predicted_labels,\n",
        "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
        "                                columns=[target])\n",
        "    predicted_df.to_csv(out_file, index_label=index_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41_PJWR8WuMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "write_to_submission_file(logit_test_pred, 'bs26.csv') # 0.95191"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3-HLfPXT2OX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}